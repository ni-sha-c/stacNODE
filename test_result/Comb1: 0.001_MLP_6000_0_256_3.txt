time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 6000
num_train: 10000
num_test: 6000
num_trans: 0
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 256
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 6000
num_train: 10000
num_test: 6000
num_trans: 0
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 256
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 99.69%, model saved.
Epoch: 0 Train: 3886.70483 Test: 3949.11401
Epoch: 60 Train: 464.49414 Test: 536.67737
Epoch 120: New minimal relative error: 29.55%, model saved.
Epoch: 120 Train: 62.36379 Test: 68.25016
Epoch 180: New minimal relative error: 22.54%, model saved.
Epoch: 180 Train: 18.07524 Test: 29.00929
Epoch: 240 Train: 10.69360 Test: 19.11886
Epoch 300: New minimal relative error: 10.44%, model saved.
Epoch: 300 Train: 7.59268 Test: 14.26599
Epoch: 360 Train: 6.28724 Test: 12.71762
Epoch: 420 Train: 4.56167 Test: 10.12174
Epoch: 480 Train: 3.85398 Test: 8.94878
Epoch: 540 Train: 3.28486 Test: 7.81734
Epoch: 600 Train: 2.45150 Test: 6.82356
Epoch: 660 Train: 2.60875 Test: 7.19295
Epoch: 720 Train: 5.30321 Test: 8.09461
Epoch: 780 Train: 5.60814 Test: 9.14884
Epoch: 840 Train: 2.23581 Test: 5.85654
Epoch 900: New minimal relative error: 7.78%, model saved.
Epoch: 900 Train: 1.43435 Test: 4.49031
Epoch: 960 Train: 1.28676 Test: 4.32288
Epoch: 1020 Train: 0.97708 Test: 4.01724
Epoch: 1080 Train: 0.94824 Test: 3.97262
Epoch 1140: New minimal relative error: 6.74%, model saved.
Epoch: 1140 Train: 0.98856 Test: 3.98220
Epoch: 1200 Train: 1.63681 Test: 4.47365
Epoch: 1260 Train: 1.27085 Test: 4.18597
Epoch: 1320 Train: 1.19040 Test: 4.01721
Epoch: 1380 Train: 0.70943 Test: 3.41543
Epoch: 1440 Train: 0.59790 Test: 3.20810
Epoch: 1500 Train: 0.66827 Test: 3.26196
Epoch 1560: New minimal relative error: 5.37%, model saved.
Epoch: 1560 Train: 0.50013 Test: 3.16447
Epoch: 1620 Train: 0.51411 Test: 3.19635
Epoch: 1680 Train: 0.66651 Test: 3.38601
Epoch: 1740 Train: 0.69191 Test: 3.52194
Epoch: 1800 Train: 1.73881 Test: 3.61215
Epoch: 1860 Train: 0.39336 Test: 3.15517
Epoch: 1920 Train: 0.41284 Test: 3.20458
Epoch: 1980 Train: 0.52530 Test: 3.29386
Epoch: 2040 Train: 0.40130 Test: 3.11384
Epoch: 2100 Train: 0.40811 Test: 3.18665
Epoch: 2160 Train: 0.38363 Test: 3.16150
Epoch 2220: New minimal relative error: 5.31%, model saved.
Epoch: 2220 Train: 0.40301 Test: 3.18671
Epoch 2280: New minimal relative error: 4.86%, model saved.
Epoch: 2280 Train: 0.40162 Test: 3.17058
Epoch: 2340 Train: 0.56310 Test: 3.40340
Epoch: 2400 Train: 0.28447 Test: 3.05860
Epoch: 2460 Train: 0.30469 Test: 3.09834
Epoch: 2520 Train: 0.75925 Test: 3.52977
Epoch: 2580 Train: 0.28567 Test: 3.07376
Epoch: 2640 Train: 0.26038 Test: 3.05539
Epoch: 2700 Train: 0.25734 Test: 3.08465
Epoch: 2760 Train: 0.37850 Test: 3.12376
Epoch: 2820 Train: 0.25412 Test: 3.10322
Epoch: 2880 Train: 0.23349 Test: 3.07261
Epoch: 2940 Train: 0.25790 Test: 3.15792
Epoch: 3000 Train: 0.22028 Test: 3.08200
Epoch: 3060 Train: 0.21553 Test: 3.10548
Epoch: 3120 Train: 0.32482 Test: 3.24816
Epoch: 3180 Train: 0.34741 Test: 3.24145
Epoch: 3240 Train: 0.24676 Test: 3.16103
Epoch: 3300 Train: 0.19551 Test: 3.13999
Epoch: 3360 Train: 0.22633 Test: 3.18738
Epoch: 3420 Train: 0.18790 Test: 3.16058
Epoch: 3480 Train: 0.71646 Test: 3.49848
Epoch: 3540 Train: 0.18107 Test: 3.18035
Epoch: 3600 Train: 0.17682 Test: 3.21142
Epoch: 3660 Train: 0.44860 Test: 3.40821
Epoch: 3720 Train: 0.17102 Test: 3.19563
Epoch: 3780 Train: 0.16707 Test: 3.21958
Epoch: 3840 Train: 0.18872 Test: 3.25685
Epoch: 3900 Train: 0.16129 Test: 3.29426
Epoch 3960: New minimal relative error: 4.44%, model saved.
Epoch: 3960 Train: 0.17624 Test: 3.34105
Epoch: 4020 Train: 0.15569 Test: 3.37775
Epoch: 4080 Train: 0.16562 Test: 3.44625
Epoch: 4140 Train: 0.15427 Test: 3.40503
Epoch: 4200 Train: 0.14807 Test: 3.42411
Epoch 4260: New minimal relative error: 3.45%, model saved.
Epoch: 4260 Train: 0.14549 Test: 3.43253
Epoch: 4320 Train: 0.28083 Test: 3.61787
Epoch: 4380 Train: 0.14172 Test: 3.41174
Epoch: 4440 Train: 0.13893 Test: 3.43319
Epoch: 4500 Train: 0.13670 Test: 3.43649
Epoch: 4560 Train: 0.18660 Test: 3.43099
Epoch: 4620 Train: 0.13298 Test: 3.41949
Epoch: 4680 Train: 0.13089 Test: 3.44082
Epoch: 4740 Train: 0.12893 Test: 3.44454
Epoch: 4800 Train: 0.20819 Test: 3.53194
Epoch: 4860 Train: 0.12868 Test: 3.43510
Epoch: 4920 Train: 0.12363 Test: 3.43213
Epoch: 4980 Train: 0.12186 Test: 3.43153
Epoch: 5040 Train: 0.13937 Test: 3.41545
Epoch: 5100 Train: 0.11896 Test: 3.42834
Epoch: 5160 Train: 0.11721 Test: 3.45338
Epoch: 5220 Train: 0.11566 Test: 3.46808
Epoch: 5280 Train: 0.11416 Test: 3.48046
Epoch: 5340 Train: 0.16098 Test: 3.49346
Epoch: 5400 Train: 0.11160 Test: 3.48238
Epoch: 5460 Train: 0.11017 Test: 3.51386
Epoch: 5520 Train: 0.10882 Test: 3.53222
Epoch: 5580 Train: 0.10751 Test: 3.54812
Epoch: 5640 Train: 0.10622 Test: 3.56439
Epoch: 5700 Train: 0.20526 Test: 3.65943
Epoch: 5760 Train: 0.10385 Test: 3.59491
Epoch: 5820 Train: 0.10260 Test: 3.63685
Epoch: 5880 Train: 0.10141 Test: 3.66427
Epoch: 5940 Train: 0.13820 Test: 3.70889
Epoch 5999: New minimal relative error: 3.07%, model saved.
Epoch: 5999 Train: 0.09963 Test: 3.67696
Training Loss: tensor(0.0996)
Test Loss: tensor(3.6770)
Learned LE: [ 0.8908147  -0.01504013 -4.9944563 ]
True LE: [ 8.6415690e-01  1.3477914e-03 -1.4541009e+01]
Relative Error: [6.853182   7.423528   7.9690804  8.468196   8.916888   9.293594
 9.543083   9.5822525  9.34094    8.945199   8.710989   8.582548
 8.081207   6.5549006  4.339281   3.1408634  2.6066334  1.9285645
 1.9047048  2.2156215  2.444624   2.63673    2.9662187  3.2549648
 3.4596338  3.5261075  3.4094822  3.2059836  3.0295665  2.914742
 2.8586009  2.8786352  3.0185235  3.325736   3.83268    4.499382
 4.538279   4.3483057  4.073846   4.2279487  4.1954374  3.8517735
 3.5582297  2.675834   1.8165672  1.0601804  0.5832337  0.73332924
 1.2610296  1.5348654  1.7853717  2.2819202  2.9151094  3.3930569
 3.7954395  4.276694   4.643792   4.6928782  4.6891036  4.7646346
 4.955626   5.3295755  5.856285   6.416268   6.922383   7.360437
 7.7541733  8.125012   8.462352   8.703588   8.736805   8.448132
 7.9489546  7.634469   7.488714   6.884016   5.062359   2.9267964
 2.09833    1.5917854  1.3821347  1.6273041  1.948642   2.1919143
 2.6296158  3.0572615  3.313201   3.5542817  3.6606312  3.5210316
 3.2603714  2.9762342  2.677666   2.4536834  2.3997939  2.513505
 2.7781074  3.249891   3.932095   3.9840136  3.8693833  3.608244
 3.7840798  3.766568   3.48048    3.1865306  2.3199272  1.5515687
 0.9864559  0.5298533  0.78876364 1.2459459  1.3826861  1.5808095
 2.0896678  2.6647856  3.0908196  3.5460312  3.9558942  4.0470576
 4.053957   4.13944    4.2742014  4.5265026  4.93457    5.4005356
 5.820291   6.1794996  6.508341   6.833539   7.168003   7.5013585
 7.7804914  7.8856697  7.6514935  7.0875382  6.631337   6.392875
 5.657777   3.8192582  1.8537579  1.220101   1.0410681  1.2012424
 1.3827602  1.6758727  2.024297   2.5864007  2.9910321  3.292703
 3.6800854  3.8839872  3.7962193  3.6324475  3.357627   2.8688507
 2.340501   2.0109003  2.0127387  2.2526903  2.6347778  3.284981
 3.48562    3.3685822  3.145238   3.195944   3.3344634  3.1123667
 2.9520276  2.2075105  1.5092217  0.98528314 0.4563971  0.7065839
 1.1076872  1.1664666  1.3205746  1.8165795  2.3326466  2.789513
 3.304929   3.5223212  3.5356238  3.6400392  3.8122947  4.017025
 4.28857    4.592501   4.843663   5.0152245  5.171494   5.399371
 5.718356   6.0871305  6.4540653  6.7698183  6.963453   6.884712
 6.3827934  5.75712    5.3778605  4.5650043  2.839697   1.1136875
 0.73401845 0.9997984  1.152782   1.2030445  1.4720219  1.872508
 2.421598   2.87226    3.2880015  3.7866766  4.056935   4.0446086
 4.0353847  3.92976    3.4965653  2.8689778  2.275309   1.7832965
 1.6160396  1.8999813  2.3840327  3.0352745  2.7811975  2.735556
 2.5208163  2.8619978  2.669587   2.715092   2.2967916  1.6581035
 0.99641055 0.45050615 0.43432248 0.8803143  0.9309506  1.0227748
 1.4491585  1.9855907  2.5131552  2.9699156  3.0079238  3.0460944
 3.2188866  3.4544547  3.7125766  3.9507515  4.102519   4.15345
 4.142352   4.1244855  4.193175   4.440678   4.8457975  5.2744265
 5.619904   5.8439717  5.909587   5.6635118  5.009109   4.414962
 3.7022889  2.2172465  0.72802037 0.72889644 0.9658891  1.2785616
 1.2046499  1.423614   1.7606082  2.2166345  2.75256    3.3050172
 3.782069   4.1164865  4.083272   3.9607782  3.953762   3.7768252
 3.3234909  2.7297392  2.2132838  1.7127184  1.1804676  1.3258097
 1.9209331  2.4098504  2.0981486  2.0317125  2.0329692  2.2041478
 2.2104964  2.3413231  1.9408712  1.2271773  0.6698671  0.14695859
 0.46319306 0.67350894 0.6921396  0.9980149  1.5852938  2.0727482
 2.4669442  2.4597034  2.5210786  2.7053044  2.9420798  3.1810126
 3.3657956  3.4249473  3.3410623  3.2081857  3.1414468  3.1703308
 3.2806098  3.4848108  3.8060758  4.1761227  4.4755535  4.643386
 4.645498   4.343286   3.604744   2.8839066  1.9367135  0.6447036
 1.0702493  1.0366238  1.3055305  1.3768419  1.4821191  1.7586917
 2.096432   2.5426733  3.2233782  3.7024953  4.0839834  4.240641
 4.0161424  3.9216871  3.9410417  3.8266253  3.4934618  2.8227508
 2.1012828  1.5963694  1.1010802  0.6427321  1.3262136  1.9289324
 1.5252213  1.3948746  1.476466   1.581537   1.7174091  2.0015798
 1.6590585  1.0112714  0.5900753  0.14121428 0.22949849 0.3562139
 0.4893701  0.95163614 1.4761105  1.7978142  1.8925859  1.8982822
 2.0401568  2.2543006  2.4391031  2.5401878  2.5955486  2.5241332
 2.3311539  2.159951   2.1594527  2.322551   2.4942775  2.5773523
 2.6477988  2.8480737  3.1510782  3.3810523  3.4154215  3.140572
 2.3846319  1.6298866  1.0511357  0.53169924 1.369847   1.457929
 1.5881104  1.5691919  1.704564   2.0957365 ]
time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 6000
num_train: 10000
num_test: 6000
num_trans: 0
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 256
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 99.69%, model saved.
Epoch: 0 Train: 3886.70483 Test: 3949.11401
Epoch: 60 Train: 464.49414 Test: 536.67737
Epoch 120: New minimal relative error: 29.55%, model saved.
Epoch: 120 Train: 62.36379 Test: 68.25016
Epoch 180: New minimal relative error: 22.54%, model saved.
Epoch: 180 Train: 18.07524 Test: 29.00929
Epoch: 240 Train: 10.69360 Test: 19.11886
Epoch 300: New minimal relative error: 10.44%, model saved.
Epoch: 300 Train: 7.59268 Test: 14.26599
Epoch: 360 Train: 6.28724 Test: 12.71762
Epoch: 420 Train: 4.56167 Test: 10.12174
Epoch: 480 Train: 3.85398 Test: 8.94878
Epoch: 540 Train: 3.28486 Test: 7.81734
Epoch: 600 Train: 2.45150 Test: 6.82356
Epoch: 660 Train: 2.60875 Test: 7.19295
Epoch: 720 Train: 5.30321 Test: 8.09461
Epoch: 780 Train: 5.60814 Test: 9.14884
Epoch: 840 Train: 2.23581 Test: 5.85654
Epoch 900: New minimal relative error: 7.78%, model saved.
Epoch: 900 Train: 1.43435 Test: 4.49031
Epoch: 960 Train: 1.28676 Test: 4.32288
Epoch: 1020 Train: 0.97708 Test: 4.01724
Epoch: 1080 Train: 0.94824 Test: 3.97262
Epoch 1140: New minimal relative error: 6.74%, model saved.
Epoch: 1140 Train: 0.98856 Test: 3.98220
Epoch: 1200 Train: 1.63681 Test: 4.47365
Epoch: 1260 Train: 1.27085 Test: 4.18597
Epoch: 1320 Train: 1.19040 Test: 4.01721
Epoch: 1380 Train: 0.70943 Test: 3.41543
Epoch: 1440 Train: 0.59790 Test: 3.20810
Epoch: 1500 Train: 0.66827 Test: 3.26196
Epoch 1560: New minimal relative error: 5.37%, model saved.
Epoch: 1560 Train: 0.50013 Test: 3.16447
Epoch: 1620 Train: 0.51411 Test: 3.19635
Epoch: 1680 Train: 0.66651 Test: 3.38601
Epoch: 1740 Train: 0.69191 Test: 3.52194
Epoch: 1800 Train: 1.73881 Test: 3.61215
Epoch: 1860 Train: 0.39336 Test: 3.15517
Epoch: 1920 Train: 0.41284 Test: 3.20458
Epoch: 1980 Train: 0.52530 Test: 3.29386
Epoch: 2040 Train: 0.40130 Test: 3.11384
Epoch: 2100 Train: 0.40811 Test: 3.18665
Epoch: 2160 Train: 0.38363 Test: 3.16150
Epoch 2220: New minimal relative error: 5.31%, model saved.
Epoch: 2220 Train: 0.40301 Test: 3.18671
Epoch 2280: New minimal relative error: 4.86%, model saved.
Epoch: 2280 Train: 0.40162 Test: 3.17058
Epoch: 2340 Train: 0.56310 Test: 3.40340
Epoch: 2400 Train: 0.28447 Test: 3.05860
Epoch: 2460 Train: 0.30469 Test: 3.09834
Epoch: 2520 Train: 0.75925 Test: 3.52977
Epoch: 2580 Train: 0.28567 Test: 3.07376
Epoch: 2640 Train: 0.26038 Test: 3.05539
Epoch: 2700 Train: 0.25734 Test: 3.08465
Epoch: 2760 Train: 0.37850 Test: 3.12376
Epoch: 2820 Train: 0.25412 Test: 3.10322
Epoch: 2880 Train: 0.23349 Test: 3.07261
Epoch: 2940 Train: 0.25790 Test: 3.15792
Epoch: 3000 Train: 0.22028 Test: 3.08200
Epoch: 3060 Train: 0.21553 Test: 3.10548
Epoch: 3120 Train: 0.32482 Test: 3.24816
Epoch: 3180 Train: 0.34741 Test: 3.24145
Epoch: 3240 Train: 0.24676 Test: 3.16103
Epoch: 3300 Train: 0.19551 Test: 3.13999
Epoch: 3360 Train: 0.22633 Test: 3.18738
Epoch: 3420 Train: 0.18790 Test: 3.16058
Epoch: 3480 Train: 0.71646 Test: 3.49848
Epoch: 3540 Train: 0.18107 Test: 3.18035
Epoch: 3600 Train: 0.17682 Test: 3.21142
Epoch: 3660 Train: 0.44860 Test: 3.40821
Epoch: 3720 Train: 0.17102 Test: 3.19563
Epoch: 3780 Train: 0.16707 Test: 3.21958
Epoch: 3840 Train: 0.18872 Test: 3.25685
Epoch: 3900 Train: 0.16129 Test: 3.29426
Epoch 3960: New minimal relative error: 4.44%, model saved.
Epoch: 3960 Train: 0.17624 Test: 3.34105
Epoch: 4020 Train: 0.15569 Test: 3.37775
Epoch: 4080 Train: 0.16562 Test: 3.44625
Epoch: 4140 Train: 0.15427 Test: 3.40503
Epoch: 4200 Train: 0.14807 Test: 3.42411
Epoch 4260: New minimal relative error: 3.45%, model saved.
Epoch: 4260 Train: 0.14549 Test: 3.43253
Epoch: 4320 Train: 0.28083 Test: 3.61787
Epoch: 4380 Train: 0.14172 Test: 3.41174
Epoch: 4440 Train: 0.13893 Test: 3.43319
Epoch: 4500 Train: 0.13670 Test: 3.43649
Epoch: 4560 Train: 0.18660 Test: 3.43099
Epoch: 4620 Train: 0.13298 Test: 3.41949
Epoch: 4680 Train: 0.13089 Test: 3.44082
Epoch: 4740 Train: 0.12893 Test: 3.44454
Epoch: 4800 Train: 0.20819 Test: 3.53194
Epoch: 4860 Train: 0.12868 Test: 3.43510
Epoch: 4920 Train: 0.12363 Test: 3.43213
Epoch: 4980 Train: 0.12186 Test: 3.43153
Epoch: 5040 Train: 0.13937 Test: 3.41545
Epoch: 5100 Train: 0.11896 Test: 3.42834
Epoch: 5160 Train: 0.11721 Test: 3.45338
Epoch: 5220 Train: 0.11566 Test: 3.46808
Epoch: 5280 Train: 0.11416 Test: 3.48046
Epoch: 5340 Train: 0.16098 Test: 3.49346
Epoch: 5400 Train: 0.11160 Test: 3.48238
Epoch: 5460 Train: 0.11017 Test: 3.51386
Epoch: 5520 Train: 0.10882 Test: 3.53222
Epoch: 5580 Train: 0.10751 Test: 3.54812
Epoch: 5640 Train: 0.10622 Test: 3.56439
Epoch: 5700 Train: 0.20526 Test: 3.65943
Epoch: 5760 Train: 0.10385 Test: 3.59491
Epoch: 5820 Train: 0.10260 Test: 3.63685
Epoch: 5880 Train: 0.10141 Test: 3.66427
Epoch: 5940 Train: 0.13820 Test: 3.70889
Epoch 5999: New minimal relative error: 3.07%, model saved.
Epoch: 5999 Train: 0.09963 Test: 3.67696
Training Loss: tensor(0.0996)
Test Loss: tensor(3.6770)
Learned LE: [ 0.8908147  -0.01504013 -4.9944563 ]
True LE: [ 8.6415690e-01  1.3477914e-03 -1.4541009e+01]
Relative Error: [6.853182   7.423528   7.9690804  8.468196   8.916888   9.293594
 9.543083   9.5822525  9.34094    8.945199   8.710989   8.582548
 8.081207   6.5549006  4.339281   3.1408634  2.6066334  1.9285645
 1.9047048  2.2156215  2.444624   2.63673    2.9662187  3.2549648
 3.4596338  3.5261075  3.4094822  3.2059836  3.0295665  2.914742
 2.8586009  2.8786352  3.0185235  3.325736   3.83268    4.499382
 4.538279   4.3483057  4.073846   4.2279487  4.1954374  3.8517735
 3.5582297  2.675834   1.8165672  1.0601804  0.5832337  0.73332924
 1.2610296  1.5348654  1.7853717  2.2819202  2.9151094  3.3930569
 3.7954395  4.276694   4.643792   4.6928782  4.6891036  4.7646346
 4.955626   5.3295755  5.856285   6.416268   6.922383   7.360437
 7.7541733  8.125012   8.462352   8.703588   8.736805   8.448132
 7.9489546  7.634469   7.488714   6.884016   5.062359   2.9267964
 2.09833    1.5917854  1.3821347  1.6273041  1.948642   2.1919143
 2.6296158  3.0572615  3.313201   3.5542817  3.6606312  3.5210316
 3.2603714  2.9762342  2.677666   2.4536834  2.3997939  2.513505
 2.7781074  3.249891   3.932095   3.9840136  3.8693833  3.608244
 3.7840798  3.766568   3.48048    3.1865306  2.3199272  1.5515687
 0.9864559  0.5298533  0.78876364 1.2459459  1.3826861  1.5808095
 2.0896678  2.6647856  3.0908196  3.5460312  3.9558942  4.0470576
 4.053957   4.13944    4.2742014  4.5265026  4.93457    5.4005356
 5.820291   6.1794996  6.508341   6.833539   7.168003   7.5013585
 7.7804914  7.8856697  7.6514935  7.0875382  6.631337   6.392875
 5.657777   3.8192582  1.8537579  1.220101   1.0410681  1.2012424
 1.3827602  1.6758727  2.024297   2.5864007  2.9910321  3.292703
 3.6800854  3.8839872  3.7962193  3.6324475  3.357627   2.8688507
 2.340501   2.0109003  2.0127387  2.2526903  2.6347778  3.284981
 3.48562    3.3685822  3.145238   3.195944   3.3344634  3.1123667
 2.9520276  2.2075105  1.5092217  0.98528314 0.4563971  0.7065839
 1.1076872  1.1664666  1.3205746  1.8165795  2.3326466  2.789513
 3.304929   3.5223212  3.5356238  3.6400392  3.8122947  4.017025
 4.28857    4.592501   4.843663   5.0152245  5.171494   5.399371
 5.718356   6.0871305  6.4540653  6.7698183  6.963453   6.884712
 6.3827934  5.75712    5.3778605  4.5650043  2.839697   1.1136875
 0.73401845 0.9997984  1.152782   1.2030445  1.4720219  1.872508
 2.421598   2.87226    3.2880015  3.7866766  4.056935   4.0446086
 4.0353847  3.92976    3.4965653  2.8689778  2.275309   1.7832965
 1.6160396  1.8999813  2.3840327  3.0352745  2.7811975  2.735556
 2.5208163  2.8619978  2.669587   2.715092   2.2967916  1.6581035
 0.99641055 0.45050615 0.43432248 0.8803143  0.9309506  1.0227748
 1.4491585  1.9855907  2.5131552  2.9699156  3.0079238  3.0460944
 3.2188866  3.4544547  3.7125766  3.9507515  4.102519   4.15345
 4.142352   4.1244855  4.193175   4.440678   4.8457975  5.2744265
 5.619904   5.8439717  5.909587   5.6635118  5.009109   4.414962
 3.7022889  2.2172465  0.72802037 0.72889644 0.9658891  1.2785616
 1.2046499  1.423614   1.7606082  2.2166345  2.75256    3.3050172
 3.782069   4.1164865  4.083272   3.9607782  3.953762   3.7768252
 3.3234909  2.7297392  2.2132838  1.7127184  1.1804676  1.3258097
 1.9209331  2.4098504  2.0981486  2.0317125  2.0329692  2.2041478
 2.2104964  2.3413231  1.9408712  1.2271773  0.6698671  0.14695859
 0.46319306 0.67350894 0.6921396  0.9980149  1.5852938  2.0727482
 2.4669442  2.4597034  2.5210786  2.7053044  2.9420798  3.1810126
 3.3657956  3.4249473  3.3410623  3.2081857  3.1414468  3.1703308
 3.2806098  3.4848108  3.8060758  4.1761227  4.4755535  4.643386
 4.645498   4.343286   3.604744   2.8839066  1.9367135  0.6447036
 1.0702493  1.0366238  1.3055305  1.3768419  1.4821191  1.7586917
 2.096432   2.5426733  3.2233782  3.7024953  4.0839834  4.240641
 4.0161424  3.9216871  3.9410417  3.8266253  3.4934618  2.8227508
 2.1012828  1.5963694  1.1010802  0.6427321  1.3262136  1.9289324
 1.5252213  1.3948746  1.476466   1.581537   1.7174091  2.0015798
 1.6590585  1.0112714  0.5900753  0.14121428 0.22949849 0.3562139
 0.4893701  0.95163614 1.4761105  1.7978142  1.8925859  1.8982822
 2.0401568  2.2543006  2.4391031  2.5401878  2.5955486  2.5241332
 2.3311539  2.159951   2.1594527  2.322551   2.4942775  2.5773523
 2.6477988  2.8480737  3.1510782  3.3810523  3.4154215  3.140572
 2.3846319  1.6298866  1.0511357  0.53169924 1.369847   1.457929
 1.5881104  1.5691919  1.704564   2.0957365 ]
