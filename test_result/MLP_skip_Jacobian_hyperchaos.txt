time_step: 0.001
lr: 0.001
weight_decay: 0.0005
num_epoch: 20000
num_train: 10000
num_test: 8000
num_val: 3000
num_trans: 0
loss_type: Jacobian
dyn_sys: hyperchaos
model_type: MLP_skip
s: 0.2
n_hidden: 512
n_layers: 3
reg_param: 500
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 6192677.000000000 Test: 4224691.000000000
Epoch 0: New minimal relative error: 99.57%, model saved.
Epoch: 200 Train: 775561.937500000 Test: 780230.375000000
Epoch 200: New minimal relative error: 50.21%, model saved.
Epoch: 400 Train: 715343.625000000 Test: 765045.687500000
Epoch 400: New minimal relative error: 42.23%, model saved.
Epoch: 600 Train: 617008.187500000 Test: 724154.875000000
Epoch 600: New minimal relative error: 42.08%, model saved.
Epoch: 800 Train: 439528.875000000 Test: 642113.187500000
Epoch 800: New minimal relative error: 32.93%, model saved.
Epoch: 1000 Train: 273675.093750000 Test: 530865.625000000
Epoch 1000: New minimal relative error: 21.23%, model saved.
Epoch: 1200 Train: 171988.625000000 Test: 441040.625000000
Epoch 1200: New minimal relative error: 15.03%, model saved.
Epoch: 1400 Train: 116367.218750000 Test: 376506.843750000
Epoch 1400: New minimal relative error: 12.97%, model saved.
Epoch: 1600 Train: 81693.828125000 Test: 331014.875000000
Epoch 1600: New minimal relative error: 9.02%, model saved.
Epoch: 1800 Train: 59820.531250000 Test: 288798.406250000
Epoch: 2000 Train: 46480.781250000 Test: 260580.921875000
Epoch 2000: New minimal relative error: 5.02%, model saved.
Epoch: 2200 Train: 38665.628906250 Test: 243366.890625000
Epoch: 2400 Train: 31165.738281250 Test: 227581.359375000
Epoch 2400: New minimal relative error: 4.61%, model saved.
Epoch: 2600 Train: 27337.718750000 Test: 217981.296875000
Epoch: 2800 Train: 33027.929687500 Test: 222888.609375000
Epoch: 3000 Train: 37167.675781250 Test: 212388.406250000
Epoch: 3200 Train: 31818.621093750 Test: 212312.906250000
Epoch: 3400 Train: 17851.992187500 Test: 191076.781250000
Epoch: 3600 Train: 15247.519531250 Test: 180477.625000000
Epoch 3600: New minimal relative error: 2.92%, model saved.
Epoch: 3800 Train: 14090.574218750 Test: 174539.031250000
Epoch 3800: New minimal relative error: 2.09%, model saved.
Epoch: 4000 Train: 12956.822265625 Test: 170080.250000000
Epoch: 4200 Train: 11931.537109375 Test: 166106.296875000
Epoch: 4400 Train: 11518.120117188 Test: 163289.984375000
Epoch: 4600 Train: 12394.569335938 Test: 162415.718750000
Epoch: 4800 Train: 10398.779296875 Test: 156854.250000000
Epoch: 5000 Train: 9698.873046875 Test: 152848.890625000
Epoch: 5200 Train: 12956.432617188 Test: 150713.109375000
Epoch: 5400 Train: 10303.142578125 Test: 146429.296875000
Epoch: 5600 Train: 8221.660156250 Test: 144416.750000000
Epoch: 5800 Train: 7828.673339844 Test: 142273.109375000
Epoch: 6000 Train: 7772.317382812 Test: 139695.640625000
Epoch 6000: New minimal relative error: 1.74%, model saved.
Epoch: 6200 Train: 7207.452636719 Test: 137097.328125000
Epoch: 6400 Train: 6936.987304688 Test: 135302.671875000
Epoch: 6600 Train: 6733.875000000 Test: 133790.687500000
Epoch: 6800 Train: 7413.803710938 Test: 133428.625000000
Epoch: 7000 Train: 6315.388183594 Test: 131210.906250000
Epoch: 7200 Train: 5993.510742188 Test: 130585.820312500
Epoch: 7400 Train: 6075.847167969 Test: 128855.992187500
Epoch: 7600 Train: 5695.312011719 Test: 128961.828125000
Epoch: 7800 Train: 5533.255371094 Test: 128499.210937500
Epoch 7800: New minimal relative error: 1.21%, model saved.
Epoch: 8000 Train: 5391.956542969 Test: 129842.710937500
Epoch: 8200 Train: 5244.269042969 Test: 136357.921875000
Epoch 8200: New minimal relative error: 1.16%, model saved.
Epoch: 8400 Train: 5128.621582031 Test: 136200.500000000
Epoch: 8600 Train: 4917.317382812 Test: 133308.171875000
Epoch: 8800 Train: 4792.661132812 Test: 129461.304687500
Epoch: 9000 Train: 4669.099609375 Test: 126669.601562500
Epoch: 9200 Train: 4576.874023438 Test: 125370.320312500
Epoch 9200: New minimal relative error: 1.09%, model saved.
Epoch: 9400 Train: 4645.674804688 Test: 124936.039062500
Epoch: 9600 Train: 4656.031738281 Test: 124407.976562500
Epoch: 9800 Train: 4529.605468750 Test: 122960.125000000
Epoch: 10000 Train: 4191.091308594 Test: 122497.835937500
Epoch: 10200 Train: 4105.817382812 Test: 120918.875000000
Epoch: 10400 Train: 4174.592285156 Test: 118507.937500000
Epoch: 10600 Train: 3997.855224609 Test: 117205.203125000
Epoch: 10800 Train: 3854.830566406 Test: 115469.890625000
Epoch: 11000 Train: 3788.402099609 Test: 113374.625000000
Epoch 11000: New minimal relative error: 1.02%, model saved.
Epoch: 11200 Train: 3934.729492188 Test: 112875.460937500
Epoch: 11400 Train: 3916.046142578 Test: 113112.718750000
Epoch: 11600 Train: 3629.604980469 Test: 111938.351562500
Epoch: 11800 Train: 3594.022460938 Test: 112164.414062500
Epoch: 12000 Train: 3539.421630859 Test: 111904.976562500
Epoch: 12200 Train: 3473.263916016 Test: 112729.843750000
Epoch: 12400 Train: 3911.297607422 Test: 112052.171875000
Epoch: 12600 Train: 3422.127685547 Test: 112285.859375000
Epoch: 12800 Train: 3383.117187500 Test: 117184.625000000
Epoch 12800: New minimal relative error: 0.95%, model saved.
Epoch: 13000 Train: 3359.966796875 Test: 116721.867187500
Epoch: 13200 Train: 3573.917236328 Test: 115565.445312500
Epoch: 13400 Train: 3387.636962891 Test: 114059.875000000
Epoch: 13600 Train: 3249.412597656 Test: 111917.796875000
Epoch: 13800 Train: 3462.723632812 Test: 110459.226562500
Epoch: 14000 Train: 3584.562988281 Test: 108992.625000000
Epoch: 14200 Train: 3108.706542969 Test: 108085.703125000
Epoch: 14400 Train: 3082.809570312 Test: 108299.703125000
Epoch: 14600 Train: 3050.025878906 Test: 108462.546875000
Epoch: 14800 Train: 3454.252929688 Test: 109671.453125000
Epoch: 15000 Train: 3005.368164062 Test: 108777.820312500
Epoch: 15200 Train: 2977.473632812 Test: 108202.085937500
Epoch: 15400 Train: 2948.435791016 Test: 107415.679687500
Epoch: 15600 Train: 2889.642089844 Test: 107047.937500000
Epoch: 15800 Train: 2847.061767578 Test: 107265.125000000
Epoch: 16000 Train: 2975.493408203 Test: 107326.750000000
Epoch: 16200 Train: 2836.302734375 Test: 107172.859375000
Epoch: 16400 Train: 2806.120605469 Test: 106989.078125000
Epoch: 16600 Train: 2788.797851562 Test: 106891.218750000
Epoch: 16800 Train: 2796.734130859 Test: 106697.164062500
Epoch 16800: New minimal relative error: 0.90%, model saved.
Epoch: 17000 Train: 2757.449462891 Test: 106627.796875000
Epoch: 17200 Train: 2755.347167969 Test: 106692.570312500
Epoch: 17400 Train: 2711.900634766 Test: 106091.609375000
Epoch: 17600 Train: 2727.995849609 Test: 106310.281250000
Epoch: 17800 Train: 2699.601562500 Test: 106142.546875000
Epoch: 18000 Train: 2699.021484375 Test: 106000.632812500
Epoch: 18200 Train: 2679.214111328 Test: 106201.453125000
Epoch: 18400 Train: 2630.589599609 Test: 105313.757812500
Epoch: 18600 Train: 2606.735351562 Test: 104344.789062500
Epoch 18600: New minimal relative error: 0.75%, model saved.
Epoch: 18800 Train: 2565.762451172 Test: 104273.671875000
Epoch: 19000 Train: 2550.438232422 Test: 104194.921875000
Epoch: 19200 Train: 2536.300292969 Test: 104138.914062500
Epoch: 19400 Train: 2516.410888672 Test: 104201.914062500
Epoch: 19600 Train: 2509.009521484 Test: 104301.375000000
Epoch: 19800 Train: 2471.896484375 Test: 104001.500000000
Epoch: 19999 Train: 2431.338867188 Test: 103438.210937500
Training Loss: tensor(2431.3389)
Test Loss: tensor(103438.2109)
True Mean x: tensor(-0.1886, device='cuda:0')
Learned Mean x: tensor(-0.1181, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(2044.3016, device='cuda:0')
Learned Var x: tensor(2270.2839, device='cuda:0', grad_fn=<VarBackward0>)
True Mean z: tensor(-0.0110, device='cuda:0')
Learned Mean z: tensor(-1.4986, device='cuda:0', grad_fn=<MeanBackward0>)
True Var z: tensor(1891.5219, device='cuda:0')
Learned Var z: tensor(2064.6914, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(4.7165)
Jacobian term Test Loss: tensor(19.4323)
Learned LE: [  4.3789105   -0.16172636 -19.838627   -48.30655   ]
True LE: [ 4.0039463e+00  8.2440469e-03 -1.9997406e+01 -4.8020523e+01]
Relative Error: [0.6602282  0.5086449  0.5099751  ... 0.41330922 0.36731336 0.27854753]
Norm Diff:: tensor(0.5258)

05_20_03_25_32_