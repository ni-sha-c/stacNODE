time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 10000
num_test: 8000
num_val: 3000
num_trans: 0
loss_type: Jacobian
dyn_sys: tilted_tent_map
model_type: MLP_skip
s: 0.8
n_hidden: 512
n_layers: 3
reg_param: 500
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 22106.808593750 Test: 2460.694091797
Epoch 0: New minimal relative error: 2460.69%, model saved.
Epoch: 100 Train: 483.883178711 Test: 5.048384666
Epoch 100: New minimal relative error: 5.05%, model saved.
Epoch: 200 Train: 129.134384155 Test: 18.880643845
Epoch: 300 Train: 185.463272095 Test: 27.546945572
Epoch: 400 Train: 39.504375458 Test: 0.020403175
Epoch 400: New minimal relative error: 0.02%, model saved.
Epoch: 500 Train: 130.312362671 Test: 0.202545017
Epoch: 600 Train: 30.919254303 Test: 0.009886789
Epoch 600: New minimal relative error: 0.01%, model saved.
Epoch: 700 Train: 159.674804688 Test: 8.760356903
Epoch: 800 Train: 28.553516388 Test: 0.012920251
Epoch: 900 Train: 22.675388336 Test: 0.057317898
Epoch: 1000 Train: 38.544929504 Test: 0.021377314
Epoch: 1100 Train: 88.725387573 Test: 0.034338631
Epoch: 1200 Train: 213.485275269 Test: 16.390956879
Epoch: 1300 Train: 25.694162369 Test: 0.013039135
Epoch: 1400 Train: 8.392531395 Test: 0.004000943
Epoch 1400: New minimal relative error: 0.00%, model saved.
Epoch: 1500 Train: 85.807655334 Test: 0.016056402
Epoch: 1600 Train: 39.310207367 Test: 0.009303991
Epoch: 1700 Train: 37.441974640 Test: 0.036985386
Epoch: 1800 Train: 116.828666687 Test: 0.048585087
Epoch: 1900 Train: 14.914544106 Test: 0.064614072
Epoch: 2000 Train: 35.045883179 Test: 0.006321220
Epoch: 2100 Train: 10.491250992 Test: 0.151259169
Epoch: 2200 Train: 72.984642029 Test: 0.094921015
Epoch: 2300 Train: 37.147045135 Test: 0.005370020
Epoch: 2400 Train: 37.675685883 Test: 0.006360442
Epoch: 2500 Train: 36.484497070 Test: 0.004198789
Epoch: 2600 Train: 35.972969055 Test: 0.002602006
Epoch 2600: New minimal relative error: 0.00%, model saved.
Epoch: 2700 Train: 35.900943756 Test: 0.004826340
Epoch: 2800 Train: 35.332088470 Test: 0.003227493
Epoch: 2900 Train: 34.563964844 Test: 0.003135745
Epoch: 3000 Train: 34.461360931 Test: 0.002312476
Epoch 3000: New minimal relative error: 0.00%, model saved.
Epoch: 3100 Train: 34.624973297 Test: 0.002653718
Epoch: 3200 Train: 33.493843079 Test: 0.001869630
Epoch 3200: New minimal relative error: 0.00%, model saved.
Epoch: 3300 Train: 32.047542572 Test: 0.006544021
Epoch: 3400 Train: 31.587795258 Test: 0.021275023
Epoch: 3500 Train: 32.026443481 Test: 0.302520245
Epoch: 3600 Train: 31.262804031 Test: 0.001971361
Epoch: 3700 Train: 31.311428070 Test: 0.002131400
Epoch: 3800 Train: 31.185935974 Test: 0.013715856
Epoch: 3900 Train: 31.547315598 Test: 0.032973934
Epoch: 4000 Train: 30.940856934 Test: 0.002542839
Epoch: 4100 Train: 30.107460022 Test: 0.003155884
Epoch: 4200 Train: 29.509069443 Test: 0.002375908
Epoch: 4300 Train: 29.358819962 Test: 0.005986162
Epoch: 4400 Train: 28.958328247 Test: 0.002959382
Epoch: 4500 Train: 32.927425385 Test: 0.172633246
Epoch: 4600 Train: 28.450563431 Test: 0.002296888
Epoch: 4700 Train: 29.950437546 Test: 0.032783847
Epoch: 4800 Train: 28.325330734 Test: 0.003456215
Epoch: 4900 Train: 32.043354034 Test: 0.010936959
Epoch: 5000 Train: 29.544773102 Test: 0.033056851
Epoch: 5100 Train: 28.957008362 Test: 0.991750717
Epoch: 5200 Train: 28.563102722 Test: 0.002708202
Epoch: 5300 Train: 29.555198669 Test: 0.002062670
Epoch: 5400 Train: 29.403350830 Test: 0.004019804
Epoch: 5500 Train: 31.026746750 Test: 0.002080415
Epoch: 5600 Train: 33.635231018 Test: 0.003200134
Epoch: 5700 Train: 28.261444092 Test: 0.058521554
Epoch: 5800 Train: 30.391950607 Test: 0.004307003
Epoch: 5900 Train: 29.404542923 Test: 0.002655700
Epoch: 6000 Train: 29.255619049 Test: 1.757164955
Epoch: 6100 Train: 30.141990662 Test: 0.004653232
Epoch: 6200 Train: 27.964735031 Test: 0.002838520
Epoch: 6300 Train: 35.755496979 Test: 1.395196438
Epoch: 6400 Train: 29.023929596 Test: 0.003425183
Epoch: 6500 Train: 40.159187317 Test: 0.004158034
Epoch: 6600 Train: 38.050415039 Test: 0.013115320
Epoch: 6700 Train: 41.079658508 Test: 0.014123227
Epoch: 6800 Train: 18.413509369 Test: 0.725673914
Epoch: 6900 Train: 30.481781006 Test: 0.002272497
Epoch: 7000 Train: 31.644958496 Test: 0.065908633
Epoch: 7100 Train: 32.966827393 Test: 0.002570663
Epoch: 7200 Train: 30.179628372 Test: 0.003556091
Epoch: 7300 Train: 28.819135666 Test: 0.001981950
Epoch: 7400 Train: 29.902286530 Test: 0.005742637
Epoch: 7500 Train: 26.671041489 Test: 0.002533468
Epoch: 7600 Train: 37.175827026 Test: 0.006149443
Epoch: 7700 Train: 27.277793884 Test: 0.157607362
Epoch: 7800 Train: 40.192676544 Test: 0.708221734
Epoch: 7900 Train: 30.600147247 Test: 0.008109493
Epoch: 8000 Train: 30.545543671 Test: 0.004183604
Epoch: 8100 Train: 34.131439209 Test: 0.004997733
Epoch: 8200 Train: 29.491235733 Test: 0.007307774
Epoch: 8300 Train: 26.498987198 Test: 0.009510216
Epoch: 8400 Train: 28.728244781 Test: 0.003827305
Epoch: 8500 Train: 29.542989731 Test: 0.002892681
Epoch: 8600 Train: 29.825237274 Test: 0.067508884
Epoch: 8700 Train: 29.981344223 Test: 0.003167460
Epoch: 8800 Train: 29.298522949 Test: 0.007889511
Epoch: 8900 Train: 28.460279465 Test: 0.002289531
Epoch: 9000 Train: 27.584936142 Test: 0.001757332
Epoch 9000: New minimal relative error: 0.00%, model saved.
Epoch: 9100 Train: 48.968738556 Test: 0.134804145
Epoch: 9200 Train: 38.969841003 Test: 0.012492130
Epoch: 9300 Train: 46.492874146 Test: 0.012364988
Epoch: 9400 Train: 38.475578308 Test: 0.018475732
Epoch: 9500 Train: 39.113498688 Test: 0.005633636
Epoch: 9600 Train: 21.173038483 Test: 0.005947715
Epoch: 9700 Train: 33.914264679 Test: 0.183111027
Epoch: 9800 Train: 32.848335266 Test: 0.019260213
Epoch: 9900 Train: 31.063161850 Test: 0.013164884
Epoch: 9999 Train: 35.100570679 Test: 0.004765571
Training Loss: tensor(35.1006)
Test Loss: tensor(0.0048)
True Mean x: tensor(0.9444, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(1.0526, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(0.3506, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(0.3053, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(0.0702)
Jacobian term Test Loss: tensor(0.0856)
Learned LE: [[0.34024802]]
True LE: tensor([[0.3188]], device='cuda:0')
05_19_14_23_24_
