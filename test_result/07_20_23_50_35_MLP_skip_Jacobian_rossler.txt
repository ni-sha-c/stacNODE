time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 10000
num_test: 8000
num_val: 3000
num_trans: 0
loss_type: Jacobian
dyn_sys: rossler
model_type: MLP_skip
s: 0.2
n_hidden: 512
n_layers: 2
reg_param: 500
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 4.398026466 Test: 4.769734383
Epoch 0: New minimal relative error: 89.31%, model saved.
Epoch: 100 Train: 0.399786621 Test: 0.557765841
Epoch 100: New minimal relative error: 22.00%, model saved.
Epoch: 200 Train: 0.203879192 Test: 0.301858574
Epoch: 300 Train: 0.170247853 Test: 0.254379451
Epoch: 400 Train: 0.150079563 Test: 0.229212999
Epoch 400: New minimal relative error: 18.98%, model saved.
Epoch: 500 Train: 0.136166587 Test: 0.205527410
Epoch 500: New minimal relative error: 7.22%, model saved.
Epoch: 600 Train: 0.131900921 Test: 0.198483199
Epoch: 700 Train: 0.106896840 Test: 0.165937647
Epoch: 800 Train: 0.115154706 Test: 0.168356165
Epoch: 900 Train: 0.093109362 Test: 0.160504058
Epoch 900: New minimal relative error: 4.17%, model saved.
Epoch: 1000 Train: 0.091224208 Test: 0.152852520
Epoch: 1100 Train: 0.094925933 Test: 0.161821395
Epoch: 1200 Train: 0.103251725 Test: 0.159922078
Epoch: 1300 Train: 0.087740384 Test: 0.154908732
Epoch: 1400 Train: 0.094498910 Test: 0.156986028
Epoch: 1500 Train: 0.092189610 Test: 0.162446052
Epoch: 1600 Train: 0.084851697 Test: 0.140578046
Epoch: 1700 Train: 0.082008570 Test: 0.123582691
Epoch: 1800 Train: 0.078018405 Test: 0.117751509
Epoch: 1900 Train: 0.063079409 Test: 0.097788997
Epoch: 2000 Train: 0.070163198 Test: 0.113992035
Epoch: 2100 Train: 0.061005183 Test: 0.101500183
Epoch: 2200 Train: 0.053405922 Test: 0.085999079
Epoch: 2300 Train: 0.042383753 Test: 0.069746390
Epoch: 2400 Train: 0.045674823 Test: 0.074369699
Epoch: 2500 Train: 0.043117404 Test: 0.067111336
Epoch 2500: New minimal relative error: 1.83%, model saved.
Epoch: 2600 Train: 0.041727062 Test: 0.064894050
Epoch: 2700 Train: 0.037755210 Test: 0.060064081
Epoch: 2800 Train: 0.032927729 Test: 0.053423394
Epoch: 2900 Train: 0.035270751 Test: 0.054208234
Epoch: 3000 Train: 0.034959696 Test: 0.057293016
Epoch: 3100 Train: 0.033834107 Test: 0.050868869
Epoch: 3200 Train: 0.036457416 Test: 0.053538501
Epoch: 3300 Train: 0.035665125 Test: 0.054970451
Epoch: 3400 Train: 0.037762932 Test: 0.057706647
Epoch: 3500 Train: 0.033968959 Test: 0.054235104
Epoch: 3600 Train: 0.032124177 Test: 0.052035615
Epoch: 3700 Train: 0.029627221 Test: 0.047688559
Epoch: 3800 Train: 0.027685493 Test: 0.044131145
Epoch: 3900 Train: 0.026668752 Test: 0.042410605
Epoch: 4000 Train: 0.029268116 Test: 0.047249284
Epoch: 4100 Train: 0.028617145 Test: 0.044296693
Epoch: 4200 Train: 0.028141912 Test: 0.046021003
Epoch: 4300 Train: 0.025027705 Test: 0.038191218
Epoch: 4400 Train: 0.023986025 Test: 0.039902702
Epoch: 4500 Train: 0.025493370 Test: 0.042066935
Epoch: 4600 Train: 0.022249466 Test: 0.036656998
Epoch: 4700 Train: 0.019751906 Test: 0.032253325
Epoch: 4800 Train: 0.019668583 Test: 0.032035455
Epoch: 4900 Train: 0.020455910 Test: 0.035474755
Epoch: 5000 Train: 0.019628635 Test: 0.033994328
Epoch: 5100 Train: 0.020648068 Test: 0.035702910
Epoch: 5200 Train: 0.022447044 Test: 0.038054451
Epoch: 5300 Train: 0.021934118 Test: 0.037005238
Epoch: 5400 Train: 0.020114137 Test: 0.034890436
Epoch: 5500 Train: 0.023088487 Test: 0.038338613
Epoch: 5600 Train: 0.021682367 Test: 0.036019914
Epoch: 5700 Train: 0.021607596 Test: 0.035095185
Epoch: 5800 Train: 0.025158571 Test: 0.040575311
Epoch: 5900 Train: 0.025824079 Test: 0.041821044
Epoch: 6000 Train: 0.023755621 Test: 0.038256824
Epoch: 6100 Train: 0.021918267 Test: 0.034573521
Epoch: 6200 Train: 0.024780080 Test: 0.037688047
Epoch: 6300 Train: 0.021860395 Test: 0.033266954
Epoch: 6400 Train: 0.020275060 Test: 0.031491648
Epoch 6400: New minimal relative error: 1.42%, model saved.
Epoch: 6500 Train: 0.020510215 Test: 0.034599312
Epoch: 6600 Train: 0.019948559 Test: 0.033485286
Epoch: 6700 Train: 0.020920686 Test: 0.036214378
Epoch: 6800 Train: 0.021653254 Test: 0.036225300
Epoch: 6900 Train: 0.022294840 Test: 0.038389634
Epoch: 7000 Train: 0.020345550 Test: 0.033906288
Epoch: 7100 Train: 0.019331021 Test: 0.031538785
Epoch: 7200 Train: 0.018881608 Test: 0.030913016
Epoch: 7300 Train: 0.018726069 Test: 0.030959373
Epoch: 7400 Train: 0.018583219 Test: 0.029984118
Epoch: 7500 Train: 0.020106131 Test: 0.032367777
Epoch: 7600 Train: 0.022906659 Test: 0.037505236
Epoch: 7700 Train: 0.020695237 Test: 0.033592153
Epoch: 7800 Train: 0.023015823 Test: 0.036703955
Epoch: 7900 Train: 0.021852585 Test: 0.035965573
Epoch: 8000 Train: 0.021817496 Test: 0.035721932
Epoch 8000: New minimal relative error: 1.39%, model saved.
Epoch: 8100 Train: 0.018107295 Test: 0.029496988
Epoch: 8200 Train: 0.020672875 Test: 0.032968648
Epoch 8200: New minimal relative error: 1.11%, model saved.
Epoch: 8300 Train: 0.018768588 Test: 0.031035468
Epoch: 8400 Train: 0.016048800 Test: 0.026524208
Epoch: 8500 Train: 0.015158499 Test: 0.025248008
Epoch: 8600 Train: 0.013269356 Test: 0.021201661
Epoch: 8700 Train: 0.015159085 Test: 0.025210109
Epoch: 8800 Train: 0.014401514 Test: 0.021899134
Epoch: 8900 Train: 0.014490544 Test: 0.024200417
Epoch: 9000 Train: 0.013328554 Test: 0.021374721
Epoch: 9100 Train: 0.012432505 Test: 0.021016231
Epoch: 9200 Train: 0.011850614 Test: 0.019574022
Epoch: 9300 Train: 0.012901356 Test: 0.021683913
Epoch: 9400 Train: 0.013358241 Test: 0.020485256
Epoch: 9500 Train: 0.013233907 Test: 0.021453215
Epoch: 9600 Train: 0.012369381 Test: 0.020296056
Epoch: 9700 Train: 0.012604326 Test: 0.021304104
Epoch: 9800 Train: 0.012096420 Test: 0.019729543
Epoch: 9900 Train: 0.011951506 Test: 0.017812504
Epoch: 9999 Train: 0.012281625 Test: 0.018133901
Training Loss: tensor(0.0123)
Test Loss: tensor(0.0181)
True Mean x: tensor(0.1316, device='cuda:0')
Learned Mean x: tensor(0.1756, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(24.6191, device='cuda:0')
Learned Var x: tensor(23.2974, device='cuda:0', grad_fn=<VarBackward0>)
True Mean z: tensor(0.8011, device='cuda:0')
Learned Mean z: tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>)
True Var z: tensor(7.8988, device='cuda:0')
Learned Var z: tensor(8.1016, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(2.4550e-05)
Jacobian term Test Loss: tensor(3.6244e-05)
Learned LE: [ 0.07797597  0.01508634 -5.4108605 ]
True LE: [ 6.2638000e-02  3.3546316e-03 -5.4428802e+00]
Relative Error: [0.25983    0.24439584 0.23313695 ... 0.64180374 0.61629784 0.60880554]
Norm Diff:: tensor(0.0374)
