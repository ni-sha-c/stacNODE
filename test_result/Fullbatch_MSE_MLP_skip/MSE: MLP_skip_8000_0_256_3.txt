time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 0
loss_type: MSE
dyn_sys: lorenz
model_type: MLP_skip
n_hidden: 256
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 100.39%, model saved.
Epoch: 0 Train: 3903.58472 Test: 3958.51880
Epoch 80: New minimal relative error: 94.61%, model saved.
Epoch: 80 Train: 310.16360 Test: 371.36139
Epoch 160: New minimal relative error: 73.39%, model saved.
Epoch: 160 Train: 42.39538 Test: 50.76918
Epoch 240: New minimal relative error: 17.32%, model saved.
Epoch: 240 Train: 20.33459 Test: 20.76059
Epoch: 320 Train: 10.27277 Test: 13.12502
Epoch: 400 Train: 7.61791 Test: 10.44625
Epoch 480: New minimal relative error: 9.76%, model saved.
Epoch: 480 Train: 6.33646 Test: 9.02663
Epoch: 560 Train: 5.50287 Test: 7.76014
Epoch: 640 Train: 4.65800 Test: 6.85986
Epoch: 720 Train: 4.08541 Test: 7.37769
Epoch: 800 Train: 3.58128 Test: 5.48232
Epoch: 880 Train: 3.17047 Test: 5.04273
Epoch: 960 Train: 3.08999 Test: 4.67290
Epoch: 1040 Train: 2.55797 Test: 4.29983
Epoch: 1120 Train: 7.92575 Test: 8.50087
Epoch: 1200 Train: 1.98695 Test: 3.50588
Epoch: 1280 Train: 1.78932 Test: 3.31443
Epoch: 1360 Train: 1.78936 Test: 3.14930
Epoch: 1440 Train: 1.73660 Test: 3.44562
Epoch: 1520 Train: 1.30451 Test: 2.61531
Epoch: 1600 Train: 5.65842 Test: 5.72282
Epoch: 1680 Train: 1.09782 Test: 2.33279
Epoch 1760: New minimal relative error: 6.17%, model saved.
Epoch: 1760 Train: 1.05608 Test: 2.20137
Epoch: 1840 Train: 1.00706 Test: 2.09494
Epoch: 1920 Train: 0.99513 Test: 2.17216
Epoch 2000: New minimal relative error: 5.78%, model saved.
Epoch: 2000 Train: 0.82751 Test: 1.89322
Epoch: 2080 Train: 0.78198 Test: 1.83252
Epoch: 2160 Train: 1.13409 Test: 1.94393
Epoch: 2240 Train: 0.73571 Test: 1.68176
Epoch 2320: New minimal relative error: 4.90%, model saved.
Epoch: 2320 Train: 0.74175 Test: 1.80142
Epoch: 2400 Train: 0.65288 Test: 1.59822
Epoch: 2480 Train: 0.69080 Test: 1.67493
Epoch 2560: New minimal relative error: 4.30%, model saved.
Epoch: 2560 Train: 0.56684 Test: 1.46203
Epoch: 2640 Train: 1.06441 Test: 2.26737
Epoch: 2720 Train: 0.52326 Test: 1.38211
Epoch: 2800 Train: 0.54349 Test: 1.34818
Epoch: 2880 Train: 0.84455 Test: 1.84733
Epoch: 2960 Train: 0.52511 Test: 1.28195
Epoch: 3040 Train: 0.50884 Test: 1.25627
Epoch: 3120 Train: 0.48773 Test: 1.22647
Epoch: 3200 Train: 0.54824 Test: 1.39455
Epoch: 3280 Train: 0.40805 Test: 1.17436
Epoch: 3360 Train: 0.41380 Test: 1.12825
Epoch: 3440 Train: 0.68680 Test: 1.57618
Epoch: 3520 Train: 0.41230 Test: 1.15452
Epoch: 3600 Train: 0.42141 Test: 1.09401
Epoch: 3680 Train: 0.38940 Test: 1.05531
Epoch: 3760 Train: 0.36917 Test: 1.07361
Epoch: 3840 Train: 0.43927 Test: 1.06867
Epoch: 3920 Train: 0.36596 Test: 1.01723
Epoch: 4000 Train: 0.36412 Test: 1.00383
Epoch: 4080 Train: 0.30531 Test: 0.98204
Epoch 4160: New minimal relative error: 3.35%, model saved.
Epoch: 4160 Train: 0.31009 Test: 0.96126
Epoch: 4240 Train: 0.36150 Test: 1.06504
Epoch: 4320 Train: 0.31312 Test: 0.95187
Epoch: 4400 Train: 0.36910 Test: 1.06029
Epoch: 4480 Train: 0.35568 Test: 0.97392
Epoch: 4560 Train: 0.27514 Test: 0.89753
Epoch: 4640 Train: 0.26641 Test: 0.90321
Epoch: 4720 Train: 0.26332 Test: 0.87136
Epoch: 4800 Train: 0.28188 Test: 0.87492
Epoch: 4880 Train: 0.28840 Test: 0.90533
Epoch: 4960 Train: 0.26416 Test: 0.84791
Epoch: 5040 Train: 0.25154 Test: 0.83436
Epoch 5120: New minimal relative error: 3.13%, model saved.
Epoch: 5120 Train: 0.24537 Test: 0.82111
Epoch: 5200 Train: 0.24425 Test: 0.81430
Epoch: 5280 Train: 0.24043 Test: 0.80622
Epoch: 5360 Train: 0.27809 Test: 0.91082
Epoch: 5440 Train: 0.22731 Test: 0.79044
Epoch: 5520 Train: 0.22047 Test: 0.78734
Epoch: 5600 Train: 0.21683 Test: 0.76422
Epoch: 5680 Train: 0.21357 Test: 0.75983
Epoch: 5760 Train: 0.21788 Test: 0.76523
Epoch: 5840 Train: 0.21884 Test: 0.76038
Epoch: 5920 Train: 0.20457 Test: 0.73065
Epoch: 6000 Train: 0.20272 Test: 0.71393
Epoch: 6080 Train: 0.20068 Test: 0.71392
Epoch: 6160 Train: 0.33931 Test: 0.85365
Epoch: 6240 Train: 0.19299 Test: 0.69824
Epoch: 6320 Train: 0.22614 Test: 0.69563
Epoch: 6400 Train: 0.18806 Test: 0.68765
Epoch: 6480 Train: 0.18882 Test: 0.69493
Epoch: 6560 Train: 0.18353 Test: 0.67831
Epoch: 6640 Train: 0.18275 Test: 0.67465
Epoch: 6720 Train: 0.17921 Test: 0.66634
Epoch: 6800 Train: 0.17740 Test: 0.66388
Epoch: 6880 Train: 0.17508 Test: 0.65757
Epoch: 6960 Train: 0.17500 Test: 0.65756
Epoch: 7040 Train: 0.17169 Test: 0.65372
Epoch: 7120 Train: 0.17861 Test: 0.66588
Epoch: 7200 Train: 0.16758 Test: 0.63913
Epoch: 7280 Train: 0.16895 Test: 0.64467
Epoch 7360: New minimal relative error: 2.86%, model saved.
Epoch: 7360 Train: 0.17013 Test: 0.63764
Epoch: 7440 Train: 0.16258 Test: 0.62219
Epoch: 7520 Train: 0.21559 Test: 0.67735
Epoch: 7600 Train: 0.15886 Test: 0.61526
Epoch: 7680 Train: 0.15852 Test: 0.61328
Epoch: 7760 Train: 0.15939 Test: 0.60553
Epoch: 7840 Train: 0.15413 Test: 0.60358
Epoch: 7920 Train: 0.15262 Test: 0.60074
Epoch: 7999 Train: 0.15127 Test: 0.59679
Training Loss: tensor(0.1513)
Test Loss: tensor(0.5968)
Learned LE: [ 0.7886132   0.06569006 -4.4802027 ]
True LE: [ 8.6596406e-01 -2.6797608e-03 -1.4538744e+01]
Relative Error: [4.277719  3.9533052 3.5424604 3.223476  2.9987617 2.876609  2.9040825
 3.1094913 3.496168  4.0452833 4.6169257 5.2280936 5.8634796 6.5222516
 7.1748824 7.7920012 8.178926  8.469802  8.665993  8.691112  8.648448
 8.614865  8.635485  8.693465  8.379602  7.1433334 6.0908694 5.2265544
 4.551857  3.7854798 3.2257068 2.8567276 2.6397994 2.5448315 2.484429
 2.3491766 2.292574  2.302418  2.3671272 2.7514288 3.3548143 4.1873164
 5.1763573 6.318949  7.5472393 8.069391  8.415719  8.723099  8.898894
 8.65544   8.407779  8.190961  7.6136374 6.750021  6.0199866 5.463849
 4.892882  4.4091964 4.090911  3.904348  3.8244934 3.843791  3.7718408
 3.3444052 2.992934  2.7033281 2.4869084 2.3763342 2.417111  2.660607
 3.1030784 3.709776  4.374741  5.042964  5.7068543 6.3789673 7.029396
 7.613153  7.9618745 8.214156  8.29165   8.224093  8.131229  8.058887
 7.8600383 7.7939286 7.297263  6.134178  5.1590333 4.371231  3.6545422
 3.0344276 2.6320105 2.390463  2.2564573 2.2000675 2.2221522 2.1615345
 2.1393492 2.1735468 2.2536304 2.5499997 3.1441185 3.9753172 4.962762
 6.092715  7.3014073 7.7666984 8.061832  8.31814   8.37995   8.095052
 7.8231187 7.560938  6.8928046 6.075836  5.422711  4.81804   4.2724977
 3.9172595 3.7042289 3.5908313 3.55546   3.5993304 3.2699726 2.9268591
 2.620049  2.339222  2.1050518 1.9751467 2.0184195 2.2959816 2.7950957
 3.4590597 4.201331  4.9243917 5.6115956 6.2920136 6.934811  7.4708757
 7.7889466 7.9996376 7.903424  7.778843  7.636196  7.2511687 6.9217205
 7.152723  6.31075   5.228008  4.3352876 3.6265447 2.9593413 2.5202088
 2.2875314 2.1892343 2.1051888 2.046529  2.0348551 2.04136   2.0430853
 2.0927885 2.181111  2.4087255 2.988112  3.7989671 4.730154  5.8625093
 7.0941195 7.4818997 7.723534  7.9285564 7.870416  7.5487027 7.258704
 6.951442  6.2142653 5.458254  4.821206  4.2025313 3.8115964 3.5878475
 3.4678872 3.4077835 3.3941362 3.286942  2.9881694 2.7142417 2.431854
 2.1365886 1.8583261 1.6770767 1.7071773 2.0158124 2.5707445 3.288412
 4.092783  4.864986  5.5705743 6.254317  6.8851337 7.370758  7.6553597
 7.670445  7.5364523 7.354571  6.9835715 6.347066  6.5708556 6.3123093
 5.4299865 4.438843  3.6114671 2.8613842 2.3556597 2.1298347 2.0683916
 2.0653574 2.069988  2.0586514 1.9788183 1.9731634 1.9888932 2.0467083
 2.138369  2.2178676 2.610627  3.3081446 4.234551  5.3466673 6.6109548
 7.057945  7.396955  7.5544586 7.370816  7.0169992 6.6837153 6.379329
 5.584089  4.9088693 4.193597  3.755657  3.5294478 3.426844  3.376491
 3.3429403 3.3272994 3.1281815 2.9223795 2.6898108 2.4070573 2.0772207
 1.7369218 1.4821153 1.4800407 1.8161697 2.4257994 3.1923394 4.043625
 4.8593388 5.578261  6.260938  6.87569   7.308637  7.526582  7.373111
 7.189662  6.8982134 6.0096374 5.938533  5.9915934 5.5735307 4.670514
 3.6761231 2.8546526 2.2869964 2.081453  2.0869176 2.1421962 2.1632175
 2.1317136 2.075316  2.0150528 1.9406861 1.9628445 2.0242686 1.9545856
 1.9382963 2.2466931 2.9041765 3.8118358 4.894421  6.1325345 6.483203
 6.8627625 7.1883173 6.87847   6.4984984 6.118651  5.802118  5.023087
 4.2504272 3.7377086 3.5010386 3.431025  3.4218724 3.4094784 3.3744767
 3.3003223 3.1826756 3.0294704 2.8048103 2.498129  2.1199372 1.7103585
 1.3742094 1.3249705 1.6913769 2.3527353 3.1626875 4.0429854 4.9013433
 5.628661  6.305235  6.899692  7.279347  7.292598  7.106062  6.8625026
 6.0158415 5.493808  5.5869427 5.311202  4.931347  3.8820047 2.9663277
 2.2990532 2.0998907 2.1873052 2.3334746 2.4185054 2.4064887 2.3060186
 2.15802   2.0369492 1.9399914 1.9451144 1.8468    1.798629  1.7975168
 1.9833307 2.578912  3.4521823 4.497963  5.6379023 5.9455724 6.2847786
 6.6916456 6.3951583 5.97684   5.584978  5.206191  4.389533  3.7579935
 3.48261   3.4442642 3.4981756 3.543543  3.536297  3.4535487 3.425997
 3.3904438 3.2474246 3.0010324 2.6521447 2.2171965 1.7385459 1.3254524
 1.2321743 1.630697  2.3412802 3.1899538 4.093853  4.98297   5.7141976
 6.380733  6.951549  7.2356277 7.0775957 6.856726  5.9317427 4.825431
 4.7268662 4.657862  4.295085  3.9019585 3.1527247 2.4358354 2.1485567
 2.3076737]
