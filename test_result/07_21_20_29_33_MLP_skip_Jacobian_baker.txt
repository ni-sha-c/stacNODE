time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 1000
num_test: 1000
num_val: 0
num_trans: 0
loss_type: Jacobian
dyn_sys: baker
model_type: MLP_skip
s: 0.2
n_hidden: 128
n_layers: 2
reg_param: 300.0
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 26.891569138 Test: 24.016508102
Epoch 0: New minimal relative error: 24.02%, model saved.
Epoch: 100 Train: 4.041164398 Test: 4.093780041
Epoch 100: New minimal relative error: 4.09%, model saved.
Epoch: 200 Train: 3.975317478 Test: 4.050286293
Epoch 200: New minimal relative error: 4.05%, model saved.
Epoch: 300 Train: 3.939689636 Test: 4.021255970
Epoch 300: New minimal relative error: 4.02%, model saved.
Epoch: 400 Train: 3.942540646 Test: 4.044675827
Epoch: 500 Train: 3.921503544 Test: 4.014719009
Epoch 500: New minimal relative error: 4.01%, model saved.
Epoch: 600 Train: 3.949766636 Test: 4.035536766
Epoch: 700 Train: 4.040357590 Test: 4.102171898
Epoch: 800 Train: 3.940848112 Test: 4.012652397
Epoch 800: New minimal relative error: 4.01%, model saved.
Epoch: 900 Train: 3.891460419 Test: 3.988984585
Epoch 900: New minimal relative error: 3.99%, model saved.
Epoch: 1000 Train: 3.869949341 Test: 3.954761267
Epoch 1000: New minimal relative error: 3.95%, model saved.
Epoch: 1100 Train: 3.829138041 Test: 3.915654659
Epoch 1100: New minimal relative error: 3.92%, model saved.
Epoch: 1200 Train: 3.825591326 Test: 3.906609774
Epoch 1200: New minimal relative error: 3.91%, model saved.
Epoch: 1300 Train: 4.100504875 Test: 4.231501579
Epoch: 1400 Train: 3.842828274 Test: 3.938561916
Epoch: 1500 Train: 3.840296268 Test: 3.918684006
Epoch: 1600 Train: 3.818123817 Test: 3.891526222
Epoch 1600: New minimal relative error: 3.89%, model saved.
Epoch: 1700 Train: 3.807689428 Test: 3.881446838
Epoch 1700: New minimal relative error: 3.88%, model saved.
Epoch: 1800 Train: 3.818689823 Test: 3.879678965
Epoch 1800: New minimal relative error: 3.88%, model saved.
Epoch: 1900 Train: 3.827018738 Test: 3.872024775
Epoch 1900: New minimal relative error: 3.87%, model saved.
Epoch: 2000 Train: 3.808607340 Test: 3.850927830
Epoch 2000: New minimal relative error: 3.85%, model saved.
Epoch: 2100 Train: 3.814636230 Test: 3.868975639
Epoch: 2200 Train: 3.828009129 Test: 3.915883064
Epoch: 2300 Train: 3.833784580 Test: 3.915783882
Epoch: 2400 Train: 3.822215796 Test: 3.894237518
Epoch: 2500 Train: 3.826000929 Test: 3.885020733
Epoch: 2600 Train: 3.835726976 Test: 3.880531311
Epoch: 2700 Train: 3.842525959 Test: 3.888226032
Epoch: 2800 Train: 3.857201576 Test: 3.899877071
Epoch: 2900 Train: 3.866692066 Test: 3.914827347
Epoch: 3000 Train: 3.883988619 Test: 3.924437523
Epoch: 3100 Train: 3.909397364 Test: 3.938145399
Epoch: 3200 Train: 3.924646378 Test: 3.954131603
Epoch: 3300 Train: 3.949388504 Test: 3.995029688
Epoch: 3400 Train: 3.912518978 Test: 3.960051060
Epoch: 3500 Train: 3.917345047 Test: 3.964712620
Epoch: 3600 Train: 3.915915489 Test: 3.961622238
Epoch: 3700 Train: 3.911375046 Test: 3.958915710
Epoch: 3800 Train: 3.909707546 Test: 3.959864855
Epoch: 3900 Train: 3.912007809 Test: 3.964719772
Epoch: 4000 Train: 3.918162584 Test: 3.968832493
Epoch: 4100 Train: 3.928516150 Test: 3.975332737
Epoch: 4200 Train: 3.983313560 Test: 4.033507824
Epoch: 4300 Train: 3.956238270 Test: 4.002561092
Epoch: 4400 Train: 3.960716248 Test: 4.008523941
Epoch: 4500 Train: 3.965462208 Test: 4.010478973
Epoch: 4600 Train: 3.972148180 Test: 4.014275551
Epoch: 4700 Train: 3.976967812 Test: 4.025328636
Epoch: 4800 Train: 3.981983662 Test: 4.028347015
Epoch: 4900 Train: 4.020355225 Test: 4.059486389
Epoch: 5000 Train: 3.965455532 Test: 4.020176888
Epoch: 5100 Train: 3.965542316 Test: 4.010893822
Epoch: 5200 Train: 3.969923019 Test: 4.012347698
Epoch: 5300 Train: 3.982821941 Test: 4.025049210
Epoch: 5400 Train: 3.989810228 Test: 4.031550407
Epoch: 5500 Train: 3.987795353 Test: 4.030887604
Epoch: 5600 Train: 3.989326239 Test: 4.032603264
Epoch: 5700 Train: 3.994519234 Test: 4.034897804
Epoch: 5800 Train: 3.995562077 Test: 4.036068916
Epoch: 5900 Train: 3.998836517 Test: 4.037637711
Epoch: 6000 Train: 4.000303268 Test: 4.037371635
Epoch: 6100 Train: 4.003314972 Test: 4.037246704
Epoch: 6200 Train: 4.003843307 Test: 4.037733078
Epoch: 6300 Train: 4.002750397 Test: 4.037375450
Epoch: 6400 Train: 4.003877163 Test: 4.040156364
Epoch: 6500 Train: 4.004840851 Test: 4.039642811
Epoch: 6600 Train: 4.003126621 Test: 4.039776802
Epoch: 6700 Train: 4.009760380 Test: 4.040596008
Epoch: 6800 Train: 4.006550312 Test: 4.040482521
Epoch: 6900 Train: 4.009727478 Test: 4.041364193
Epoch: 7000 Train: 4.009219646 Test: 4.042412758
Epoch: 7100 Train: 4.012640476 Test: 4.046392441
Epoch: 7200 Train: 4.011598587 Test: 4.045892239
Epoch: 7300 Train: 4.012510300 Test: 4.044091225
Epoch: 7400 Train: 4.014496326 Test: 4.043703079
Epoch: 7500 Train: 4.029701233 Test: 4.059955597
Epoch: 7600 Train: 4.027393341 Test: 4.053515434
Epoch: 7700 Train: 4.022622108 Test: 4.045142651
Epoch: 7800 Train: 4.021170139 Test: 4.044065952
Epoch: 7900 Train: 4.020982742 Test: 4.046732426
Epoch: 8000 Train: 4.020275116 Test: 4.046655655
Epoch: 8100 Train: 4.019540310 Test: 4.048871517
Epoch: 8200 Train: 4.023771286 Test: 4.055849075
Epoch: 8300 Train: 4.030339718 Test: 4.057348251
Epoch: 8400 Train: 4.032114983 Test: 4.058052063
Epoch: 8500 Train: 4.008233070 Test: 4.041616440
Epoch: 8600 Train: 4.012846470 Test: 4.044418812
Epoch: 8700 Train: 4.030169487 Test: 4.054250717
Epoch: 8800 Train: 4.031119347 Test: 4.052389145
Epoch: 8900 Train: 4.031414032 Test: 4.054797649
Epoch: 9000 Train: 4.029153347 Test: 4.055214882
Epoch: 9100 Train: 4.027935982 Test: 4.054661751
Epoch: 9200 Train: 4.028350353 Test: 4.049632549
Epoch: 9300 Train: 4.030025005 Test: 4.058198929
Epoch: 9400 Train: 4.025063515 Test: 4.053120613
Epoch: 9500 Train: 4.013422489 Test: 4.042523384
Epoch: 9600 Train: 4.013866425 Test: 4.044958591
Epoch: 9700 Train: 4.014488220 Test: 4.043320656
Epoch: 9800 Train: 4.016200542 Test: 4.041857719
Epoch: 9900 Train: 4.016153336 Test: 4.041492462
Epoch: 9999 Train: 4.009466171 Test: 4.032944679
Training Loss: tensor(4.0095)
Test Loss: tensor(4.0329)
True Mean x: tensor(3.3019, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(3.2380, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(3.3662, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(0.0046, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(0.0067)
Jacobian term Test Loss: tensor(0.0066)
Learned LE: [1.1829257 0.290844 ]
True LE: tensor([ 0.6932, -0.7017], dtype=torch.float64)
