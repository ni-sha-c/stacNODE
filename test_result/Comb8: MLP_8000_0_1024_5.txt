time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 0
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 1024
n_layers: 5
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 100.27%, model saved.
Epoch: 0 Train: 3479.04980 Test: 4067.36499
Epoch 80: New minimal relative error: 43.37%, model saved.
Epoch: 80 Train: 48.96512 Test: 63.34439
Epoch 160: New minimal relative error: 12.42%, model saved.
Epoch: 160 Train: 15.24483 Test: 6.80760
Epoch: 240 Train: 13.84232 Test: 8.37599
Epoch: 320 Train: 4.68036 Test: 3.02861
Epoch: 400 Train: 2.32620 Test: 1.27851
Epoch: 480 Train: 1.93847 Test: 3.34490
Epoch: 560 Train: 7.53897 Test: 13.53108
Epoch: 640 Train: 13.53787 Test: 5.45807
Epoch: 720 Train: 0.26334 Test: 0.41012
Epoch 800: New minimal relative error: 10.42%, model saved.
Epoch: 800 Train: 2.03162 Test: 2.77194
Epoch: 880 Train: 4.89979 Test: 4.36829
Epoch: 960 Train: 6.74012 Test: 12.20684
Epoch: 1040 Train: 0.94102 Test: 1.11788
Epoch 1120: New minimal relative error: 6.41%, model saved.
Epoch: 1120 Train: 0.25797 Test: 0.65636
Epoch: 1200 Train: 1.09395 Test: 1.13925
Epoch: 1280 Train: 0.20392 Test: 0.55232
Epoch: 1360 Train: 2.20963 Test: 2.47439
Epoch: 1440 Train: 1.02744 Test: 0.97438
Epoch: 1520 Train: 1.42624 Test: 1.36607
Epoch 1600: New minimal relative error: 3.09%, model saved.
Epoch: 1600 Train: 0.10687 Test: 0.32398
Epoch: 1680 Train: 1.94756 Test: 2.48254
Epoch: 1760 Train: 0.77954 Test: 1.38539
Epoch: 1840 Train: 2.82188 Test: 3.60397
Epoch: 1920 Train: 1.14813 Test: 1.61483
Epoch: 2000 Train: 1.15328 Test: 1.34395
Epoch: 2080 Train: 0.78327 Test: 0.83542
Epoch: 2160 Train: 0.36620 Test: 0.55728
Epoch: 2240 Train: 4.03013 Test: 5.86914
Epoch: 2320 Train: 3.09528 Test: 3.54207
Epoch: 2400 Train: 0.35014 Test: 0.67128
Epoch: 2480 Train: 2.91503 Test: 4.52580
Epoch: 2560 Train: 0.74801 Test: 0.67045
Epoch: 2640 Train: 1.08294 Test: 1.48301
Epoch: 2720 Train: 0.31825 Test: 0.37044
Epoch: 2800 Train: 0.98518 Test: 1.24225
Epoch: 2880 Train: 1.04979 Test: 1.27965
Epoch: 2960 Train: 0.20172 Test: 0.46110
Epoch: 3040 Train: 0.85619 Test: 1.15648
Epoch: 3120 Train: 0.86715 Test: 1.16244
Epoch: 3200 Train: 0.42826 Test: 0.71316
Epoch: 3280 Train: 0.06200 Test: 0.24692
Epoch: 3360 Train: 0.36616 Test: 0.62312
Epoch: 3440 Train: 0.48354 Test: 0.64597
Epoch: 3520 Train: 0.41392 Test: 0.62220
Epoch: 3600 Train: 0.71624 Test: 0.86515
Epoch: 3680 Train: 0.14789 Test: 0.32152
Epoch: 3760 Train: 0.40525 Test: 0.64044
Epoch: 3840 Train: 0.94076 Test: 1.25506
Epoch: 3920 Train: 0.53721 Test: 0.67859
Epoch: 4000 Train: 0.41122 Test: 0.61248
Epoch: 4080 Train: 0.17345 Test: 0.37881
Epoch 4160: New minimal relative error: 3.03%, model saved.
Epoch: 4160 Train: 0.17415 Test: 0.42466
Epoch: 4240 Train: 0.21872 Test: 0.45923
Epoch: 4320 Train: 0.69119 Test: 0.81713
Epoch: 4400 Train: 0.30204 Test: 0.47743
Epoch: 4480 Train: 0.03185 Test: 0.21413
Epoch: 4560 Train: 0.04919 Test: 0.25395
Epoch: 4640 Train: 0.08916 Test: 0.28822
Epoch: 4720 Train: 0.15680 Test: 0.39086
Epoch: 4800 Train: 0.05365 Test: 0.23818
Epoch: 4880 Train: 0.13498 Test: 0.36951
Epoch: 4960 Train: 0.08422 Test: 0.28326
Epoch: 5040 Train: 0.01785 Test: 0.21601
Epoch: 5120 Train: 0.35536 Test: 0.64752
Epoch: 5200 Train: 0.79123 Test: 0.97651
Epoch: 5280 Train: 0.43848 Test: 0.69171
Epoch: 5360 Train: 0.51103 Test: 0.73405
Epoch: 5440 Train: 0.09192 Test: 0.29109
Epoch: 5520 Train: 0.08328 Test: 0.28328
Epoch: 5600 Train: 0.27913 Test: 0.47498
Epoch: 5680 Train: 0.16842 Test: 0.37436
Epoch: 5760 Train: 0.16390 Test: 0.39591
Epoch: 5840 Train: 0.22695 Test: 0.49489
Epoch 5920: New minimal relative error: 2.29%, model saved.
Epoch: 5920 Train: 0.04464 Test: 0.24525
Epoch: 6000 Train: 0.04770 Test: 0.25329
Epoch: 6080 Train: 0.03385 Test: 0.23125
Epoch: 6160 Train: 0.02617 Test: 0.22282
Epoch: 6240 Train: 0.36997 Test: 0.55401
Epoch: 6320 Train: 0.22712 Test: 0.38286
Epoch: 6400 Train: 0.54113 Test: 0.83507
Epoch: 6480 Train: 0.38256 Test: 0.61005
Epoch: 6560 Train: 0.04733 Test: 0.24171
Epoch: 6640 Train: 0.13474 Test: 0.33405
Epoch: 6720 Train: 0.07028 Test: 0.28263
Epoch: 6800 Train: 0.01938 Test: 0.21173
Epoch: 6880 Train: 0.06208 Test: 0.25344
Epoch: 6960 Train: 0.27204 Test: 0.54634
Epoch: 7040 Train: 0.37421 Test: 0.53383
Epoch: 7120 Train: 0.30742 Test: 0.55968
Epoch: 7200 Train: 0.08436 Test: 0.27996
Epoch: 7280 Train: 0.04717 Test: 0.24387
Epoch: 7360 Train: 0.09257 Test: 0.28741
Epoch: 7440 Train: 0.01036 Test: 0.20555
Epoch: 7520 Train: 0.01254 Test: 0.20579
Epoch: 7600 Train: 0.01544 Test: 0.21151
Epoch: 7680 Train: 0.02006 Test: 0.21145
Epoch: 7760 Train: 0.11732 Test: 0.31219
Epoch: 7840 Train: 0.18157 Test: 0.36617
Epoch: 7920 Train: 0.13081 Test: 0.34661
Epoch: 7999 Train: 0.20611 Test: 0.36375
Training Loss: tensor(0.2061)
Test Loss: tensor(0.3637)
Learned LE: [ 0.93738717 -0.00907707 -5.2611513 ]
True LE: [ 8.8183731e-01  9.1199746e-04 -1.4553538e+01]
Relative Error: [15.180624  13.96184   12.952956  12.155933  11.570199  11.189254
 10.997362  10.96591   11.049871  11.187897  11.309731  11.353947
 11.294736  11.171563  11.111361  11.31602   11.992377  13.248162
 15.04602   17.252335  19.709625  22.27909   24.851833  27.34842
 29.7138    31.915983  33.94445   35.80892   37.53369   39.151093
 40.692856  42.18297   43.6313    45.031372  46.36178   47.589985
 48.678314  49.58759   50.27926   50.71689   50.866623  50.70228
 50.213028  49.410908  48.33495   47.043774  45.599518  44.044624
 42.386253  40.598934  38.64485   36.500652  34.17725   31.72103
 29.202261  26.698572  24.280756  22.004076  19.906061  18.00751
 16.316242  14.8329735 13.556446  12.486758  11.625841  10.9757
 10.534978  10.29549   10.238999  10.332837  10.526059  10.748408
 10.918485  10.963404  10.848378  10.611055  10.389475  10.418102
 10.949913  12.120971  13.884165  16.077675  18.521326  21.063917
 23.591953  26.023787  28.304771  30.405033  32.317776  34.058784
 35.65959   37.15832   38.590523  39.98175   41.340942  42.657444
 43.903957  45.042152  46.02973   46.82678   47.3977    47.711143
 47.741093  47.470535  46.89927   46.05062   44.973827  43.73352
 42.389606  40.97039   39.45996   37.807865  35.959377  33.888405
 31.615004  29.201365  26.7331    24.29861   21.97381   19.814266
 17.853325  16.105219  14.570911  13.245665  12.124636  11.206543
 10.493387   9.98711    9.685386   9.578504   9.646416   9.854487
 10.147697  10.448482  10.6650505 10.712884  10.546934  10.199538
  9.814992   9.656008  10.025059  11.093846  12.807308  14.9727745
 17.386356  19.885353  22.352142  24.704025  26.886374  28.870947
 30.656286  32.264545  33.734093  35.10905   36.429623  37.722904
 38.996876  40.237152  41.409786  42.468815  43.367153  44.06401
 44.526855  44.730614  44.657196  44.299282  43.665947  42.791737
 41.735325  40.566532  39.340015  38.06677   36.70524   35.179504
 33.42067   31.405201  29.168251  26.790556  24.373653  22.015387
 19.79583   17.768019  15.958754  14.373774  13.005882  11.843883
 10.879494  10.110646   9.539516   9.167768   8.992014   9.001479
  9.17632    9.482391   9.863035  10.234926  10.496492  10.551417
 10.343475   9.896651   9.355679   9.005085   9.196942  10.147042
 11.7956505 13.917671  16.284872  18.724321  21.115103  23.373367
 25.444641  27.302786  28.951368  30.419462  31.75228   32.999603
 34.20623   35.401814  36.59479   37.766857  38.876896  39.87042
 40.693626  41.3043    41.673885  41.784035  41.624866  41.197716
 40.521732  39.641197  38.623825  37.543575  36.447468  35.32615
 34.10909   32.696434  31.009802  29.034271  26.824492  24.481491
 22.121452  19.85145   17.752075  15.871674  14.22805   12.816608
 11.620682  10.622452   9.810756   9.183179   8.742422   8.489817
  8.420845   8.524911   8.784652   9.169316   9.623272  10.058955
 10.365417  10.433934  10.195619   9.664247   8.979892   8.440578
  8.444803   9.260397  10.828875  12.892096  15.197715  17.563467
 19.86593   22.020466  23.97179   25.695866  27.201649  28.524786
 29.71698   30.833122  31.922298  33.019     34.13324   35.244965
 36.30494   37.24807   38.012302  38.553185  38.846115  38.880066
 38.65352   38.17594   37.475384  36.605453  35.64262   34.663673
 33.70618   32.73732   31.656855  30.342182  28.711658  26.765167
 24.579493  22.275585  19.983294  17.815401  15.851633  14.132931
 12.665818  11.433787  10.41015    9.570797   8.902276   8.40279
  8.075899   7.9224715  7.937233   8.110889   8.430938   8.873171
  9.385711   9.878154  10.230302  10.320501  10.0662     9.468263
  8.658352   7.939532   7.749436   8.414917   9.887807  11.877742
 14.107852  16.388195  18.593628  20.63767   22.46413   24.05086
 25.411602  26.588583  27.638445  28.620111  29.587503  30.58085
 31.615814  32.67263   33.694984  34.60514   35.329235  35.81891
 36.053528  36.030052  35.75487   35.24498   34.536266  33.69119
 32.794334  31.924686  31.108803  30.28807   29.332123  28.100193
 26.51382   24.592196  22.435183  20.180847  17.969654  15.918851
 14.104742  12.558357  11.273498  10.220803   9.363624   8.672378
  8.132547   7.7439165  7.5113254  7.435193   7.509445   7.726998
  8.082196   8.560122   9.115707   9.657976  10.057778  10.179445
  9.924954   9.281057   8.367172   7.483069   7.095039   7.5942755
  8.955784  10.859011  13.002354  15.188843  17.291838  19.223074
 20.92449   22.375002  23.593218  24.626604 ]
