time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 2000
num_train: 8000
num_test: 6000
num_trans: 0
loss_type: Jacobian
dyn_sys: lorenz
model_type: MLP
n_hidden: 512
n_layers: 4
reg_param: 800
optim_name: AdamW
Learned LE: [  0.84303373   0.01595717 -14.588984  ]
True LE: [ 8.6133826e-01  3.5988071e-03 -1.4542237e+01]
