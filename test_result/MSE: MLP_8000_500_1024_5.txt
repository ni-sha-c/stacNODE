time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 500
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 1024
n_layers: 5
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 100.31%, model saved.
Epoch: 0 Train: 3560.75806 Test: 4089.04321
Epoch 80: New minimal relative error: 67.75%, model saved.
Epoch: 80 Train: 48.27910 Test: 54.92671
Epoch 160: New minimal relative error: 28.43%, model saved.
Epoch: 160 Train: 4.63839 Test: 6.00776
Epoch: 240 Train: 3.60659 Test: 4.15525
Epoch: 320 Train: 10.55945 Test: 17.50380
Epoch: 400 Train: 3.48153 Test: 4.77068
Epoch: 480 Train: 3.86191 Test: 6.92430
Epoch: 560 Train: 4.42538 Test: 1.31119
Epoch: 640 Train: 4.20517 Test: 9.59185
Epoch: 720 Train: 12.43484 Test: 14.76281
Epoch: 800 Train: 1.54190 Test: 2.70770
Epoch: 880 Train: 6.07794 Test: 6.77340
Epoch: 960 Train: 1.48992 Test: 1.21283
Epoch 1040: New minimal relative error: 26.60%, model saved.
Epoch: 1040 Train: 3.39021 Test: 4.31974
Epoch: 1120 Train: 0.48459 Test: 1.27879
Epoch: 1200 Train: 1.25288 Test: 1.52188
Epoch: 1280 Train: 0.26094 Test: 0.73661
Epoch: 1360 Train: 0.66773 Test: 0.73892
Epoch 1440: New minimal relative error: 18.41%, model saved.
Epoch: 1440 Train: 0.36105 Test: 0.50539
Epoch: 1520 Train: 1.05834 Test: 1.20266
Epoch: 1600 Train: 0.93785 Test: 0.67370
Epoch: 1680 Train: 0.15358 Test: 0.65910
Epoch: 1760 Train: 1.26971 Test: 1.75576
Epoch: 1840 Train: 1.95884 Test: 1.92018
Epoch: 1920 Train: 2.96901 Test: 3.08847
Epoch: 2000 Train: 1.74302 Test: 1.89390
Epoch: 2080 Train: 0.88212 Test: 0.99769
Epoch: 2160 Train: 2.49012 Test: 3.11392
Epoch: 2240 Train: 1.86394 Test: 2.38253
Epoch: 2320 Train: 0.59596 Test: 0.90664
Epoch: 2400 Train: 1.90688 Test: 2.19141
Epoch: 2480 Train: 0.15768 Test: 0.32093
Epoch: 2560 Train: 0.39493 Test: 0.72026
Epoch: 2640 Train: 1.42397 Test: 2.13018
Epoch: 2720 Train: 2.55724 Test: 2.80692
Epoch: 2800 Train: 2.35469 Test: 2.55798
Epoch: 2880 Train: 1.96673 Test: 2.76015
Epoch: 2960 Train: 1.54808 Test: 1.36826
Epoch: 3040 Train: 0.68820 Test: 0.88861
Epoch: 3120 Train: 1.73319 Test: 2.65191
Epoch: 3200 Train: 0.11836 Test: 0.39047
Epoch: 3280 Train: 0.55036 Test: 0.93649
Epoch: 3360 Train: 1.56300 Test: 1.17886
Epoch 3440: New minimal relative error: 13.35%, model saved.
Epoch: 3440 Train: 0.72429 Test: 1.18094
Epoch: 3520 Train: 0.08700 Test: 0.37036
Epoch: 3600 Train: 0.85700 Test: 1.44434
Epoch: 3680 Train: 0.62006 Test: 0.82643
Epoch: 3760 Train: 2.40771 Test: 2.11849
Epoch: 3840 Train: 1.59377 Test: 1.94532
Epoch: 3920 Train: 0.93689 Test: 1.43035
Epoch: 4000 Train: 0.24875 Test: 0.62581
Epoch: 4080 Train: 0.95746 Test: 1.39658
Epoch 4160: New minimal relative error: 7.90%, model saved.
Epoch: 4160 Train: 0.02196 Test: 0.34021
Epoch: 4240 Train: 0.70008 Test: 1.02336
Epoch: 4320 Train: 0.55555 Test: 0.94154
Epoch: 4400 Train: 0.47966 Test: 0.83128
Epoch: 4480 Train: 0.13365 Test: 0.46553
Epoch: 4560 Train: 0.43922 Test: 0.84066
Epoch: 4640 Train: 0.11053 Test: 0.50725
Epoch: 4720 Train: 0.14333 Test: 0.45304
Epoch: 4800 Train: 0.38747 Test: 0.73356
Epoch: 4880 Train: 0.07922 Test: 0.44217
Epoch: 4960 Train: 0.14177 Test: 0.50442
Epoch: 5040 Train: 0.31792 Test: 0.60404
Epoch: 5120 Train: 0.02730 Test: 0.38508
Epoch: 5200 Train: 0.06698 Test: 0.44672
Epoch: 5280 Train: 0.67972 Test: 1.06105
Epoch: 5360 Train: 0.09548 Test: 0.46991
Epoch: 5440 Train: 0.40723 Test: 0.80088
Epoch: 5520 Train: 0.58366 Test: 1.01273
Epoch: 5600 Train: 0.23683 Test: 0.66029
Epoch: 5680 Train: 0.19549 Test: 0.56532
Epoch: 5760 Train: 0.14717 Test: 0.54861
Epoch: 5840 Train: 0.02187 Test: 0.39984
Epoch: 5920 Train: 0.05288 Test: 0.44170
Epoch: 6000 Train: 0.07340 Test: 0.44672
Epoch: 6080 Train: 0.05878 Test: 0.43953
Epoch: 6160 Train: 0.38580 Test: 0.76714
Epoch: 6240 Train: 0.06401 Test: 0.43009
Epoch: 6320 Train: 0.36719 Test: 0.77727
Epoch: 6400 Train: 0.06542 Test: 0.44129
Epoch: 6480 Train: 0.09882 Test: 0.49079
Epoch: 6560 Train: 0.03262 Test: 0.41687
Epoch: 6640 Train: 0.01416 Test: 0.39951
Epoch: 6720 Train: 0.01167 Test: 0.42111
Epoch: 6800 Train: 0.05544 Test: 0.45211
Epoch: 6880 Train: 0.10127 Test: 0.47014
Epoch: 6960 Train: 0.14104 Test: 0.49691
Epoch: 7040 Train: 0.01119 Test: 0.39980
Epoch: 7120 Train: 0.01968 Test: 0.40676
Epoch: 7200 Train: 0.02020 Test: 0.41510
Epoch: 7280 Train: 0.03945 Test: 0.42424
Epoch: 7360 Train: 0.04069 Test: 0.42806
Epoch: 7440 Train: 0.01894 Test: 0.42229
Epoch: 7520 Train: 0.06507 Test: 0.43056
Epoch: 7600 Train: 0.01867 Test: 0.40925
Epoch: 7680 Train: 0.02739 Test: 0.41568
Epoch: 7760 Train: 0.13705 Test: 0.51132
Epoch: 7840 Train: 0.01771 Test: 0.40495
Epoch: 7920 Train: 0.04394 Test: 0.43633
Epoch: 7999 Train: 0.11088 Test: 0.51656
Training Loss: tensor(0.1109)
Test Loss: tensor(0.5166)
Learned LE: [ 0.91454756 -0.04236697 -4.9053187 ]
True LE: [ 8.8183731e-01  9.1199746e-04 -1.4553538e+01]
Relative Error: [ 6.8064876  7.0525036  7.517587   8.195354   9.065906  10.098729
 11.256302  12.495588  13.768439  15.021139  16.193975  17.223957
 18.050758  18.624548  18.916428  18.924175  18.675932  18.229263
 17.665426  17.081024  16.576775  16.244122  16.152222  16.33658
 16.795233  17.493443  18.375414  19.379581  20.45079   21.548992
 22.6506    23.744886  24.825842  25.885157  26.904879  27.853683
 28.684896  29.338684  29.747692  29.847855  29.590569  28.955954
 27.961687  26.661781  25.136112  23.473326  21.754349  20.042076
 18.37814   16.787083  15.2830515 13.875781  12.576303  11.396996
 10.348223   9.434438   8.652855   7.9963794  7.4598656  7.044829
  6.761755   6.6288633  6.6683464  6.9006286  7.3384566  7.981756
  8.815975   9.813797  10.938467  12.146211  13.387338  14.606155
 15.740532  16.725239  17.497738  18.007782  18.225883  18.15145
 17.815409  17.279495  16.630384  15.971251  15.409897  15.044249
 14.946994  15.15158   15.647836  16.388588  17.30534   18.327564
 19.397158  20.476248  21.54667   22.603981  23.647537  24.67158
 25.658352  26.573622  27.366108  27.970768  28.316858  28.33963
 27.995945  27.277555  26.21836   24.888893  23.380487  21.782557
 20.168182  18.585203  17.060602  15.608001  14.236285  12.954996
 11.776652  10.715571   9.782243   8.978304   8.296528   7.726068
  7.2592735  6.8966365  6.647841   6.529608   6.563183   6.770438
  7.168992   7.765873   8.553108   9.507381  10.593174  11.766371
 12.975846  14.163719  15.265414  16.212706  16.940573  17.396698
 17.551025  17.403482  16.986916  16.366499  15.634349  14.900349
 14.279987  13.879175  13.775152  13.999553  14.532572  15.31256
 16.257359  17.28769   18.343859  19.392323  20.42235   21.436466
 22.439503  23.428688  24.385489  25.271814  26.031002  26.592701
 26.882044  26.834213  26.411936  25.620165  24.50978   23.168766
 21.69834   20.186754  18.694387  17.251509  15.86982   14.553399
 13.30806   12.145121  11.080384  10.130111   9.30406    8.600147
  8.00698    7.5102487  7.101255   6.7806654  6.5576696  6.447275
  6.468516   6.6432858  6.9934072  7.5335274  8.263643   9.166066
 10.207595  11.343972  12.522546  13.683385  14.758974  15.67799
 16.372227  16.786495  16.888735  16.678402  16.189608  15.490659
 14.678354  13.869457  13.187964  12.7487955 12.6353655 12.877824
 13.445358  14.259712  15.223874  16.25099   17.281961  18.289284
 19.27048   20.236053  21.197124  22.153002  23.083704  23.946707
 24.679447  25.205606  25.446241  25.336441  24.84493   23.99057
 22.842964  21.507418  20.09392   18.687078  17.33059   16.034567
 14.794268  13.6070175 12.478795  11.42455   10.464129   9.615472
  8.886501   8.271363   7.7541246  7.3184385  6.9559417  6.6686006
  6.4656367  6.359605   6.3658366  6.504362   6.799826   7.2745285
  7.938075   8.7803335  9.771874  10.868902  12.017714  13.156009
 14.213408  15.114595  15.787363  16.172705  16.235703  15.974237
 15.422986  14.652814  13.764904  12.881801  12.13644   11.654224
 11.52699   11.784242  12.382403  13.2244005 14.198022  15.2101145
 16.204468  17.1608    18.085537  18.998455  19.916908  20.842056
 21.750942  22.596348  23.310019  23.809744  24.011814  23.850502
 23.30151   22.397118  21.226276  19.911625  18.571129  17.282974
 16.071276  14.923519  13.819507  12.751457  11.728707  10.772034
  9.905275   9.147468   8.504282   7.9654365  7.511327   7.124609
  6.798651   6.5377603  6.3515687  6.249499   6.2416234  6.343799
  6.5811954  6.9833336  7.570725   8.343587   9.278278  10.332668
 11.452312  12.572472  13.619571  14.513964  15.178514  15.54915
 15.587014  15.287831  14.686446  13.854918  12.897491  11.941977
 11.129694  10.59807   10.45019   10.716464  11.339153  12.200377
 13.172279  14.158042  15.105505  16.002058  16.864126  17.721193
 18.597242  19.493856  20.38507   21.219273  21.922653  22.40691
 22.582798  22.38338   21.790506  20.8503    19.669903  18.389202
 17.133612  15.972717  14.908938  13.905742  12.928024  11.966295
 11.036284  10.16542    9.381524   8.703692   8.134631   7.659916
  7.257048   6.908629   6.6107183  6.371004   6.199985   6.1038704
  6.085971   6.1552944  6.334623   6.658767   7.1604953  7.8531847
  8.7222395  9.728978  10.818632  11.924279  12.968694  13.867296
 14.536874  14.907704  14.936026  14.614604  13.977424  13.097207
 12.079625  11.055545  10.173603   9.584583   9.406412   9.673049
 10.31166   11.181402  12.14032   13.089514 ]
