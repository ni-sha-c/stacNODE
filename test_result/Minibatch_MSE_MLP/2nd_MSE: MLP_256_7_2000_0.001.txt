time_step: 0.01
lr: 0.001
weight_decay: 0.001
num_epoch: 10000
num_train: 10000
num_test: 8000
num_trans: 1000
batch_size: 2000
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 256
n_layers: 7
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE_new/
Epoch 0: New minimal relative error: 99.97%, model saved.
Epoch: 0 Train: 3882.04883 Test: 4071.91968
Epoch: 100 Train: 210.11667 Test: 405.46783
Epoch 200: New minimal relative error: 88.41%, model saved.
Epoch: 200 Train: 38.06588 Test: 34.67772
Epoch 300: New minimal relative error: 23.79%, model saved.
Epoch: 300 Train: 15.47976 Test: 18.52776
Epoch: 400 Train: 99.81815 Test: 71.77956
Epoch: 500 Train: 5.99513 Test: 5.26282
Epoch: 600 Train: 15.65166 Test: 8.82704
Epoch 700: New minimal relative error: 16.79%, model saved.
Epoch: 700 Train: 3.71544 Test: 2.45788
Epoch: 800 Train: 17.96991 Test: 8.48301
Epoch: 900 Train: 15.57015 Test: 10.77971
Epoch 1000: New minimal relative error: 15.94%, model saved.
Epoch: 1000 Train: 1.14067 Test: 1.06291
Epoch 1100: New minimal relative error: 15.84%, model saved.
Epoch: 1100 Train: 0.67339 Test: 0.65945
Epoch: 1200 Train: 1.49317 Test: 1.20455
Epoch 1300: New minimal relative error: 6.32%, model saved.
Epoch: 1300 Train: 0.47276 Test: 0.37465
Epoch: 1400 Train: 0.30441 Test: 0.26893
Epoch: 1500 Train: 2.29509 Test: 4.80067
Epoch: 1600 Train: 3.28404 Test: 2.99220
Epoch: 1700 Train: 0.78371 Test: 1.02712
Epoch: 1800 Train: 0.78913 Test: 0.92593
Epoch: 1900 Train: 0.43077 Test: 0.82279
Epoch: 2000 Train: 2.79657 Test: 1.89376
Epoch: 2100 Train: 0.21647 Test: 0.15479
Epoch: 2200 Train: 0.22540 Test: 0.19997
Epoch: 2300 Train: 1.04647 Test: 2.34335
Epoch: 2400 Train: 0.51241 Test: 0.26564
Epoch: 2500 Train: 0.23401 Test: 0.24443
Epoch: 2600 Train: 3.13050 Test: 3.85364
Epoch: 2700 Train: 0.19291 Test: 0.17142
Epoch: 2800 Train: 0.16284 Test: 0.16189
Epoch: 2900 Train: 4.06569 Test: 2.47844
Epoch: 3000 Train: 0.26912 Test: 0.44980
Epoch: 3100 Train: 0.11741 Test: 0.11898
Epoch: 3200 Train: 4.78450 Test: 7.17230
Epoch: 3300 Train: 0.55008 Test: 0.28270
Epoch: 3400 Train: 0.86246 Test: 0.88889
Epoch: 3500 Train: 0.10324 Test: 0.07458
Epoch: 3600 Train: 0.07968 Test: 0.07571
Epoch: 3700 Train: 0.11709 Test: 0.11657
Epoch: 3800 Train: 0.66695 Test: 0.39131
Epoch: 3900 Train: 0.09384 Test: 0.15819
Epoch: 4000 Train: 1.65734 Test: 2.01193
Epoch: 4100 Train: 0.18711 Test: 0.06358
Epoch: 4200 Train: 0.27664 Test: 0.24465
Epoch: 4300 Train: 0.06951 Test: 0.07179
Epoch: 4400 Train: 0.04618 Test: 0.04381
Epoch: 4500 Train: 0.04899 Test: 0.04702
Epoch: 4600 Train: 0.05482 Test: 0.05701
Epoch: 4700 Train: 0.04938 Test: 0.04815
Epoch: 4800 Train: 0.04486 Test: 0.04409
Epoch: 4900 Train: 0.07565 Test: 0.08325
Epoch: 5000 Train: 0.04067 Test: 0.03920
Epoch: 5100 Train: 0.16912 Test: 0.22462
Epoch: 5200 Train: 0.12334 Test: 0.15858
Epoch: 5300 Train: 0.03723 Test: 0.03620
Epoch: 5400 Train: 0.19486 Test: 0.24654
Epoch: 5500 Train: 1.65080 Test: 1.96805
Epoch: 5600 Train: 2.12650 Test: 1.82239
Epoch: 5700 Train: 0.05152 Test: 0.11383
Epoch: 5800 Train: 0.04388 Test: 0.04017
Epoch: 5900 Train: 0.03348 Test: 0.03295
Epoch: 6000 Train: 1.08088 Test: 1.22859
Epoch: 6100 Train: 0.58718 Test: 0.60372
Epoch: 6200 Train: 0.13953 Test: 0.05169
Epoch: 6300 Train: 0.02859 Test: 0.02918
Epoch: 6400 Train: 0.02971 Test: 0.02903
Epoch: 6500 Train: 0.06589 Test: 0.06004
Epoch: 6600 Train: 0.02922 Test: 0.02759
Epoch: 6700 Train: 0.02555 Test: 0.02549
Epoch: 6800 Train: 0.11736 Test: 0.03670
Epoch: 6900 Train: 0.03411 Test: 0.03816
Epoch: 7000 Train: 0.04942 Test: 0.09759
Epoch: 7100 Train: 0.10990 Test: 0.15012
Epoch: 7200 Train: 0.45666 Test: 0.44682
Epoch: 7300 Train: 0.12594 Test: 0.16544
Epoch: 7400 Train: 0.02529 Test: 0.02816
Epoch: 7500 Train: 0.30987 Test: 0.09174
Epoch: 7600 Train: 0.01996 Test: 0.02109
Epoch: 7700 Train: 0.02134 Test: 0.02223
Epoch: 7800 Train: 0.02401 Test: 0.02143
Epoch: 7900 Train: 0.02985 Test: 0.03092
Epoch: 8000 Train: 0.09508 Test: 0.13454
Epoch: 8100 Train: 0.01837 Test: 0.01936
Epoch: 8200 Train: 0.07050 Test: 0.07148
Epoch: 8300 Train: 0.13571 Test: 0.23496
Epoch: 8400 Train: 0.01709 Test: 0.01819
Epoch: 8500 Train: 0.01669 Test: 0.01824
Epoch: 8600 Train: 0.01715 Test: 0.01805
Epoch: 8700 Train: 0.02314 Test: 0.02124
Epoch: 8800 Train: 0.01559 Test: 0.01687
Epoch: 8900 Train: 0.02002 Test: 0.01768
Epoch: 9000 Train: 0.01571 Test: 0.01760
Epoch: 9100 Train: 0.01518 Test: 0.01646
Epoch: 9200 Train: 0.09003 Test: 0.05893
Epoch: 9300 Train: 0.01463 Test: 0.01597
Epoch: 9400 Train: 0.01411 Test: 0.01555
Epoch: 9500 Train: 0.01489 Test: 0.01652
Epoch: 9600 Train: 0.65413 Test: 0.34313
Epoch: 9700 Train: 0.01362 Test: 0.01507
Epoch: 9800 Train: 0.02442 Test: 0.02178
Epoch: 9900 Train: 0.01322 Test: 0.01471
Epoch: 9999 Train: 0.14809 Test: 0.17615
Training Loss: tensor(0.1481)
Test Loss: tensor(0.1761)
Learned LE: [ 9.2340040e-01 -1.0649007e-03 -3.4160681e+00]
True LE: [ 8.6787224e-01 -1.4479156e-02 -1.4533365e+01]
Relative Error: [6.9583306 7.446921  7.8361263 8.101994  8.229475  8.229707  8.137398
 7.997575  7.852836  7.736125  7.666418  7.6500235 7.6842093 7.762266
 7.8759136 8.011829  8.146973  8.252885  8.312165  8.334068  8.347758
 8.380665  8.448384  8.558879  8.712825  8.895265  9.067488  9.1724205
 9.152841  8.971225  8.621223  8.126119  7.519277  6.830128  6.18876
 5.935435  6.233116  6.763654  7.2421484 7.5713625 7.7421556 7.7775025
 7.7035995 7.5467253 7.342772  7.137061  6.9708824 6.866454  6.824211
 6.82804   6.8530717 6.872612  6.862536  6.804217  6.68216   6.47745
 6.1618237 5.7254457 5.2723093 5.064376  5.288357  5.8052487 6.361169
 6.855768  7.2625585 7.5467596 7.687717  7.6964045 7.611552  7.482453
 7.3532395 7.254479  7.2009354 7.194164  7.2298417 7.3028793 7.40893
 7.537289  7.6644    7.759317  7.806895  7.824     7.84475   7.8941865
 7.9838276 8.119726  8.302064  8.511589  8.701069  8.805813  8.766953
 8.552049  8.163347  7.6325154 6.995111  6.2881722 5.6909857 5.586621
 5.9829254 6.5085583 6.946619  7.22548   7.3502383 7.3529243 7.258406
 7.0883965 6.8785987 6.678396  6.5307856 6.4556694 6.4482584 6.486682
 6.5412006 6.5817475 6.5828085 6.526322  6.4008274 6.193562  5.8787932
 5.431065  4.9211864 4.6132817 4.7503395 5.2238255 5.765941  6.270435
 6.7017426 7.012317  7.1741266 7.1977935 7.126237  7.0131593 6.903818
 6.82501   6.7854567 6.7821345 6.809803  6.867291  6.9559226 7.069528
 7.184437  7.267002  7.304046  7.3199434 7.3522434 7.42165   7.5346684
 7.6962075 7.905881  8.138927  8.339169  8.436038  8.372522  8.124294
 7.704005  7.1499863 6.499338  5.796405  5.2724113 5.3086143 5.751948
 6.2603498 6.659786  6.8919735 6.977608  6.9546795 6.843689  6.660488
 6.4427123 6.2456536 6.1159215 6.0710726 6.100073  6.174836  6.2606015
 6.3235865 6.336447  6.2819653 6.151854  5.940052  5.62732   5.1786757
 4.6252584 4.2112103 4.2360682 4.647273  5.1701474 5.687119  6.150132
 6.496352  6.688422  6.7356033 6.6846585 6.594209  6.5096064 6.452399
 6.4238205 6.4164    6.4254613 6.455998  6.516757  6.607951  6.7064786
 6.7753816 6.8027773 6.8199315 6.866393  6.957595  7.0942535 7.2801776
 7.513424  7.7634125 7.965398  8.046185  7.9542317 7.6761327 7.234463
 6.672716  6.0279737 5.3497357 4.9232717 5.0710683 5.5312805 6.0207176
 6.3839593 6.5758414 6.630063  6.587515  6.461007  6.261542  6.0310736
 5.834368  5.7217674 5.707817  5.7744436 5.8863115 6.003793  6.089887
 6.116138  6.0657177 5.9331784 5.7174726 5.40801   4.9687896 4.391666
 3.8747892 3.760604  4.0820694 4.574616  5.1038904 5.604977  5.9966784
 6.230256  6.3113303 6.2899446 6.229524  6.174405  6.138674  6.1158266
 6.0951405 6.0750957 6.067524  6.0907497 6.152445  6.23133   6.286077
 6.3036375 6.321861  6.3825703 6.495551  6.6550217 6.8619    7.112401
 7.3702455 7.564783  7.623166  7.502304  7.201127  6.7506447 6.196274
 5.5743437 4.93664   4.62221   4.84829   5.3138223 5.7837977 6.1155386
 6.2765017 6.308129  6.2496824 6.1066475 5.8879437 5.643498  5.4473243
 5.3532977 5.371279  5.4750047 5.6218705 5.767612  5.874278  5.9138546
 5.8708386 5.741155  5.526654  5.223383  4.802041  4.2259316 3.6246133
 3.3514135 3.5449762 3.986628  4.522122  5.064597  5.5103292 5.7969832
 5.924124  5.942921  5.9197845 5.8962164 5.8782024 5.85277   5.808775
 5.7495375 5.695071  5.673309  5.7010865 5.7601476 5.80238   5.8096695
 5.8251457 5.896113  6.0285673 6.2088027 6.4318986 6.6911554 6.947154
 7.127378  7.161653  7.016166  6.7014866 6.254931  5.7199955 5.1308675
 4.542183  4.3383512 4.6186404 5.0865684 5.537145  5.8449993 5.986073
 6.0020843 5.9288015 5.769299  5.536605  5.287139  5.1002    5.02965
 5.0799203 5.216711  5.390747  5.555215  5.673893  5.7229185 5.6900144
 5.5714345 5.3679833 5.0776215 4.680477  4.1296883 3.478415  3.0468502
 3.0693727 3.4248822 3.9503806 4.5311646 5.035672  5.3850207 5.5702987
 5.639481  5.6580577 5.6630735 5.653864  5.6149817 5.537982  5.4321156
 5.3246536 5.253397  5.2462773 5.2901053 5.3273463 5.326321  5.332487
 5.404169  5.550099  5.748145  5.982353  6.241297  6.4868426 6.6503296
 6.6655517]
