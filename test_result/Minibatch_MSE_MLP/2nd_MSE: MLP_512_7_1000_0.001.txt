time_step: 0.01
lr: 0.001
weight_decay: 0.001
num_epoch: 10000
num_train: 10000
num_test: 8000
num_trans: 1000
batch_size: 1000
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 512
n_layers: 7
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE_new/
Epoch 0: New minimal relative error: 99.96%, model saved.
Epoch: 0 Train: 4097.72266 Test: 4437.15918
Epoch 100: New minimal relative error: 82.92%, model saved.
Epoch: 100 Train: 97.32040 Test: 55.92308
Epoch 200: New minimal relative error: 40.90%, model saved.
Epoch: 200 Train: 5.66526 Test: 7.06786
Epoch: 300 Train: 2.32317 Test: 3.94952
Epoch 400: New minimal relative error: 39.51%, model saved.
Epoch: 400 Train: 3.79941 Test: 7.79363
Epoch 500: New minimal relative error: 38.26%, model saved.
Epoch: 500 Train: 10.51943 Test: 10.74731
Epoch: 600 Train: 8.56934 Test: 9.04818
Epoch: 700 Train: 2.12911 Test: 2.69701
Epoch: 800 Train: 10.12039 Test: 12.85152
Epoch: 900 Train: 1.95177 Test: 2.75981
Epoch 1000: New minimal relative error: 11.59%, model saved.
Epoch: 1000 Train: 4.62045 Test: 6.36341
Epoch: 1100 Train: 1.50136 Test: 2.29195
Epoch: 1200 Train: 4.53125 Test: 4.28818
Epoch: 1300 Train: 2.97062 Test: 4.48653
Epoch: 1400 Train: 5.68424 Test: 5.49767
Epoch: 1500 Train: 0.45508 Test: 1.15733
Epoch: 1600 Train: 2.71482 Test: 4.31431
Epoch: 1700 Train: 0.11931 Test: 0.44925
Epoch: 1800 Train: 0.87584 Test: 0.88440
Epoch: 1900 Train: 0.86443 Test: 1.46656
Epoch: 2000 Train: 1.06097 Test: 1.66619
Epoch: 2100 Train: 2.53962 Test: 3.20797
Epoch: 2200 Train: 0.72692 Test: 1.56865
Epoch: 2300 Train: 1.42625 Test: 1.75468
Epoch: 2400 Train: 4.87568 Test: 5.27729
Epoch: 2500 Train: 6.47501 Test: 6.33718
Epoch: 2600 Train: 0.90878 Test: 1.63096
Epoch: 2700 Train: 2.41072 Test: 3.51034
Epoch: 2800 Train: 0.26272 Test: 0.71793
Epoch: 2900 Train: 0.84366 Test: 1.81085
Epoch: 3000 Train: 2.86470 Test: 4.01228
Epoch: 3100 Train: 1.26045 Test: 1.82702
Epoch: 3200 Train: 0.38517 Test: 0.67804
Epoch: 3300 Train: 1.08400 Test: 1.04704
Epoch: 3400 Train: 0.71406 Test: 1.32606
Epoch: 3500 Train: 1.03549 Test: 1.64664
Epoch: 3600 Train: 1.32294 Test: 1.71107
Epoch: 3700 Train: 0.08674 Test: 0.64541
Epoch: 3800 Train: 2.74344 Test: 3.35458
Epoch: 3900 Train: 2.27849 Test: 2.57178
Epoch: 4000 Train: 0.43231 Test: 1.11764
Epoch: 4100 Train: 0.41085 Test: 1.06322
Epoch: 4200 Train: 1.91651 Test: 2.34699
Epoch: 4300 Train: 0.20821 Test: 0.93957
Epoch: 4400 Train: 2.72217 Test: 3.41447
Epoch: 4500 Train: 0.15506 Test: 0.88675
Epoch: 4600 Train: 0.56450 Test: 1.30853
Epoch: 4700 Train: 0.57833 Test: 1.38889
Epoch: 4800 Train: 0.63517 Test: 1.46601
Epoch: 4900 Train: 1.10306 Test: 2.05897
Epoch: 5000 Train: 0.64177 Test: 1.65192
Epoch: 5100 Train: 0.27313 Test: 1.30075
Epoch: 5200 Train: 0.18120 Test: 1.19757
Epoch: 5300 Train: 0.43869 Test: 1.39342
Epoch: 5400 Train: 0.44299 Test: 1.52801
Epoch: 5500 Train: 0.27531 Test: 1.40103
Epoch: 5600 Train: 0.12802 Test: 1.34367
Epoch: 5700 Train: 0.79535 Test: 2.03067
Epoch: 5800 Train: 0.14566 Test: 1.48519
Epoch: 5900 Train: 0.28794 Test: 1.68285
Epoch: 6000 Train: 0.10741 Test: 1.49108
Epoch: 6100 Train: 0.14587 Test: 1.51704
Epoch: 6200 Train: 0.64605 Test: 2.15972
Epoch: 6300 Train: 0.08602 Test: 1.73636
Epoch: 6400 Train: 0.02874 Test: 1.74881
Epoch: 6500 Train: 0.15821 Test: 1.79375
Epoch: 6600 Train: 0.46591 Test: 2.25812
Epoch: 6700 Train: 0.52223 Test: 2.52894
Epoch: 6800 Train: 0.03868 Test: 2.05353
Epoch: 6900 Train: 0.48782 Test: 2.65803
Epoch: 7000 Train: 0.70364 Test: 2.92397
Epoch: 7100 Train: 0.44223 Test: 2.69162
Epoch: 7200 Train: 0.06361 Test: 2.35725
Epoch: 7300 Train: 0.05470 Test: 2.39716
Epoch: 7400 Train: 0.01550 Test: 2.47423
Epoch: 7500 Train: 0.05193 Test: 2.63927
Epoch: 7600 Train: 0.16317 Test: 2.76114
Epoch: 7700 Train: 0.26169 Test: 3.02516
Epoch: 7800 Train: 0.01612 Test: 2.83504
Epoch: 7900 Train: 0.51077 Test: 3.28517
Epoch: 8000 Train: 0.43440 Test: 3.39391
Epoch: 8100 Train: 0.24743 Test: 3.45118
Epoch: 8200 Train: 0.52444 Test: 3.74558
Epoch: 8300 Train: 0.06487 Test: 3.38035
Epoch: 8400 Train: 0.62578 Test: 3.89639
Epoch: 8500 Train: 0.01381 Test: 3.56815
Epoch: 8600 Train: 0.00948 Test: 3.59126
Epoch: 8700 Train: 0.00879 Test: 3.71383
Epoch: 8800 Train: 0.00795 Test: 3.74107
Epoch: 8900 Train: 0.01629 Test: 3.87556
Epoch: 9000 Train: 0.12423 Test: 4.08780
Epoch: 9100 Train: 0.08775 Test: 4.07787
Epoch: 9200 Train: 0.01005 Test: 4.04109
Epoch: 9300 Train: 0.01496 Test: 4.13822
Epoch: 9400 Train: 0.00809 Test: 4.17931
Epoch: 9500 Train: 0.00588 Test: 4.28595
Epoch: 9600 Train: 0.06757 Test: 4.30359
Epoch: 9700 Train: 0.00496 Test: 4.35479
Epoch: 9800 Train: 0.00779 Test: 4.49537
Epoch: 9900 Train: 0.00946 Test: 4.45807
Epoch: 9999 Train: 0.01915 Test: 4.55275
Training Loss: tensor(0.0191)
Test Loss: tensor(4.5527)
Learned LE: [ 0.79452515 -0.04983985 -4.019265  ]
True LE: [ 8.7640446e-01  4.0437733e-03 -1.4550108e+01]
Relative Error: [13.878012   13.131989   12.287322   11.359824   10.389902    9.419775
  8.486784    7.6255507   6.8687744   6.2468624   5.786488    5.5049033
  5.401286    5.452998    5.6196256   5.8530684   6.103217    6.318854
  6.4445763   6.421366    6.1918674   5.7049346   4.9188533   3.8287456
  2.5290146   1.3505685   1.5909076   3.0420423   4.609728    5.983422
  7.0098033   7.654394    8.003687    8.199909    8.364479    8.571074
  8.852752    9.215466    9.6474085  10.125777   10.623802   11.118421
 11.598473   12.069776   12.551214   13.060474   13.595856   14.129981
 14.615943   14.998499   15.226968   15.293588   15.278856   15.294221
 15.379656   15.483258   15.53306    15.474055   15.267383   14.921705
 14.473083   13.946488   13.341364   12.642135   11.834861   10.931113
  9.973105    9.002214    8.053493    7.1610293   6.3574324   5.6727734
  5.1348176   4.7664275   4.578039    4.5592546   4.678367    4.891118
  5.149914    5.406735    5.6099067   5.7010283   5.6195006   5.3108306
  4.7282104   3.8399      2.6833344   1.4607651   1.1526173   2.4353843
  3.991351    5.3971424   6.457363    7.1132116   7.452913    7.6317577
  7.77852     7.9682164   8.233932    8.580741    8.996343    9.45838
  9.939199   10.413554   10.867434   11.305065   11.748594   12.223877
 12.739857   13.277011   13.794945   14.244096   14.567816   14.718129
 14.71979    14.690781   14.719352   14.784212   14.810435   14.743905
 14.5447445  14.219064   13.805495   13.33012    12.78913    12.159444
 11.417328   10.565881    9.647816    8.701711    7.7580347   6.849467
  6.0097437   5.2695646   4.6550946   4.190052    3.893272    3.7697892
  3.8030763   3.9578075   4.1903267   4.456206    4.709272    4.8955293
  4.9528174   4.8210936   4.450988    3.8000827   2.8545647   1.7172061
  0.89810455  1.7565655   3.2548316   4.70165     5.8343267   6.545578
  6.907696    7.0858912   7.219474    7.388564    7.629193    7.9480267
  8.334245    8.768001    9.223593    9.674099   10.100372   10.501857
 10.900113   11.328281   11.807195   12.328134   12.85699    13.352898
 13.768808   14.04007    14.119835   14.072829   14.034099   14.046568
 14.046099   13.971066   13.781023   13.475336   13.096153   12.675129
 12.208607   11.667481   11.017743   10.2473955   9.398084    8.506387
  7.594503    6.691142    5.8325267   5.0529814   4.378303    3.827964
  3.4202788   3.1705446   3.0809739   3.1334732   3.2938673   3.5228975
  3.7810333   4.0234423   4.1928096   4.2239046   4.059808    3.6573198
  2.9800053   2.0447803   1.0803258   1.1436617   2.420046    3.8734481
  5.108794    5.930693    6.3605003   6.56376     6.6950703   6.843832
  7.051971    7.33059     7.6726875   8.0640955   8.484619    8.907854
  9.308442    9.67602    10.026028   10.395516   10.818808   11.301438
 11.816342   12.325584   12.80057    13.193284   13.420266   13.437212
 13.348505   13.289491   13.257472   13.175519   12.997368   12.709962
 12.356814   11.98248    11.590841   11.148617   10.613388    9.950403
  9.192784    8.382591    7.5324483   6.6616564   5.805732    5.0066586
  4.2959733   3.6902256   3.1997132   2.8367696   2.6131048   2.529556
  2.570148    2.7067828   2.9084227   3.1427867   3.3675604   3.522777
  3.5412624   3.3715122   2.9773648   2.3331378   1.5116521   0.9880844
  1.6295774   2.9220304   4.2369404   5.2236614   5.7851114   6.0546975
  6.206884    6.345995    6.5214744   6.750662    7.0342236   7.366837
  7.738413    8.128144    8.505983    8.848195    9.155013    9.458624
  9.807183   10.227787   10.705914   11.199843   11.679844   12.137627
 12.518345   12.714397   12.678285   12.548022   12.460572   12.376717
 12.218494   11.954281   11.615674   11.267684   10.934787   10.589204
 10.179095    9.649908    8.99805     8.283466    7.5192747   6.7115693
  5.8863835   5.0885773   4.362131    3.730835    3.1991231   2.768276
  2.4452746   2.2369423   2.1413918   2.1457694   2.2312565   2.378959
  2.5684063   2.764408    2.907544    2.9303951   2.7875972   2.45261
  1.9190725   1.3404285   1.2787112   2.0256672   3.2138236   4.3552494
  5.1245384   5.524999    5.7366977   5.8931737   6.0530434   6.2373185
  6.453273    6.709712    7.013119    7.354515    7.706291    8.033723
  8.315617    8.562377    8.82101     9.147867    9.560843   10.024872
 10.485663   10.926515   11.364191   11.744744   11.934738   11.86261
 11.691305   11.578541   11.454828   11.237489   10.917597   10.569191
 10.258167    9.983448    9.691002    9.317616    8.797491    8.176471
  7.501573    6.7766333   6.014092    5.246235    4.5215364   3.8806617
  3.3358057   2.8797512   2.5076752   2.223327    2.0290782   1.918933
  1.8807026   1.9020717   1.9751976   2.095004    2.242818    2.3690305
  2.4089365   2.3230057   2.098195    1.7487032 ]
