time_step: 0.01
lr: 0.001
weight_decay: 0.0001
num_epoch: 10000
num_train: 10000
num_test: 8000
num_trans: 1000
batch_size: 2000
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 512
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE_new/
Epoch 0: New minimal relative error: 99.23%, model saved.
Epoch: 0 Train: 4076.64697 Test: 3892.83545
Epoch 100: New minimal relative error: 48.41%, model saved.
Epoch: 100 Train: 40.41293 Test: 47.15009
Epoch 200: New minimal relative error: 25.21%, model saved.
Epoch: 200 Train: 14.89280 Test: 15.08587
Epoch: 300 Train: 23.83299 Test: 13.40223
Epoch 400: New minimal relative error: 23.86%, model saved.
Epoch: 400 Train: 4.29609 Test: 4.53185
Epoch 500: New minimal relative error: 20.77%, model saved.
Epoch: 500 Train: 2.04825 Test: 2.74231
Epoch: 600 Train: 4.38689 Test: 7.51399
Epoch 700: New minimal relative error: 8.41%, model saved.
Epoch: 700 Train: 1.56662 Test: 1.72201
Epoch: 800 Train: 12.14854 Test: 16.93666
Epoch: 900 Train: 1.20346 Test: 1.04561
Epoch: 1000 Train: 1.37979 Test: 1.56975
Epoch: 1100 Train: 0.50430 Test: 0.71425
Epoch: 1200 Train: 0.61535 Test: 0.64574
Epoch: 1300 Train: 0.56597 Test: 0.66661
Epoch: 1400 Train: 0.54771 Test: 0.57849
Epoch: 1500 Train: 2.46002 Test: 2.01813
Epoch: 1600 Train: 0.36833 Test: 1.01542
Epoch 1700: New minimal relative error: 3.98%, model saved.
Epoch: 1700 Train: 0.45924 Test: 0.53293
Epoch: 1800 Train: 1.43796 Test: 1.61348
Epoch: 1900 Train: 3.61781 Test: 3.46409
Epoch: 2000 Train: 0.32580 Test: 0.36384
Epoch: 2100 Train: 0.42133 Test: 0.48514
Epoch: 2200 Train: 0.50117 Test: 0.75855
Epoch: 2300 Train: 0.25855 Test: 0.26571
Epoch: 2400 Train: 0.16808 Test: 0.21826
Epoch: 2500 Train: 0.17756 Test: 0.22976
Epoch: 2600 Train: 1.03472 Test: 0.78692
Epoch: 2700 Train: 0.49751 Test: 0.56540
Epoch: 2800 Train: 0.37605 Test: 0.36097
Epoch: 2900 Train: 0.20013 Test: 0.23224
Epoch: 3000 Train: 0.44247 Test: 0.55994
Epoch: 3100 Train: 1.45455 Test: 1.83387
Epoch: 3200 Train: 0.67396 Test: 0.98877
Epoch: 3300 Train: 0.18184 Test: 0.24081
Epoch: 3400 Train: 0.99372 Test: 1.53907
Epoch: 3500 Train: 0.10313 Test: 0.14496
Epoch: 3600 Train: 0.35490 Test: 0.45359
Epoch: 3700 Train: 0.09669 Test: 0.14540
Epoch: 3800 Train: 0.16549 Test: 0.18159
Epoch: 3900 Train: 0.30130 Test: 0.33282
Epoch: 4000 Train: 0.08730 Test: 0.12423
Epoch: 4100 Train: 0.66485 Test: 0.92463
Epoch: 4200 Train: 0.21786 Test: 0.16839
Epoch: 4300 Train: 0.10878 Test: 0.12213
Epoch: 4400 Train: 0.12614 Test: 0.18954
Epoch: 4500 Train: 0.07646 Test: 0.10874
Epoch: 4600 Train: 0.07470 Test: 0.10457
Epoch: 4700 Train: 0.06761 Test: 0.09917
Epoch: 4800 Train: 0.06755 Test: 0.09742
Epoch: 4900 Train: 0.06678 Test: 0.09559
Epoch: 5000 Train: 0.13461 Test: 0.17807
Epoch: 5100 Train: 0.28552 Test: 0.38825
Epoch: 5200 Train: 0.09578 Test: 0.14173
Epoch: 5300 Train: 0.44036 Test: 0.58401
Epoch: 5400 Train: 0.05822 Test: 0.08658
Epoch: 5500 Train: 0.06312 Test: 0.09270
Epoch: 5600 Train: 0.15372 Test: 0.20027
Epoch: 5700 Train: 0.05413 Test: 0.08240
Epoch: 5800 Train: 0.05536 Test: 0.08913
Epoch: 5900 Train: 0.05221 Test: 0.08025
Epoch: 6000 Train: 0.05531 Test: 0.08348
Epoch: 6100 Train: 0.06761 Test: 0.08329
Epoch: 6200 Train: 0.04919 Test: 0.07645
Epoch: 6300 Train: 0.04937 Test: 0.07583
Epoch: 6400 Train: 0.04794 Test: 0.07445
Epoch: 6500 Train: 0.73103 Test: 0.90970
Epoch: 6600 Train: 0.04640 Test: 0.07357
Epoch: 6700 Train: 0.04735 Test: 0.07210
Epoch: 6800 Train: 0.53387 Test: 0.35165
Epoch: 6900 Train: 0.04378 Test: 0.06968
Epoch: 7000 Train: 0.04348 Test: 0.06934
Epoch: 7100 Train: 0.05740 Test: 0.08010
Epoch: 7200 Train: 0.07253 Test: 0.10461
Epoch: 7300 Train: 0.04134 Test: 0.06709
Epoch: 7400 Train: 0.06767 Test: 0.08657
Epoch: 7500 Train: 0.05348 Test: 0.07374
Epoch: 7600 Train: 0.08719 Test: 0.15617
Epoch: 7700 Train: 0.04303 Test: 0.06964
Epoch: 7800 Train: 0.03880 Test: 0.06437
Epoch: 7900 Train: 0.03860 Test: 0.06235
Epoch: 8000 Train: 0.05154 Test: 0.06953
Epoch: 8100 Train: 0.49297 Test: 0.54015
Epoch: 8200 Train: 0.03866 Test: 0.06492
Epoch: 8300 Train: 0.32878 Test: 0.37515
Epoch: 8400 Train: 0.03630 Test: 0.06133
Epoch: 8500 Train: 0.03494 Test: 0.05851
Epoch: 8600 Train: 0.03714 Test: 0.06009
Epoch: 8700 Train: 0.03407 Test: 0.05807
Epoch: 8800 Train: 0.09127 Test: 0.12188
Epoch: 8900 Train: 0.09977 Test: 0.15082
Epoch: 9000 Train: 0.34006 Test: 0.26830
Epoch: 9100 Train: 0.03219 Test: 0.05528
Epoch: 9200 Train: 0.03201 Test: 0.05510
Epoch: 9300 Train: 0.06996 Test: 0.08401
Epoch: 9400 Train: 0.03300 Test: 0.05439
Epoch: 9500 Train: 0.03198 Test: 0.05428
Epoch: 9600 Train: 0.03036 Test: 0.05291
Epoch: 9700 Train: 0.03496 Test: 0.06709
Epoch: 9800 Train: 0.04484 Test: 0.05552
Epoch: 9900 Train: 0.03930 Test: 0.06819
Epoch: 9999 Train: 0.18131 Test: 0.21442
Training Loss: tensor(0.1813)
Test Loss: tensor(0.2144)
Learned LE: [ 0.8878365   0.01098778 -3.923224  ]
True LE: [ 8.7614554e-01 -7.3054419e-03 -1.4544998e+01]
Relative Error: [ 7.5617356  7.2860727  6.9787083  6.685579   6.4777455  6.4812617
  6.8423023  7.56709    8.523002   9.551686  10.452405  11.102661
 11.788819  12.647414  13.328345  13.479924  12.886779  12.273205
 11.792848  11.378326  10.942559  10.537085  10.219697   9.921234
  9.61722    9.333846   9.0383005  8.698797   8.40085    8.099066
  7.6917863  7.3823156  7.3167267  7.1216106  6.765525   6.6254773
  6.5313244  5.8774004  5.7155313  5.770703   5.187244   5.1966367
  5.8114195  6.7953186  7.7687182  8.486032   8.903586   9.038368
  9.08237    9.184371   9.182035   9.006947   8.740604   8.456441
  8.170582   7.9012513  7.7282777  7.684133   7.7007093  7.699488
  7.640521   7.5100365  7.301479   7.0128865  6.6523075  6.254167
  5.896313   5.695089   5.8215356  6.381648   7.265221   8.287952
  9.274654  10.014879  10.6613655 11.57255   12.430421  12.804855
 12.237803  11.605196  11.1547985 10.763958  10.337647   9.880096
  9.514793   9.2050495  8.84713    8.491028   8.214284   7.995207
  7.7093678  7.4345694  7.1974225  6.7680383  6.447604   6.4705343
  6.3107915  6.023966   5.9391747  5.6830525  5.1340866  5.1333146
  4.878417   4.5324435  4.843812   5.7085547  6.784332   7.665829
  8.119726   8.264952   8.277318   8.371071   8.419567   8.235739
  7.920461   7.6233783  7.4196196  7.291849   7.1977153  7.1866846
  7.279787   7.378186   7.414166   7.3752174  7.2494054  7.0112953
  6.649776   6.183646   5.6704373  5.230701   5.04237    5.310245
  6.043929   7.0124106  8.019765   8.875118   9.495718  10.287161
 11.353678  12.045966  11.632062  10.974738  10.592561  10.25601
  9.89679    9.454988   9.037282   8.679542   8.221357   7.7342005
  7.3258705  7.0254073  6.833972   6.6043115  6.2974973  6.2224364
  6.0137053  5.736625   5.835626   5.697519   5.4151797  5.321389
  4.932686   4.475756   4.5864725  4.154497   4.1052923  4.6394186
  5.5931573  6.632351   7.1601124  7.4214196  7.5499783  7.6233664
  7.672064   7.483746   7.1040006  6.72376    6.4491587  6.319813
  6.362433   6.5256023  6.69748    6.891403   7.071039   7.1845455
  7.202984   7.0961275  6.831704   6.4006886  5.8367333  5.212893
  4.6807723  4.49247    4.891673   5.758162   6.7468414  7.6797595
  8.38259    8.958233   9.943208  11.013595  11.108826  10.419466
 10.105682   9.854104   9.567015   9.220629   8.765746   8.282108
  7.776721   7.272011   6.8118124  6.403397   6.054676   5.785503
  5.568446   5.1913877  5.1466293  5.4867506  5.281519   5.3151
  5.2629266  4.9586763  4.8166094  4.38236    3.889462   3.99904
  3.578735   3.7662885  4.445673   5.385728   6.0272937  6.4549675
  6.77936    6.9633512  6.9286966  6.7369437  6.351883   5.9155436
  5.5658765  5.350902   5.286631   5.441574   5.8094153  6.128712
  6.3521786  6.613986   6.852112   6.9562087  6.873174   6.602828
  6.1472793  5.5354543  4.8430552  4.2214403  3.9766989  4.452397
  5.439483   6.424753   7.2622786  7.8518367  8.414661   9.508462
 10.343976   9.9956255  9.622032   9.526666   9.323827   9.096278
  8.754009   8.158319   7.5722694  7.0927367  6.58459    6.075047
  5.6071696  5.2008295  4.869729   4.679513   4.5657287  4.340664
  4.66171    5.039677   4.910897   5.0429277  4.7003613  4.484139
  4.1510077  3.4887083  3.4938529  3.0772061  3.3656075  4.150621
  4.868372   5.2840934  5.7686763  6.2151494  6.3240914  6.0301347
  5.682582   5.2395635  4.820932   4.526599   4.372518   4.37027
  4.5718727  4.946078   5.3357153  5.591616   5.893126   6.234652
  6.4552436  6.4534197  6.2316275  5.8174496  5.2164783  4.4909973
  3.791917   3.4201686  3.8308244  4.951912   6.013883   6.7705045
  7.2959275  7.8379164  8.84026    9.433516   9.121094   9.046537
  9.097612   8.979343   8.854067   8.493337   7.730855   7.075172
  6.5402746  5.9855814  5.4185433  4.875726   4.3826222  4.018038
  3.8679485  4.002211   4.0313373  3.8990645  4.4312606  4.7746964
  4.792649   4.5858374  4.2806554  4.127786   3.3292398  3.0987713
  2.7280896  2.8957927  3.5564706  4.22017    4.584153   5.0455775
  5.5999074  5.578776   5.1160636  4.692645   4.2528586  3.8804033
  3.6493115  3.5488193  3.5745072  3.7391264  3.9853566  4.281132
  4.645146   4.9432883  5.270606   5.5775795  5.755439   5.6901073
  5.36535    4.817532   4.080652   3.2925797  2.7606108  2.9531724
  4.0463047  5.360809   6.2097063  6.689851   7.1527853  7.956952
  8.496375   8.36727    8.429743   8.672156   8.710291   8.771978
  8.471387   7.6338897  6.7611456  6.1592393]
