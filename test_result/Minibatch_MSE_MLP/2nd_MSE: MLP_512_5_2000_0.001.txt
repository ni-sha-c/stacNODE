time_step: 0.01
lr: 0.001
weight_decay: 0.001
num_epoch: 10000
num_train: 10000
num_test: 8000
num_trans: 1000
batch_size: 2000
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 512
n_layers: 5
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE_new/
Epoch 0: New minimal relative error: 99.88%, model saved.
Epoch: 0 Train: 4074.48804 Test: 3990.24487
Epoch: 100 Train: 46.20010 Test: 39.90356
Epoch 200: New minimal relative error: 48.81%, model saved.
Epoch: 200 Train: 13.86852 Test: 11.26571
Epoch 300: New minimal relative error: 40.73%, model saved.
Epoch: 300 Train: 18.29129 Test: 15.21967
Epoch 400: New minimal relative error: 37.25%, model saved.
Epoch: 400 Train: 1.34339 Test: 2.24445
Epoch: 500 Train: 10.18244 Test: 13.89130
Epoch: 600 Train: 2.39666 Test: 2.64036
Epoch 700: New minimal relative error: 17.68%, model saved.
Epoch: 700 Train: 10.79695 Test: 13.37936
Epoch: 800 Train: 0.41351 Test: 0.96544
Epoch: 900 Train: 0.68711 Test: 1.03505
Epoch: 1000 Train: 1.22883 Test: 1.56881
Epoch 1100: New minimal relative error: 17.54%, model saved.
Epoch: 1100 Train: 2.53116 Test: 1.93224
Epoch: 1200 Train: 2.45522 Test: 3.46183
Epoch: 1300 Train: 0.44956 Test: 0.92893
Epoch: 1400 Train: 1.23100 Test: 2.26815
Epoch: 1500 Train: 3.16357 Test: 3.66533
Epoch: 1600 Train: 0.35438 Test: 0.70777
Epoch: 1700 Train: 0.34343 Test: 1.02771
Epoch: 1800 Train: 0.67859 Test: 1.49527
Epoch: 1900 Train: 1.85981 Test: 3.22383
Epoch: 2000 Train: 1.66902 Test: 1.82916
Epoch: 2100 Train: 0.91311 Test: 1.83866
Epoch: 2200 Train: 0.49741 Test: 1.02208
Epoch: 2300 Train: 0.16560 Test: 0.63303
Epoch: 2400 Train: 0.94763 Test: 1.08496
Epoch: 2500 Train: 1.46188 Test: 1.89012
Epoch: 2600 Train: 0.20493 Test: 0.72243
Epoch: 2700 Train: 0.34937 Test: 1.01320
Epoch: 2800 Train: 0.10554 Test: 0.68440
Epoch: 2900 Train: 0.95558 Test: 1.72933
Epoch: 3000 Train: 2.37023 Test: 3.55774
Epoch: 3100 Train: 0.34536 Test: 1.38098
Epoch: 3200 Train: 0.19319 Test: 0.85234
Epoch: 3300 Train: 2.52772 Test: 2.63171
Epoch: 3400 Train: 0.13016 Test: 0.77530
Epoch: 3500 Train: 1.45230 Test: 2.22457
Epoch: 3600 Train: 0.55580 Test: 1.23785
Epoch: 3700 Train: 0.25490 Test: 1.01157
Epoch: 3800 Train: 0.27254 Test: 1.06901
Epoch: 3900 Train: 0.59093 Test: 1.27544
Epoch: 4000 Train: 0.05533 Test: 0.78224
Epoch: 4100 Train: 0.25648 Test: 1.01897
Epoch: 4200 Train: 1.54490 Test: 2.30979
Epoch: 4300 Train: 0.17702 Test: 0.99532
Epoch: 4400 Train: 0.65815 Test: 1.44507
Epoch: 4500 Train: 0.15073 Test: 1.09337
Epoch: 4600 Train: 2.74209 Test: 4.33158
Epoch: 4700 Train: 0.66066 Test: 1.71230
Epoch: 4800 Train: 0.62938 Test: 1.43465
Epoch: 4900 Train: 0.07204 Test: 1.01647
Epoch: 5000 Train: 0.02724 Test: 1.00777
Epoch: 5100 Train: 0.07981 Test: 1.07685
Epoch: 5200 Train: 0.81388 Test: 1.78571
Epoch: 5300 Train: 1.50987 Test: 2.46442
Epoch: 5400 Train: 0.21170 Test: 1.32663
Epoch: 5500 Train: 2.14165 Test: 3.15000
Epoch: 5600 Train: 0.29940 Test: 1.45992
Epoch: 5700 Train: 0.06311 Test: 1.21348
Epoch: 5800 Train: 0.03103 Test: 1.24073
Epoch: 5900 Train: 0.02960 Test: 1.21340
Epoch: 6000 Train: 0.07587 Test: 1.32781
Epoch: 6100 Train: 0.19826 Test: 1.43229
Epoch: 6200 Train: 0.26839 Test: 1.62477
Epoch: 6300 Train: 0.01482 Test: 1.35555
Epoch: 6400 Train: 0.02159 Test: 1.40167
Epoch: 6500 Train: 0.01834 Test: 1.40569
Epoch: 6600 Train: 0.02293 Test: 1.45056
Epoch: 6700 Train: 0.03445 Test: 1.49496
Epoch: 6800 Train: 0.01382 Test: 1.52789
Epoch: 6900 Train: 0.01847 Test: 1.53713
Epoch: 7000 Train: 0.12030 Test: 1.70904
Epoch: 7100 Train: 0.08482 Test: 1.68065
Epoch: 7200 Train: 0.04828 Test: 1.67347
Epoch: 7300 Train: 0.01638 Test: 1.68339
Epoch: 7400 Train: 0.01190 Test: 1.70101
Epoch: 7500 Train: 0.02272 Test: 1.80186
Epoch: 7600 Train: 0.01448 Test: 1.78862
Epoch: 7700 Train: 0.01159 Test: 1.81045
Epoch: 7800 Train: 0.05967 Test: 1.84331
Epoch: 7900 Train: 0.26043 Test: 2.21917
Epoch: 8000 Train: 0.18610 Test: 2.13773
Epoch: 8100 Train: 0.01192 Test: 1.94219
Epoch: 8200 Train: 0.01070 Test: 1.98678
Epoch: 8300 Train: 0.02875 Test: 2.04272
Epoch: 8400 Train: 0.00995 Test: 2.04503
Epoch: 8500 Train: 0.01579 Test: 2.12164
Epoch: 8600 Train: 0.03554 Test: 2.15921
Epoch: 8700 Train: 0.01118 Test: 2.14225
Epoch: 8800 Train: 0.01240 Test: 2.19791
Epoch: 8900 Train: 0.08306 Test: 2.29894
Epoch: 9000 Train: 0.00914 Test: 2.23428
Epoch: 9100 Train: 0.00962 Test: 2.26908
Epoch: 9200 Train: 0.00885 Test: 2.29883
Epoch: 9300 Train: 0.00986 Test: 2.32551
Epoch: 9400 Train: 0.00895 Test: 2.35031
Epoch: 9500 Train: 0.00854 Test: 2.38488
Epoch: 9600 Train: 0.19957 Test: 2.64572
Epoch: 9700 Train: 0.04519 Test: 2.41948
Epoch: 9800 Train: 0.01315 Test: 2.44667
Epoch: 9900 Train: 0.00808 Test: 2.46237
Epoch: 9999 Train: 0.70313 Test: 3.26977
Training Loss: tensor(0.7031)
Test Loss: tensor(3.2698)
Learned LE: [ 0.7874767  -0.05777431 -3.7246346 ]
True LE: [  0.8716073   -0.01837929 -14.540493  ]
Relative Error: [ 7.058725    6.622067    6.472932    6.594912    6.810897    6.888502
  6.7069573   6.318434    5.833874    5.346852    4.9390864   4.670471
  4.552723    4.5559726   4.6311164   4.706652    4.7111535   4.6188073
  4.4577327   4.280265    4.137656    4.068199    4.0919075   4.208139
  4.3983154   4.6385365   4.913958    5.2261853   5.5878215   6.0115323
  6.5079913   7.091       7.778952    8.584623    9.500209   10.49463
 11.523999   12.534237   13.4452     14.14294    14.492826   14.366897
 13.692866   12.507634   10.953762    9.2220335   7.5208297   6.0999966
  5.242533    5.113036    5.5672383   6.2937064   7.0653176   7.7744193
  8.373746    8.83703     9.143785    9.27486     9.215479    8.960439
  8.516641    7.9093776   7.2107735   6.578678    6.208557    6.1679826
  6.3109713   6.375771    6.1927786   5.7973156   5.3071833   4.8214254
  4.4205165   4.152728    4.01435     3.9768026   4.011165    4.0582786
  4.0460825   3.9477863   3.7905536   3.6239915   3.4959369   3.4436145
  3.486256    3.6208      3.8241937   4.0672827   4.333161    4.6253557
  4.959359    5.3479447   5.800086    6.328927    6.9562807   7.7017636
  8.563547    9.51115    10.499451   11.47797    12.375008   13.08357
 13.468536   13.389772   12.76013    11.614826   10.104443    8.418374
  6.7639894   5.420136    4.7308145   4.8479614   5.496704    6.3069334
  7.0942783   7.79817     8.388838    8.846551    9.159402    9.316287
  9.303687    9.111654    8.737161    8.187125    7.483916    6.71865
  6.1108804   5.8517294   5.876455    5.9132257   5.732572    5.3356724
  4.845595    4.3674793   3.9774332   3.7074203   3.5354316   3.436972
  3.4114628   3.4193456   3.3890984   3.2900128   3.1451118   2.997329
  2.889905    2.8579948   2.9205947   3.073497    3.2905612   3.5383933
  3.7979274   4.073988    4.3842573   4.741931    5.152561    5.6266437
  6.187244    6.8606095   7.654339    8.543235    9.481127   10.419707
 11.296163   12.013931   12.442539   12.432695   11.877451   10.80183
  9.3591175   7.734505    6.128855    4.8484726   4.3078766   4.629377
  5.396355    6.230078    7.017041    7.7257648   8.318197    8.770993
  9.083674    9.260433    9.296318    9.177063    8.8854265   8.416583
  7.7852907   7.01077     6.216902    5.690824    5.5359554   5.516124
  5.337704    4.942195    4.4514613   3.982048    3.604753    3.3312163
  3.117801    2.941975    2.835883    2.7898846   2.736607    2.6393743
  2.5134754   2.3932729   2.3150957   2.3097017   2.394734    2.5657907
  2.7959006   3.0498674   3.306444    3.570673    3.8622153   4.193947
  4.5683227   4.990797    5.4816084   6.070953    6.7787976   7.592605
  8.469175    9.359819   10.208601   10.93054    11.405799   11.483416
 11.033741   10.059583    8.709021    7.16224     5.608035    4.368636
  3.933325    4.3943615   5.211067    6.0420284   6.8423367   7.5773573
  8.183485    8.631497    8.934215    9.116181    9.189893    9.148168
  8.961536    8.590496    8.036925    7.3426523   6.5181293   5.7408457
  5.328433    5.2030206   5.021578    4.633652    4.136272    3.666873
  3.3000119   3.0237045   2.7684956   2.505325    2.2956564   2.1739054
  2.0874991   1.9900259   1.8860787   1.8010173   1.763748    1.7964056
  1.9102464   2.1002145   2.3418236   2.601692    2.857536    3.113631
  3.3903296   3.7007113   4.0447717   4.422634    4.8469687   5.345623
  5.9495306   6.666948    7.467259    8.301261    9.115765    9.835168
 10.353158   10.528161   10.212586    9.37366     8.141176    6.6908784
  5.1950755   3.9687407   3.5705168   4.0986967   4.921558    5.7498746
  6.5830154   7.36167     7.9935355   8.443381    8.732052    8.901509
  8.985537    8.996859    8.919       8.692924    8.249411    7.617674
  6.8827996   6.0340567   5.3176856   4.9979897   4.795043    4.4306207
  3.9296649   3.4390159   3.0686622   2.7911744   2.5038714   2.1563985
  1.8192463   1.5834973   1.4423156   1.3373321   1.2529333   1.2056657
  1.2214229   1.3086816   1.4633176   1.6765316   1.9294213   2.194619
  2.4506712   2.7003396   2.964072    3.2556229   3.5742679   3.9164271
  4.2851844   4.697995    5.188359    5.7868156   6.489065    7.252958
  8.025217    8.735643    9.28737     9.556713    9.393577    8.723144
  7.6389484   6.3074803   4.884701    3.6481924   3.1985567   3.7245474
  4.535501    5.3680205   6.244938    7.079919    7.754588    8.223818
  8.508299    8.658037    8.724641    8.741724    8.719       8.629209
  8.380023    7.8722157   7.179468    6.432814    5.589959    4.956897
  4.66517     4.33852     3.8682156   3.3441052   2.9310493   2.6483815
  2.3531668   1.9591471   1.5060359   1.1069375   0.8464908   0.70167553
  0.6249299   0.6080569   0.6814287   0.8373834   1.0430058   1.2849603
  1.5516615   1.8247293   2.0840025   2.3286438 ]
