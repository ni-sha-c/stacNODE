time_step: 0.001
lr: 0.001
weight_decay: 0.0005
num_epoch: 20000
num_train: 10000
num_test: 8000
num_val: 0
num_trans: 0
loss_type: Jacobian
dyn_sys: lorenz
model_type: MLP_skip
s: 0.2
n_hidden: 256
n_layers: 4
reg_param: 500
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 11.966629982 Test: 13.371305466
Epoch 0: New minimal relative error: 114.62%, model saved.
Epoch: 200 Train: 0.609456956 Test: 4.213204384
Epoch: 400 Train: 0.558940053 Test: 5.160749912
Epoch: 600 Train: 0.574722350 Test: 4.614361763
Epoch: 800 Train: 0.509474635 Test: 4.867537975
Epoch: 1000 Train: 0.663047075 Test: 4.006201744
Epoch: 1200 Train: 0.671583295 Test: 4.052552700
Epoch: 1400 Train: 0.676293731 Test: 3.778893471
Epoch: 1600 Train: 0.526834667 Test: 4.653078556
Epoch: 1800 Train: 0.596801460 Test: 3.499434710
Epoch: 2000 Train: 0.536785960 Test: 4.339265347
Epoch: 2200 Train: 0.622212410 Test: 3.622621059
Epoch: 2400 Train: 0.566912353 Test: 3.946679115
Epoch: 2600 Train: 0.554646432 Test: 3.427757740
Epoch: 2800 Train: 0.572815359 Test: 3.195298910
Epoch: 3000 Train: 0.520711541 Test: 3.527401924
Epoch: 3200 Train: 0.519284666 Test: 3.862735987
Epoch: 3400 Train: 0.509591341 Test: 3.555066586
Epoch: 3600 Train: 0.505443335 Test: 3.564928770
Epoch: 3800 Train: 0.566520154 Test: 3.350471497
Epoch: 4000 Train: 0.542908013 Test: 3.290647507
Epoch: 4200 Train: 0.528021872 Test: 3.681913853
Epoch: 4400 Train: 0.490357846 Test: 4.710505009
Epoch: 4600 Train: 0.482485175 Test: 3.537121296
Epoch: 4800 Train: 0.581730962 Test: 3.224509001
Epoch: 5000 Train: 0.588138402 Test: 3.639061451
Epoch: 5200 Train: 0.660205483 Test: 5.244946003
Epoch: 5400 Train: 0.582637072 Test: 3.184414864
