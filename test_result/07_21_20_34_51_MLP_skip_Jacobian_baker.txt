time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 2500
num_train: 1000
num_test: 1000
num_val: 0
num_trans: 0
loss_type: Jacobian
dyn_sys: baker
model_type: MLP_skip
s: 0.2
n_hidden: 256
n_layers: 2
reg_param: 300.0
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 23.724441528 Test: 16.879564285
Epoch 0: New minimal relative error: 16.88%, model saved.
Epoch: 25 Train: 4.302457333 Test: 4.257668495
Epoch 25: New minimal relative error: 4.26%, model saved.
Epoch: 50 Train: 3.995177269 Test: 4.058179855
Epoch 50: New minimal relative error: 4.06%, model saved.
Epoch: 75 Train: 3.954754829 Test: 4.038309097
Epoch 75: New minimal relative error: 4.04%, model saved.
Epoch: 100 Train: 3.929603577 Test: 4.025576115
Epoch 100: New minimal relative error: 4.03%, model saved.
Epoch: 125 Train: 3.924299717 Test: 4.016125679
Epoch 125: New minimal relative error: 4.02%, model saved.
Epoch: 150 Train: 3.915833712 Test: 4.010874271
Epoch 150: New minimal relative error: 4.01%, model saved.
Epoch: 175 Train: 3.929207802 Test: 4.025440216
Epoch: 200 Train: 3.939594269 Test: 4.036746502
Epoch: 225 Train: 3.936002016 Test: 4.028774738
Epoch: 250 Train: 3.931055784 Test: 4.020704746
Epoch: 275 Train: 3.918663502 Test: 4.008916855
Epoch 275: New minimal relative error: 4.01%, model saved.
Epoch: 300 Train: 3.899047375 Test: 4.002320290
Epoch 300: New minimal relative error: 4.00%, model saved.
Epoch: 325 Train: 3.891745567 Test: 4.002109528
Epoch 325: New minimal relative error: 4.00%, model saved.
Epoch: 350 Train: 3.890031338 Test: 3.997772217
Epoch 350: New minimal relative error: 4.00%, model saved.
Epoch: 375 Train: 3.879319191 Test: 3.987873793
Epoch 375: New minimal relative error: 3.99%, model saved.
Epoch: 400 Train: 3.865521431 Test: 3.971831083
Epoch 400: New minimal relative error: 3.97%, model saved.
Epoch: 425 Train: 3.838722706 Test: 3.945831299
Epoch 425: New minimal relative error: 3.95%, model saved.
Epoch: 450 Train: 3.832362175 Test: 3.941590548
Epoch 450: New minimal relative error: 3.94%, model saved.
Epoch: 475 Train: 3.818282127 Test: 3.923812389
Epoch 475: New minimal relative error: 3.92%, model saved.
Epoch: 500 Train: 3.800579548 Test: 3.910015106
Epoch 500: New minimal relative error: 3.91%, model saved.
Epoch: 525 Train: 3.774317741 Test: 3.868947029
Epoch 525: New minimal relative error: 3.87%, model saved.
Epoch: 550 Train: 3.771384001 Test: 3.873144150
Epoch: 575 Train: 3.778098583 Test: 3.863235712
Epoch 575: New minimal relative error: 3.86%, model saved.
Epoch: 600 Train: 3.777988434 Test: 3.850286484
Epoch 600: New minimal relative error: 3.85%, model saved.
Epoch: 625 Train: 3.772285938 Test: 3.837115049
Epoch 625: New minimal relative error: 3.84%, model saved.
Epoch: 650 Train: 3.767538071 Test: 3.822201490
Epoch 650: New minimal relative error: 3.82%, model saved.
Epoch: 675 Train: 3.760815620 Test: 3.818798304
Epoch 675: New minimal relative error: 3.82%, model saved.
Epoch: 700 Train: 3.757723093 Test: 3.811329365
Epoch 700: New minimal relative error: 3.81%, model saved.
Epoch: 725 Train: 3.758162975 Test: 3.813480377
Epoch: 750 Train: 3.751692057 Test: 3.801872730
Epoch 750: New minimal relative error: 3.80%, model saved.
Epoch: 775 Train: 3.756359100 Test: 3.807420731
Epoch: 800 Train: 3.736942053 Test: 3.789006710
Epoch 800: New minimal relative error: 3.79%, model saved.
Epoch: 825 Train: 3.741924286 Test: 3.794117451
Epoch: 850 Train: 3.706376076 Test: 3.755889416
Epoch 850: New minimal relative error: 3.76%, model saved.
Epoch: 875 Train: 3.743668079 Test: 3.805500031
Epoch: 900 Train: 3.746841431 Test: 3.817446470
Epoch: 925 Train: 3.733223677 Test: 3.805150032
Epoch: 950 Train: 3.741158009 Test: 3.808145046
Epoch: 975 Train: 3.732065678 Test: 3.830806255
Epoch: 1000 Train: 3.730907440 Test: 3.823599100
Epoch: 1025 Train: 3.726693630 Test: 3.813315868
Epoch: 1050 Train: 3.730706930 Test: 3.813882113
Epoch: 1075 Train: 3.722363949 Test: 3.804948330
Epoch: 1100 Train: 3.716550827 Test: 3.812177181
Epoch: 1125 Train: 3.721773624 Test: 3.808452129
Epoch: 1150 Train: 3.722490311 Test: 3.804164886
Epoch: 1175 Train: 3.732767105 Test: 3.810096979
Epoch: 1200 Train: 3.723057747 Test: 3.803617954
Epoch: 1225 Train: 3.742589951 Test: 3.822117329
Epoch: 1250 Train: 3.738503695 Test: 3.816565514
Epoch: 1275 Train: 3.753274679 Test: 3.819537640
Epoch: 1300 Train: 3.757917881 Test: 3.825645924
Epoch: 1325 Train: 3.747262955 Test: 3.821848392
Epoch: 1350 Train: 3.766432285 Test: 3.820112228
Epoch: 1375 Train: 3.765805244 Test: 3.823132753
Epoch: 1400 Train: 3.761768818 Test: 3.821977615
Epoch: 1425 Train: 3.759844303 Test: 3.821732283
Epoch: 1450 Train: 3.758531570 Test: 3.819197655
Epoch: 1475 Train: 3.764485359 Test: 3.824794292
Epoch: 1500 Train: 3.774283409 Test: 3.826453209
Epoch: 1525 Train: 3.785509348 Test: 3.834609985
Epoch: 1550 Train: 3.779892445 Test: 3.838484526
Epoch: 1575 Train: 3.777065277 Test: 3.835162401
Epoch: 1600 Train: 3.776975632 Test: 3.831685066
Epoch: 1625 Train: 3.772448063 Test: 3.829484940
Epoch: 1650 Train: 3.775289536 Test: 3.838806152
Epoch: 1675 Train: 3.772531033 Test: 3.836589813
Epoch: 1700 Train: 3.778320312 Test: 3.838173866
Epoch: 1725 Train: 3.789199829 Test: 3.843473434
Epoch: 1750 Train: 3.783032656 Test: 3.839657068
Epoch: 1775 Train: 3.788015366 Test: 3.838928699
Epoch: 1800 Train: 3.786082745 Test: 3.839247704
Epoch: 1825 Train: 3.780284882 Test: 3.839868069
Epoch: 1850 Train: 3.781595469 Test: 3.850855350
Epoch: 1875 Train: 3.782612085 Test: 3.845916748
Epoch: 1900 Train: 3.781846523 Test: 3.848688126
Epoch: 1925 Train: 3.787235260 Test: 3.862688541
Epoch: 1950 Train: 3.787642002 Test: 3.863903522
Epoch: 1975 Train: 3.785193205 Test: 3.861409426
Epoch: 2000 Train: 3.783342123 Test: 3.861341953
Epoch: 2025 Train: 3.781035423 Test: 3.860693932
Epoch: 2050 Train: 3.776763916 Test: 3.861843824
Epoch: 2075 Train: 3.788419008 Test: 3.875573158
Epoch: 2100 Train: 3.792103291 Test: 3.888480663
Epoch: 2125 Train: 3.798536301 Test: 3.891477346
Epoch: 2150 Train: 3.803493023 Test: 3.903446436
Epoch: 2175 Train: 3.795097351 Test: 3.897019386
Epoch: 2200 Train: 3.792316437 Test: 3.891737461
Epoch: 2225 Train: 3.782713175 Test: 3.881285191
Epoch: 2250 Train: 3.779763222 Test: 3.878110886
Epoch: 2275 Train: 3.776061535 Test: 3.874712944
Epoch: 2300 Train: 3.769514561 Test: 3.869109631
Epoch: 2325 Train: 3.767188549 Test: 3.864347219
Epoch: 2350 Train: 3.768451691 Test: 3.863326550
Epoch: 2375 Train: 3.767209053 Test: 3.858855724
Epoch: 2400 Train: 3.763498068 Test: 3.854888916
Epoch: 2425 Train: 3.761273861 Test: 3.851602554
Epoch: 2450 Train: 3.763239622 Test: 3.852572918
Epoch: 2475 Train: 3.756975889 Test: 3.848682404
Epoch: 2499 Train: 3.756803036 Test: 3.847459793
Training Loss: tensor(3.7568)
Test Loss: tensor(3.8475)
True Mean x: tensor(3.3019, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(3.2699, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(3.3662, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(0.0028, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(0.0064)
Jacobian term Test Loss: tensor(0.0065)
Learned LE: [1.1205102  0.37353134]
True LE: tensor([ 0.6932, -0.7017], dtype=torch.float64)
