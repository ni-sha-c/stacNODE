time_step: 0.01
lr: 0.001
weight_decay: 0.001
num_epoch: 10000
num_train: 10000
num_test: 8000
num_trans: 1000
batch_size: 1000
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 256
n_layers: 7
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE_new/
Epoch 0: New minimal relative error: 99.99%, model saved.
Epoch: 0 Train: 4079.54907 Test: 4234.12598
Epoch: 100 Train: 168.17503 Test: 161.27580
Epoch 200: New minimal relative error: 71.06%, model saved.
Epoch: 200 Train: 40.01776 Test: 60.19309
Epoch 300: New minimal relative error: 34.43%, model saved.
Epoch: 300 Train: 6.31967 Test: 6.94512
Epoch: 400 Train: 36.00757 Test: 9.98451
Epoch: 500 Train: 4.13434 Test: 3.72377
Epoch 600: New minimal relative error: 15.78%, model saved.
Epoch: 600 Train: 2.13348 Test: 2.80441
Epoch 700: New minimal relative error: 14.71%, model saved.
Epoch: 700 Train: 1.30862 Test: 2.02090
Epoch 800: New minimal relative error: 9.69%, model saved.
Epoch: 800 Train: 0.82041 Test: 1.45502
Epoch: 900 Train: 9.45133 Test: 15.54603
Epoch: 1000 Train: 0.93240 Test: 1.57322
Epoch: 1100 Train: 0.98505 Test: 1.53633
Epoch: 1200 Train: 6.26811 Test: 8.25781
Epoch: 1300 Train: 1.94134 Test: 2.36128
Epoch: 1400 Train: 0.49518 Test: 1.13219
Epoch: 1500 Train: 0.77787 Test: 1.02752
Epoch: 1600 Train: 0.43725 Test: 1.14704
Epoch: 1700 Train: 0.83662 Test: 1.19715
Epoch: 1800 Train: 1.31842 Test: 2.31223
Epoch: 1900 Train: 4.87673 Test: 5.13805
Epoch: 2000 Train: 0.24068 Test: 0.82508
Epoch: 2100 Train: 9.24985 Test: 13.73432
Epoch: 2200 Train: 3.08555 Test: 1.83029
Epoch: 2300 Train: 0.43822 Test: 1.20424
Epoch: 2400 Train: 0.13376 Test: 0.68269
Epoch: 2500 Train: 7.89966 Test: 8.72898
Epoch: 2600 Train: 1.64212 Test: 3.50409
Epoch: 2700 Train: 0.15518 Test: 0.67861
Epoch: 2800 Train: 0.10914 Test: 0.58548
Epoch: 2900 Train: 0.97257 Test: 1.77758
Epoch: 3000 Train: 0.72926 Test: 1.40332
Epoch: 3100 Train: 0.18544 Test: 0.64448
Epoch: 3200 Train: 0.84384 Test: 1.36641
Epoch: 3300 Train: 0.21394 Test: 0.65492
Epoch: 3400 Train: 1.72137 Test: 2.76980
Epoch: 3500 Train: 0.16678 Test: 0.67344
Epoch: 3600 Train: 0.66032 Test: 1.35967
Epoch: 3700 Train: 0.13196 Test: 0.60506
Epoch: 3800 Train: 0.39834 Test: 0.74680
Epoch: 3900 Train: 0.12466 Test: 0.54863
Epoch: 4000 Train: 0.17822 Test: 0.63322
Epoch: 4100 Train: 0.34216 Test: 0.74979
Epoch: 4200 Train: 0.08062 Test: 0.52460
Epoch: 4300 Train: 0.07670 Test: 0.54534
Epoch: 4400 Train: 0.11168 Test: 0.57378
Epoch: 4500 Train: 1.52254 Test: 1.56726
Epoch: 4600 Train: 0.09510 Test: 0.49581
Epoch: 4700 Train: 0.05431 Test: 0.46031
Epoch 4800: New minimal relative error: 7.65%, model saved.
Epoch: 4800 Train: 0.05907 Test: 0.49300
Epoch: 4900 Train: 0.33685 Test: 0.88549
Epoch: 5000 Train: 0.13946 Test: 0.54976
Epoch: 5100 Train: 0.42284 Test: 0.97508
Epoch: 5200 Train: 0.39162 Test: 0.77636
Epoch: 5300 Train: 0.07429 Test: 0.50148
Epoch: 5400 Train: 0.13736 Test: 0.65199
Epoch 5500: New minimal relative error: 6.41%, model saved.
Epoch: 5500 Train: 0.05720 Test: 0.48938
Epoch: 5600 Train: 0.13495 Test: 0.55071
Epoch: 5700 Train: 0.06735 Test: 0.49332
Epoch: 5800 Train: 0.03198 Test: 0.44330
Epoch: 5900 Train: 0.03074 Test: 0.45133
Epoch: 6000 Train: 0.03325 Test: 0.44997
Epoch: 6100 Train: 0.03184 Test: 0.46692
Epoch: 6200 Train: 0.28562 Test: 0.61921
Epoch: 6300 Train: 0.08808 Test: 0.68734
Epoch: 6400 Train: 0.39594 Test: 0.67977
Epoch: 6500 Train: 0.87925 Test: 1.15377
Epoch: 6600 Train: 0.05510 Test: 0.47996
Epoch: 6700 Train: 0.15374 Test: 0.64118
Epoch: 6800 Train: 0.09748 Test: 0.52689
Epoch: 6900 Train: 0.03713 Test: 0.46154
Epoch: 7000 Train: 0.03803 Test: 0.44773
Epoch: 7100 Train: 0.02469 Test: 0.44460
Epoch: 7200 Train: 0.02222 Test: 0.44940
Epoch: 7300 Train: 0.78102 Test: 1.23130
Epoch: 7400 Train: 0.06449 Test: 0.50676
Epoch: 7500 Train: 0.02099 Test: 0.44586
Epoch: 7600 Train: 0.03652 Test: 0.46770
Epoch: 7700 Train: 0.08825 Test: 0.53816
Epoch: 7800 Train: 0.43659 Test: 1.00260
Epoch: 7900 Train: 0.02260 Test: 0.45117
Epoch: 8000 Train: 0.01887 Test: 0.44450
Epoch: 8100 Train: 0.03668 Test: 0.45396
Epoch: 8200 Train: 0.01855 Test: 0.44848
Epoch: 8300 Train: 0.01690 Test: 0.43963
Epoch: 8400 Train: 0.01786 Test: 0.45201
Epoch: 8500 Train: 0.06707 Test: 0.46419
Epoch: 8600 Train: 0.64249 Test: 1.26298
Epoch: 8700 Train: 0.01589 Test: 0.44173
Epoch: 8800 Train: 0.01834 Test: 0.44562
Epoch: 8900 Train: 0.01557 Test: 0.44372
Epoch: 9000 Train: 0.08314 Test: 0.52403
Epoch: 9100 Train: 0.08059 Test: 0.53945
Epoch: 9200 Train: 0.01457 Test: 0.44478
Epoch: 9300 Train: 0.01521 Test: 0.44928
Epoch: 9400 Train: 0.01393 Test: 0.43718
Epoch: 9500 Train: 0.04566 Test: 0.45768
Epoch: 9600 Train: 0.01378 Test: 0.44188
Epoch: 9700 Train: 0.04529 Test: 0.44716
Epoch: 9800 Train: 0.01304 Test: 0.43736
Epoch: 9900 Train: 0.02370 Test: 0.49227
Epoch: 9999 Train: 0.01285 Test: 0.43940
Training Loss: tensor(0.0128)
Test Loss: tensor(0.4394)
Learned LE: [ 0.8866396  -0.03165934 -4.134731  ]
True LE: [ 8.8583082e-01  1.0322435e-03 -1.4557719e+01]
Relative Error: [4.484959  4.5399704 4.6493807 4.7837443 4.9970136 5.318363  5.569045
 5.5793123 5.41387   5.1574187 4.854586  4.5502973 4.281796  4.0672526
 3.9138157 3.8303456 3.8239849 3.887888  4.000845  4.141568  4.303424
 4.500165  4.764018  5.133353  5.626959  6.211947  6.791562  7.2369394
 7.4562526 7.448342  7.276131  6.9975405 6.6945553 6.4961367 6.459542
 6.542553  6.6901736 6.8682632 7.055496  7.2361603 7.4002476 7.536395
 7.589894  7.476598  7.2095027 6.885074  6.5661745 6.2745757 6.023828
 5.8224964 5.6657357 5.539028  5.426996  5.3175197 5.20132   5.0675774
 4.904635  4.7156253 4.5315967 4.3894506 4.2864857 4.1721616 4.0984783
 4.146667  4.2530956 4.3846045 4.6068435 4.932068  5.123855  5.057651
 4.8444147 4.5539203 4.230494  3.9255798 3.6766682 3.4959364 3.3861432
 3.3550632 3.4050379 3.5168984 3.6574628 3.8003967 3.9401033 4.0936213
 4.298359  4.6042    5.050249  5.624426  6.23573   6.7368507 7.001032
 7.003436  6.822443  6.5407977 6.219929  5.983226  5.921414  6.00471
 6.1709266 6.378893  6.601266  6.8160377 7.0099974 7.1674333 7.2124014
 7.056453  6.7541876 6.4161353 6.0896487 5.790141  5.534676  5.3374066
 5.195059  5.088173  4.996293  4.906957  4.8138027 4.707633  4.5689406
 4.385846  4.1849933 4.0129952 3.8999863 3.816398  3.7475996 3.782571
 3.8836074 4.009049  4.2324023 4.5475984 4.6722736 4.5433965 4.2957315
 3.9826899 3.6515002 3.3575199 3.1363719 2.9955297 2.9371316 2.9675071
 3.0774436 3.2323961 3.390797  3.5271268 3.6402795 3.7507463 3.8963888
 4.1289988 4.501862  5.0317535 5.651947  6.2111497 6.5461082 6.585548
 6.3975377 6.1028385 5.7650023 5.479391  5.3734293 5.4480596 5.634777
 5.8818035 6.1509824 6.410065  6.6391163 6.8173795 6.8499045 6.654049
 6.3245525 5.973611  5.6354694 5.3238235 5.0582337 4.858765  4.7268634
 4.6405563 4.57165   4.5047617 4.4374356 4.364183  4.2613244 4.0983543
 3.8905845 3.6913316 3.5470881 3.4754634 3.430444  3.4492183 3.540925
 3.6559408 3.866822  4.159992  4.222763  4.0503883 3.7841358 3.4640317
 3.1385512 2.8641677 2.6734679 2.572113  2.5635047 2.6454225 2.7950394
 2.972231  3.1340168 3.2545612 3.3354177 3.4021945 3.496617  3.6687028
 3.969337  4.431487  5.0273223 5.6318316 6.0606213 6.18228   6.0134025
 5.694232  5.334248  4.995671  4.8203626 4.866853  5.0695925 5.360941
 5.688604  6.0058556 6.280385  6.4847817 6.510011  6.2802024 5.925501
 5.5565124 5.2012143 4.875882  4.598723  4.390861  4.26168   4.1925817
 4.148159  4.1054263 4.064327  4.0259385 3.9680347 3.8439162 3.6429274
 3.4258578 3.248373  3.1540453 3.1374865 3.150995  3.2266755 3.3252192
 3.5044398 3.768533  3.789169  3.5962906 3.3303351 3.0201395 2.7118125
 2.4617488 2.2991114 2.2285554 2.2472308 2.343042  2.50402   2.6954732
 2.8630824 2.96988   3.0131693 3.0211513 3.0452626 3.149075  3.389616
 3.795398  4.350042  4.972525  5.50096   5.756588  5.670963  5.3429427
 4.9432306 4.5552173 4.2865925 4.267622  4.465218  4.794202  5.185877
 5.57663   5.9153633 6.1643505 6.2029386 5.9485917 5.563492  5.1659513
 4.7842193 4.44157   4.154981  3.938941  3.8058906 3.745691  3.7232704
 3.704844  3.6876326 3.681467  3.6704679 3.6047053 3.4356322 3.2109432
 3.01031   2.879963  2.8567555 2.8908684 2.9460797 3.0216734 3.1474485
 3.3772383 3.3876724 3.1977963 2.9520848 2.6669    2.3829517 2.1578078
 2.0177484 1.9587023 1.9608045 2.0387592 2.2123625 2.429066  2.6121624
 2.7147434 2.7281833 2.6747348 2.6036024 2.5896537 2.7205684 3.0566196
 3.5828497 4.2132926 4.8227587 5.2431827 5.3272223 5.070906  4.631813
 4.1886663 3.8248339 3.6883929 3.830125  4.163823  4.6055036 5.0773187
 5.504943  5.8322186 5.930587  5.676744  5.2532544 4.81196   4.38893
 4.0157385 3.715533  3.4955368 3.3606164 3.3048854 3.297723  3.301486
 3.3034418 3.320992  3.3503196 3.3499181 3.2512765 3.0414977 2.8237982
 2.6684852 2.609807  2.6505764 2.706467  2.753634  2.8105366 2.9872446
 3.0266573 2.8600996 2.6522515 2.4057035 2.1493537 1.9455997 1.822833
 1.7494982 1.6962919 1.7579967 1.9528422 2.1917002 2.3888083 2.4960139
 2.5008311 2.4157898 2.2736604 2.1340299 2.0920515 2.2607937 2.6955106
 3.327528 ]
