time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 10000
num_test: 6000
num_trans: 500
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 1024
n_layers: 5
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 102.52%, model saved.
Epoch: 0 Train: 3837.97803 Test: 3839.11938
Epoch 100: New minimal relative error: 65.97%, model saved.
Epoch: 100 Train: 14.18453 Test: 45.23054
Epoch 200: New minimal relative error: 24.28%, model saved.
Epoch: 200 Train: 2.44514 Test: 40.27687
Epoch: 300 Train: 3.15669 Test: 46.72084
Epoch: 400 Train: 12.90993 Test: 55.82904
Epoch: 500 Train: 11.82265 Test: 63.79133
Epoch: 600 Train: 7.12006 Test: 62.11348
Epoch: 700 Train: 4.98662 Test: 70.46456
Epoch: 800 Train: 6.78320 Test: 78.98544
Epoch: 900 Train: 0.31584 Test: 79.53099
Epoch: 1000 Train: 2.44224 Test: 89.74957
Epoch: 1100 Train: 1.91364 Test: 93.37485
Epoch: 1200 Train: 1.30768 Test: 101.93619
Epoch: 1300 Train: 2.27764 Test: 110.13820
Epoch: 1400 Train: 2.47801 Test: 121.32368
Epoch: 1500 Train: 0.81444 Test: 127.23616
Epoch: 1600 Train: 2.40983 Test: 143.03091
Epoch 1700: New minimal relative error: 18.60%, model saved.
Epoch: 1700 Train: 0.76158 Test: 151.85637
Epoch 1800: New minimal relative error: 18.52%, model saved.
Epoch: 1800 Train: 1.84959 Test: 164.93570
Epoch: 1900 Train: 1.04258 Test: 182.87189
Epoch: 2000 Train: 0.70296 Test: 189.77995
Epoch: 2100 Train: 2.15912 Test: 208.02701
Epoch: 2200 Train: 0.12502 Test: 221.66591
Epoch: 2300 Train: 5.95400 Test: 233.54080
Epoch: 2400 Train: 0.36501 Test: 250.08043
Epoch: 2500 Train: 0.45158 Test: 257.41287
Epoch: 2600 Train: 2.30344 Test: 276.00003
Epoch: 2700 Train: 0.99233 Test: 291.08395
Epoch: 2800 Train: 0.47799 Test: 307.15164
Epoch: 2900 Train: 0.77719 Test: 323.26291
Epoch: 3000 Train: 0.53580 Test: 332.15997
Epoch: 3100 Train: 0.36414 Test: 351.47205
Epoch: 3200 Train: 0.23051 Test: 362.07642
Epoch: 3300 Train: 0.98046 Test: 376.37711
Epoch: 3400 Train: 2.02650 Test: 391.09088
Epoch: 3500 Train: 0.72705 Test: 405.55814
Epoch: 3600 Train: 0.11597 Test: 423.46753
Epoch: 3700 Train: 0.84787 Test: 430.51083
Epoch: 3800 Train: 3.38400 Test: 440.67755
Epoch: 3900 Train: 0.56419 Test: 455.31305
Epoch: 4000 Train: 0.65145 Test: 462.38492
Epoch: 4100 Train: 0.04093 Test: 477.88248
Epoch: 4200 Train: 0.15865 Test: 483.81784
Epoch: 4300 Train: 0.06743 Test: 498.88452
Epoch: 4400 Train: 0.25923 Test: 510.18271
Epoch: 4500 Train: 0.18731 Test: 517.58307
Epoch: 4600 Train: 0.33770 Test: 525.76074
Epoch: 4700 Train: 0.42465 Test: 541.21918
Epoch: 4800 Train: 0.49153 Test: 549.15375
Epoch: 4900 Train: 0.35600 Test: 560.38379
Epoch: 5000 Train: 0.18660 Test: 568.17377
Epoch: 5100 Train: 0.55076 Test: 581.20227
Epoch: 5200 Train: 0.61305 Test: 586.67322
Epoch: 5300 Train: 0.20284 Test: 595.80652
Epoch: 5400 Train: 0.21736 Test: 603.54254
Epoch: 5500 Train: 0.24284 Test: 609.93182
Epoch: 5600 Train: 0.74674 Test: 617.19720
Epoch: 5700 Train: 0.18592 Test: 624.99945
Epoch: 5800 Train: 0.11312 Test: 633.71381
Epoch: 5900 Train: 0.16381 Test: 638.71021
Epoch: 6000 Train: 1.82608 Test: 640.85352
Epoch: 6100 Train: 0.19676 Test: 655.58722
Epoch: 6200 Train: 0.04420 Test: 665.50372
Epoch: 6300 Train: 0.08739 Test: 673.64722
Epoch: 6400 Train: 0.52186 Test: 675.11499
Epoch: 6500 Train: 0.55791 Test: 692.24774
Epoch: 6600 Train: 0.14256 Test: 694.32349
Epoch: 6700 Train: 0.02430 Test: 701.37787
Epoch: 6800 Train: 0.57415 Test: 710.04486
Epoch: 6900 Train: 0.02682 Test: 712.74811
Epoch: 7000 Train: 0.06127 Test: 724.01917
Epoch: 7100 Train: 0.14579 Test: 724.04797
Epoch: 7200 Train: 0.01837 Test: 732.60437
Epoch: 7300 Train: 0.22979 Test: 737.00824
Epoch: 7400 Train: 0.10672 Test: 742.89319
Epoch: 7500 Train: 0.00906 Test: 748.12732
Epoch: 7600 Train: 0.09007 Test: 754.28320
Epoch: 7700 Train: 0.03908 Test: 757.84637
Epoch: 7800 Train: 0.19487 Test: 763.88593
Epoch: 7900 Train: 0.05224 Test: 767.29138
Epoch: 8000 Train: 0.08993 Test: 774.80646
Epoch: 8100 Train: 0.16205 Test: 778.97406
Epoch: 8200 Train: 0.01639 Test: 782.69342
Epoch: 8300 Train: 0.01518 Test: 785.83008
Epoch: 8400 Train: 0.01695 Test: 792.16638
Epoch: 8500 Train: 0.15459 Test: 796.52057
Epoch: 8600 Train: 0.04308 Test: 800.56787
Epoch: 8700 Train: 0.23155 Test: 805.14050
Epoch: 8800 Train: 0.06425 Test: 809.60376
Epoch: 8900 Train: 0.07179 Test: 811.88068
Epoch: 9000 Train: 0.07065 Test: 816.44043
Epoch: 9100 Train: 0.02604 Test: 817.01965
Epoch: 9200 Train: 0.03217 Test: 822.69611
Epoch: 9300 Train: 0.52423 Test: 817.76709
Epoch: 9400 Train: 0.00793 Test: 828.75372
Epoch: 9500 Train: 0.13220 Test: 830.52106
Epoch: 9600 Train: 0.01065 Test: 835.13049
Epoch: 9700 Train: 0.16879 Test: 837.29370
Epoch: 9800 Train: 0.01159 Test: 841.83124
Epoch: 9900 Train: 0.01063 Test: 843.19684
Epoch: 9999 Train: 0.02803 Test: 846.27710
Training Loss: tensor(0.0280)
Test Loss: tensor(846.2771)
Learned LE: [ 0.94326276  0.07957566 -4.783634  ]
True LE: [ 8.6080432e-01  5.4964172e-03 -1.4536659e+01]
Relative Error: [ 9.205755  11.257089  13.484855  15.75027   17.870447  19.638233
 20.858675  21.40138   21.244486  20.476542  19.25229   17.738766
 16.092377  14.473774  13.0586815 11.999789  11.359954  11.099575
 11.136394  11.395386  11.813495  12.335149  12.92473   13.583763
 14.351773  15.281674  16.398825  17.660921  18.94055   20.06825
 20.911228  21.386982  21.462132  21.198334  20.695484  19.978601
 19.030485  17.89872   16.717484  15.634413  14.713961  13.919104
 13.173316  12.416717  11.612126  10.736121   9.781053   8.765409
  7.733554   6.731938   5.790042   4.9266076  4.16501    3.5392025
  3.0859914  2.829169   2.7713287  2.9086044  3.2555447  3.8498917
  4.734734   5.939634   7.4692144  9.293799  11.338811  13.478597
 15.541249  17.324821  18.626087  19.288864  19.25859   18.601503
 17.467566  16.02758   14.436884  12.848781  11.439894  10.3829975
  9.76201    9.534394   9.600876   9.876754  10.296592  10.7976885
 11.328308  11.874338  12.474601  13.206981  14.147795  15.319838
 16.6503    17.96884   19.084177  19.857979  20.205614  20.140451
 19.782267  19.205893  18.383728  17.317137  16.126732  15.004388
 14.079906  13.340304  12.686136  12.033137  11.33847   10.574543
  9.722211   8.78621    7.8063173  6.8362384  5.9121175  5.0529675
  4.2782073  3.6182318  3.109614   2.778009   2.621144   2.6170897
  2.7594924  3.0830061  3.6519606  4.526769   5.738273   7.277213
  9.088157  11.063447  13.046007  14.84396   16.252731  17.091768
 17.261196  16.785307  15.796341  14.468469  12.9614725 11.420915
 10.016365   8.941009   8.320138   8.1237755  8.229624   8.534266
  8.97135    9.4779625  9.987387  10.458707  10.906246  11.405737
 12.070381  12.995936  14.199278  15.577589  16.92367   18.02476
 18.726196  18.95746   18.796352  18.383818  17.739538  16.812157
 15.657698  14.475545  13.482402  12.743788  12.160753  11.609607
 11.031639  10.4003725  9.685206   8.86778    7.9699435  7.048112
  6.1493645  5.2963076  4.5050764  3.8008764  3.2201018  2.7987058
  2.5488946  2.444833   2.4479086  2.5531878  2.811756   3.3117037
  4.131751   5.3033433  6.8014593  8.544454  10.395912  12.177947
 13.692361  14.745049  15.188744  14.982531  14.214201  13.051081
 11.663871  10.196942   8.8040695  7.6860547  7.028506   6.8517265
  7.010685   7.3616767  7.8303857  8.365141   8.89701    9.359539
  9.728556  10.043017  10.406627  10.962222  11.825262  13.0125885
 14.403031  15.76464   16.857424  17.504822  17.661898  17.45649
 17.01653   16.315083  15.306975  14.113511  12.998474  12.165294
 11.592345  11.123518  10.6547365 10.160491   9.61167    8.96297
  8.198792   7.361327   6.5106816  5.679624   4.8828883  4.1389275
  3.4778686  2.9403467  2.5646274  2.3564582  2.2729914  2.2597947
  2.3043888  2.4610329  2.8390396  3.5445352  4.616886   6.0176544
  7.6431804  9.336304  10.908936  12.167214  12.934081  13.094634
 12.653648  11.737661  10.524043   9.170329   7.8168416  6.645893
  5.8937182  5.692624   5.9132547  6.338396   6.8544855  7.4254
  8.004075   8.513633   8.895849   9.144733   9.313254   9.517545
  9.916842  10.647391  11.740394  13.081795  14.43795   15.541466
 16.18374   16.330536  16.128166  15.688041  14.963989  13.923801
 12.739418  11.717229  11.027042  10.5727    10.18539    9.802292
  9.414842   8.9722595  8.410077   7.7204957  6.9622173  6.188792
  5.4195566  4.6666203  3.9503005  3.3008795  2.7613966  2.38111
  2.1753657  2.0942519  2.063287   2.0461478  2.0781417  2.276863
  2.7912664  3.6901891  4.9314494  6.3971186  7.9179473  9.303166
 10.368882  10.955111  10.967075  10.430845   9.4869795  8.310337
  7.050244   5.858703   4.9647365  4.6333365  4.877688   5.411951
  6.011674   6.620638   7.2385473  7.8163614  8.2687     8.550677
  8.675396   8.705955   8.756266   8.975412   9.503571  10.399155
 11.591644  12.890405  14.025126  14.735347  14.949989  14.800976
 14.401425  13.717185  12.713109  11.573075  10.628642  10.028916
  9.641508   9.31823    9.029624   8.765677   8.4478     7.992097
  7.3975654  6.733989   6.0453234  5.3412204  4.6324534  3.9378424
  3.2802212  2.697877   2.2553003  2.0011997  1.9026349  1.8655956
  1.8146402  1.7394907  1.7259935  1.9599974  2.5892336  3.595382
  4.8562875  6.1994967  7.433962   8.385312   8.907805   8.909622
  8.407673   7.5335846  6.4570384  5.3297076  4.3303447  3.747562
  3.8427591  4.4551144  5.2024503  5.898551   6.5375104  7.152981
  7.700676   8.079065   8.248147   8.242291 ]
