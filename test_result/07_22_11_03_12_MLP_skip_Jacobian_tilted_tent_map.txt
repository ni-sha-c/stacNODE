time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 3000
num_test: 3000
num_val: 0
num_trans: 0
loss_type: Jacobian
dyn_sys: tilted_tent_map
model_type: MLP_skip
s: 0.2
n_hidden: 512
n_layers: 2
reg_param: 200.0
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 9.777094841 Test: 6.992835045
Epoch 0: New minimal relative error: 6.99%, model saved.
Epoch: 100 Train: 0.210266218 Test: 0.202030241
Epoch 100: New minimal relative error: 0.20%, model saved.
Epoch: 200 Train: 0.140443012 Test: 0.081105471
Epoch 200: New minimal relative error: 0.08%, model saved.
Epoch: 300 Train: 0.086284287 Test: 0.060068205
Epoch 300: New minimal relative error: 0.06%, model saved.
Epoch: 400 Train: 0.079604805 Test: 0.060292285
Epoch: 500 Train: 0.078122251 Test: 0.059748318
Epoch 500: New minimal relative error: 0.06%, model saved.
Epoch: 600 Train: 0.079520456 Test: 0.060588486
Epoch: 700 Train: 0.078161061 Test: 0.059850581
Epoch: 800 Train: 0.077085756 Test: 0.049504522
Epoch 800: New minimal relative error: 0.05%, model saved.
Epoch: 900 Train: 0.081667326 Test: 0.059236221
Epoch: 1000 Train: 0.080731034 Test: 0.027325815
Epoch 1000: New minimal relative error: 0.03%, model saved.
Epoch: 1100 Train: 0.075525098 Test: 0.053106111
Epoch: 1200 Train: 0.064050473 Test: 0.054364208
Epoch: 1300 Train: 0.072810344 Test: 0.060158491
Epoch: 1400 Train: 0.079082623 Test: 0.060762860
Epoch: 1500 Train: 0.087371774 Test: 0.032824937
Epoch: 1600 Train: 0.077672631 Test: 0.057273161
Epoch: 1700 Train: 0.076253705 Test: 0.011827107
Epoch 1700: New minimal relative error: 0.01%, model saved.
Epoch: 1800 Train: 0.055856738 Test: 0.015690399
Epoch: 1900 Train: 0.046162952 Test: 0.006284233
Epoch 1900: New minimal relative error: 0.01%, model saved.
Epoch: 2000 Train: 0.026682869 Test: 0.020203402
Epoch: 2100 Train: 0.026412876 Test: 0.027208591
Epoch: 2200 Train: 0.047546517 Test: 0.003016946
Epoch 2200: New minimal relative error: 0.00%, model saved.
Epoch: 2300 Train: 0.026902216 Test: 0.054053660
Epoch: 2400 Train: 0.041464966 Test: 0.005366643
Epoch: 2500 Train: 0.012979322 Test: 0.051480465
Epoch: 2600 Train: 0.020567112 Test: 0.054964203
Epoch: 2700 Train: 0.008765760 Test: 0.011346480
Epoch: 2800 Train: 0.033091445 Test: 0.002449248
Epoch 2800: New minimal relative error: 0.00%, model saved.
Epoch: 2900 Train: 0.017625079 Test: 0.001440234
Epoch 2900: New minimal relative error: 0.00%, model saved.
Epoch: 3000 Train: 0.020255920 Test: 0.000961925
Epoch 3000: New minimal relative error: 0.00%, model saved.
Epoch: 3100 Train: 0.018788280 Test: 0.000424284
Epoch 3100: New minimal relative error: 0.00%, model saved.
Epoch: 3200 Train: 0.054361045 Test: 0.011172670
Epoch: 3300 Train: 0.005803522 Test: 0.004570954
Epoch: 3400 Train: 0.009641520 Test: 0.009965353
Epoch: 3500 Train: 0.019587114 Test: 0.006976643
Epoch: 3600 Train: 0.040287327 Test: 0.002101646
Epoch: 3700 Train: 0.004769376 Test: 0.024402479
Epoch: 3800 Train: 0.020046107 Test: 0.000996858
Epoch: 3900 Train: 0.009682201 Test: 0.036638744
Epoch: 4000 Train: 0.019394737 Test: 0.008698949
Epoch: 4100 Train: 0.013098326 Test: 0.002799143
Epoch: 4200 Train: 0.019504944 Test: 0.004352340
Epoch: 4300 Train: 0.019742282 Test: 0.005459059
Epoch: 4400 Train: 0.015978431 Test: 0.012448876
Epoch: 4500 Train: 0.020129429 Test: 0.008363158
Epoch: 4600 Train: 0.028536746 Test: 0.031290740
Epoch: 4700 Train: 0.014722525 Test: 0.006391859
Epoch: 4800 Train: 0.020874795 Test: 0.008054489
Epoch: 4900 Train: 0.009287563 Test: 0.035666149
Epoch: 5000 Train: 0.018639648 Test: 0.007814925
Epoch: 5100 Train: 0.020603377 Test: 0.012082153
Epoch: 5200 Train: 0.017167926 Test: 0.007935352
Epoch: 5300 Train: 0.019138787 Test: 0.009368912
Epoch: 5400 Train: 0.028252413 Test: 0.019851144
Epoch: 5500 Train: 0.020600904 Test: 0.011473446
Epoch: 5600 Train: 0.019846573 Test: 0.005672378
Epoch: 5700 Train: 0.019414991 Test: 0.010658190
Epoch: 5800 Train: 0.020658884 Test: 0.008950594
Epoch: 5900 Train: 0.020037832 Test: 0.015878893
Epoch: 6000 Train: 0.021285553 Test: 0.008435909
Epoch: 6100 Train: 0.043854158 Test: 0.004165816
Epoch: 6200 Train: 0.038746074 Test: 0.019467840
Epoch: 6300 Train: 0.035316017 Test: 0.034899697
Epoch: 6400 Train: 0.038895961 Test: 0.031068571
Epoch: 6500 Train: 0.071379758 Test: 0.036582902
Epoch: 6600 Train: 0.017893972 Test: 0.006410589
Epoch: 6700 Train: 0.019802330 Test: 0.005829638
Epoch: 6800 Train: 0.021712512 Test: 0.006792230
Epoch: 6900 Train: 0.005207917 Test: 0.027554534
Epoch: 7000 Train: 0.020749232 Test: 0.008094216
Epoch: 7100 Train: 0.020342540 Test: 0.008528884
Epoch: 7200 Train: 0.020417932 Test: 0.008704511
Epoch: 7300 Train: 0.020376466 Test: 0.009756539
Epoch: 7400 Train: 0.030056747 Test: 0.025624892
Epoch: 7500 Train: 0.038479682 Test: 0.024327572
Epoch: 7600 Train: 0.017083075 Test: 0.008438827
Epoch: 7700 Train: 0.015408260 Test: 0.005698069
Epoch: 7800 Train: 0.020552762 Test: 0.006582018
Epoch: 7900 Train: 0.019973747 Test: 0.004148626
Epoch: 8000 Train: 0.020430654 Test: 0.003060420
Epoch: 8100 Train: 0.020455973 Test: 0.002016687
Epoch: 8200 Train: 0.007209285 Test: 0.013914576
Epoch: 8300 Train: 0.020237494 Test: 0.005559949
Epoch: 8400 Train: 0.016319368 Test: 0.009343049
Epoch: 8500 Train: 0.021436945 Test: 0.002318662
Epoch: 8600 Train: 0.022087486 Test: 0.002240458
Epoch: 8700 Train: 0.020118529 Test: 0.005624203
Epoch: 8800 Train: 0.020884400 Test: 0.005790891
Epoch: 8900 Train: 0.018321119 Test: 0.008049059
Epoch: 9000 Train: 0.018811462 Test: 0.007271432
Epoch: 9100 Train: 0.019487714 Test: 0.006300573
Epoch: 9200 Train: 0.019869493 Test: 0.007210868
Epoch: 9300 Train: 0.018215191 Test: 0.007784402
Epoch: 9400 Train: 0.020593876 Test: 0.008989368
Epoch: 9500 Train: 0.019137198 Test: 0.005112301
Epoch: 9600 Train: 0.020243475 Test: 0.000957737
Epoch: 9700 Train: 0.011359406 Test: 0.002884078
Epoch: 9800 Train: 0.019291259 Test: 0.005957852
Epoch: 9900 Train: 0.016135355 Test: 0.006989872
Epoch: 9999 Train: 0.020678096 Test: 0.002039289
Training Loss: tensor(0.0207)
Test Loss: tensor(0.0020)
True Mean x: tensor(0.9604, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(0.9984, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(0.3595, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(0.3336, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(0.0001)
Jacobian term Test Loss: tensor(1.0153e-05)
Learned LE: [[0.6676326]]
True LE: [[0.6567932]]
Norm Diff:: tensor(0.0108)
