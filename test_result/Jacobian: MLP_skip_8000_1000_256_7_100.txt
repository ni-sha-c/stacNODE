time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 1000
loss_type: Jacobian
dyn_sys: lorenz
model_type: MLP_skip
n_hidden: 256
n_layers: 7
reg_param: 100
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_Jac/
Epoch 0: New minimal relative error: 100.19%, model saved.
Epoch: 0 Train: 9649.93066 Test: 4237.86328
Epoch: 80 Train: 2754.69238 Test: 1204.04590
Epoch: 160 Train: 2740.79907 Test: 1155.40063
Epoch: 240 Train: 2699.18872 Test: 1516.71887
Epoch: 320 Train: 1892.20496 Test: 729.27417
Epoch 400: New minimal relative error: 88.64%, model saved.
Epoch: 400 Train: 995.88477 Test: 319.92975
Epoch 480: New minimal relative error: 26.89%, model saved.
Epoch: 480 Train: 379.45331 Test: 62.83976
Epoch: 560 Train: 218.87436 Test: 46.65005
Epoch: 640 Train: 180.08299 Test: 33.03821
Epoch 720: New minimal relative error: 19.80%, model saved.
Epoch: 720 Train: 118.00626 Test: 19.66619
Epoch: 800 Train: 116.59622 Test: 30.90246
Epoch: 880 Train: 84.46423 Test: 13.82472
Epoch 960: New minimal relative error: 19.12%, model saved.
Epoch: 960 Train: 72.33134 Test: 6.49975
Epoch 1040: New minimal relative error: 5.90%, model saved.
Epoch: 1040 Train: 64.58608 Test: 6.64319
Epoch: 1120 Train: 106.99068 Test: 29.91272
Epoch: 1200 Train: 53.56100 Test: 4.19344
Epoch: 1280 Train: 71.23070 Test: 11.82160
Epoch: 1360 Train: 47.09121 Test: 2.77003
Epoch: 1440 Train: 42.91493 Test: 2.26716
Epoch: 1520 Train: 43.57368 Test: 2.26489
Epoch: 1600 Train: 38.49664 Test: 2.57346
Epoch: 1680 Train: 38.85052 Test: 6.33640
Epoch: 1760 Train: 43.05801 Test: 8.16540
Epoch: 1840 Train: 35.27859 Test: 2.74241
Epoch: 1920 Train: 35.57685 Test: 3.78844
Epoch: 2000 Train: 31.18330 Test: 1.42776
Epoch: 2080 Train: 35.65992 Test: 10.94386
Epoch: 2160 Train: 25.92671 Test: 1.07062
Epoch: 2240 Train: 34.43707 Test: 5.32463
Epoch: 2320 Train: 30.99862 Test: 4.43324
Epoch: 2400 Train: 23.50591 Test: 0.89983
Epoch: 2480 Train: 24.13237 Test: 1.93322
Epoch: 2560 Train: 26.74745 Test: 4.22804
Epoch: 2640 Train: 29.04965 Test: 3.10793
Epoch: 2720 Train: 20.89062 Test: 0.69477
Epoch: 2800 Train: 26.31308 Test: 3.43226
Epoch: 2880 Train: 21.25500 Test: 0.95428
Epoch: 2960 Train: 21.90495 Test: 4.04111
Epoch: 3040 Train: 26.16343 Test: 3.15460
Epoch: 3120 Train: 24.59131 Test: 4.41611
Epoch: 3200 Train: 18.69467 Test: 0.69953
Epoch: 3280 Train: 18.54684 Test: 1.42979
Epoch 3360: New minimal relative error: 5.33%, model saved.
Epoch: 3360 Train: 18.59851 Test: 1.78271
Epoch: 3440 Train: 18.51749 Test: 0.85227
Epoch: 3520 Train: 22.45437 Test: 3.61185
Epoch: 3600 Train: 18.39935 Test: 1.30894
Epoch: 3680 Train: 23.79517 Test: 5.42065
Epoch: 3760 Train: 17.92530 Test: 2.23019
Epoch: 3840 Train: 16.99870 Test: 1.20509
Epoch 3920: New minimal relative error: 4.40%, model saved.
Epoch: 3920 Train: 15.50271 Test: 0.68875
Epoch: 4000 Train: 19.12015 Test: 2.90913
Epoch: 4080 Train: 17.93075 Test: 3.89591
Epoch 4160: New minimal relative error: 3.40%, model saved.
Epoch: 4160 Train: 14.31819 Test: 1.08111
Epoch: 4240 Train: 13.93767 Test: 0.36393
Epoch: 4320 Train: 14.90814 Test: 0.84606
Epoch: 4400 Train: 14.46273 Test: 1.26217
Epoch: 4480 Train: 14.92525 Test: 0.85204
Epoch: 4560 Train: 18.14360 Test: 6.58210
Epoch: 4640 Train: 13.19455 Test: 0.31707
Epoch: 4720 Train: 17.08460 Test: 2.42658
Epoch: 4800 Train: 13.79339 Test: 0.71231
Epoch: 4880 Train: 13.73683 Test: 0.71010
Epoch: 4960 Train: 12.60668 Test: 0.27927
Epoch: 5040 Train: 13.36743 Test: 0.41192
Epoch: 5120 Train: 13.17617 Test: 0.51065
Epoch: 5200 Train: 12.91814 Test: 1.28065
Epoch: 5280 Train: 12.68159 Test: 1.93203
Epoch: 5360 Train: 12.26174 Test: 0.32359
Epoch: 5440 Train: 11.71418 Test: 1.21418
Epoch: 5520 Train: 11.99556 Test: 0.62735
Epoch 5600: New minimal relative error: 2.62%, model saved.
Epoch: 5600 Train: 11.60907 Test: 0.55772
Epoch: 5680 Train: 15.65884 Test: 1.97930
Epoch: 5760 Train: 11.46902 Test: 0.59966
Epoch: 5840 Train: 13.78890 Test: 1.17743
Epoch: 5920 Train: 11.22265 Test: 0.39345
Epoch: 6000 Train: 11.00254 Test: 0.39365
Epoch: 6080 Train: 10.93203 Test: 0.71865
Epoch: 6160 Train: 12.74222 Test: 1.02911
Epoch: 6240 Train: 11.72171 Test: 0.49271
Epoch: 6320 Train: 10.95536 Test: 0.60670
Epoch: 6400 Train: 10.60575 Test: 0.49705
Epoch: 6480 Train: 10.60380 Test: 0.35247
Epoch: 6560 Train: 10.65194 Test: 0.70378
Epoch: 6640 Train: 11.16371 Test: 0.36506
Epoch: 6720 Train: 10.77535 Test: 0.29018
Epoch: 6800 Train: 11.84019 Test: 0.51177
Epoch: 6880 Train: 12.25870 Test: 0.72818
Epoch: 6960 Train: 10.45430 Test: 0.27537
Epoch: 7040 Train: 10.40192 Test: 0.45674
Epoch: 7120 Train: 10.30921 Test: 0.56762
Epoch: 7200 Train: 10.82969 Test: 0.31791
Epoch: 7280 Train: 10.75326 Test: 0.28303
Epoch: 7360 Train: 10.10343 Test: 0.27207
Epoch: 7440 Train: 10.15035 Test: 0.25774
Epoch: 7520 Train: 10.00443 Test: 0.26356
Epoch: 7600 Train: 11.14577 Test: 0.58603
Epoch: 7680 Train: 9.74643 Test: 0.25202
Epoch: 7760 Train: 10.45562 Test: 0.33370
Epoch: 7840 Train: 9.88461 Test: 0.23705
Epoch: 7920 Train: 9.78872 Test: 0.26612
Epoch: 7999 Train: 9.45482 Test: 0.23137
Training Loss: tensor(9.4548)
Test Loss: tensor(0.2314)
Learned LE: [  0.9613996   -0.11137877 -14.519696  ]
True LE: [ 8.6566359e-01 -2.7891735e-03 -1.4537111e+01]
Relative Error: [3.1665184 3.4221654 3.4687977 3.4305398 3.415534  3.4762728 3.64633
 3.8746822 4.0270896 4.1100407 3.8975983 3.5555642 3.1880624 2.7843769
 2.1928227 1.8060247 1.6974787 1.592442  1.6640401 1.6332743 1.6965988
 1.989007  2.416365  2.4665613 2.1518059 1.9671592 1.7265306 1.4228705
 1.2774454 1.2759076 1.3920412 1.4381019 1.384015  1.2194729 1.3034453
 1.4786503 1.7124273 1.5977824 1.3619716 1.4115546 2.1731045 2.806725
 3.0224485 3.1577754 3.1891804 3.4086645 3.2356195 3.090092  3.16942
 3.2821555 3.3292315 2.9693742 2.8860905 3.0245047 3.2099073 3.2517564
 3.155593  2.7640145 2.8637085 2.9657311 3.0066416 2.9321284 3.0357754
 3.2949739 3.3149009 3.1999946 3.1082938 3.1896453 3.27468   3.4333124
 3.8965042 3.9171193 3.6902833 3.2846446 2.889355  2.4808714 2.0188885
 1.6772525 1.5897348 1.5308553 1.523264  1.4446524 1.4617854 1.6947302
 2.1074526 2.1395218 2.0328157 1.7858196 1.5758883 1.3723062 1.1833881
 1.2578115 1.4181064 1.4839276 1.3641875 1.21947   1.2425374 1.4481009
 1.6514599 1.660629  1.4061149 1.6564893 2.4010463 3.060091  3.315186
 3.4415278 3.4723864 3.6455803 3.5267544 3.3385801 3.2858205 3.3821304
 3.3596818 2.9098403 2.8195114 2.8850117 2.8117528 2.9364886 2.8568892
 2.571691  2.5220473 2.6378849 2.6936202 2.6421983 2.8185105 3.1642008
 3.1848214 3.0251505 2.878388  2.9732828 2.9911435 3.1343813 3.455103
 3.7042835 3.5368004 3.069069  2.685308  2.3149564 1.9450493 1.5839293
 1.4390417 1.4735695 1.466708  1.3920003 1.3668101 1.4871011 1.750944
 1.9237081 1.9071513 1.6679356 1.5484021 1.3916785 1.2109078 1.2576058
 1.4463856 1.5216856 1.3831538 1.2560327 1.1981844 1.3831499 1.5536821
 1.6690933 1.618687  1.8364198 2.5942116 3.3233469 3.615237  3.6995695
 3.7124228 3.807403  3.7786658 3.5119162 3.5540183 3.5148923 3.4093797
 2.9235802 2.7262871 2.694764  2.5579822 2.5851192 2.6205888 2.291262
 2.0995226 2.128094  2.131507  2.1416473 2.3442736 2.6880047 2.6856668
 2.7085197 2.7100453 2.7669108 2.786287  2.8130813 3.0121348 3.2097545
 3.3462315 3.0517626 2.6346385 2.3277385 1.9583577 1.60642   1.4758406
 1.4583385 1.4278094 1.3996509 1.3853385 1.3864806 1.4880236 1.7565542
 1.7423875 1.6371595 1.6410779 1.4586692 1.4070914 1.3852627 1.5270951
 1.5783485 1.4666945 1.3084048 1.1834185 1.3196423 1.4374619 1.5856864
 1.6937637 2.0462143 2.7378063 3.4488068 3.86191   3.9065592 3.890243
 3.8560548 3.8958442 3.7451534 3.792278  3.8043835 3.583467  3.0819626
 2.7732356 2.6149485 2.3442807 2.2740397 2.2139068 2.0887322 1.7028445
 1.624314  1.6655567 1.707433  1.9071487 2.2190042 2.196347  2.059288
 2.2370517 2.490498  2.6414926 2.572438  2.6631272 2.6735222 2.9307377
 3.0525882 2.7084832 2.2569575 1.9376891 1.6709771 1.4792916 1.4041337
 1.4826442 1.4459765 1.3944938 1.4770136 1.3691604 1.6215966 1.6679975
 1.6454806 1.6669558 1.5256318 1.621671  1.5871001 1.6213636 1.6974725
 1.5716588 1.343325  1.1942308 1.2296888 1.3565061 1.4999324 1.7235454
 2.120415  2.861101  3.509539  4.1069636 4.160836  4.122128  3.9157326
 3.9742482 3.8736708 3.9065228 4.0364075 3.872115  3.236348  2.86349
 2.548004  2.3799384 2.0574334 1.9251522 1.662315  1.4303635 1.1410978
 1.3084711 1.4628583 1.5957499 1.907835  1.9445443 1.7550048 1.8068585
 2.1311255 2.3079135 2.3439186 2.3635945 2.3961763 2.515847  2.8028226
 2.7799842 2.3055294 1.8648698 1.5690295 1.4084713 1.4319068 1.5219297
 1.589776  1.5526063 1.5308582 1.4252863 1.4273105 1.5603776 1.6153104
 1.7603656 1.6766297 1.606482  1.7158823 1.7330716 1.8537762 1.7500417
 1.551733  1.2800403 1.1572973 1.2491467 1.4144971 1.6573963 2.179414
 2.8024297 3.4261715 4.0285172 4.317343  4.244986  4.0656524 3.955973
 4.052451  4.06599   3.9774675 4.022737  3.5064816 3.045455  2.4998448
 2.3801286 2.01512   1.766067  1.2318047 1.1613894 0.906404  0.9909002
 1.258947  1.3584188 1.6906668 1.8280083 1.628093  1.5200093 1.838661
 2.015102  2.0882149 1.9904879 2.1580966 2.2564645 2.441405  2.5112288
 2.455429  1.859208  1.4551917 1.3093281 1.3500798 1.4913112 1.7117966
 1.769731  1.6876541 1.588033  1.48849   1.3742678 1.4560804 1.6938697
 1.8405154]
