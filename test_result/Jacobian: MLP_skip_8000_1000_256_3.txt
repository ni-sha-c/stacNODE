time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 1000
loss_type: Jacobian
dyn_sys: lorenz
model_type: MLP_skip
n_hidden: 256
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_Jac/
Epoch 0: New minimal relative error: 100.65%, model saved.
Epoch: 0 Train: 173487.71875 Test: 4095.62402
Epoch: 80 Train: 45753.28125 Test: 1844.72437
Epoch: 160 Train: 46803.16797 Test: 1865.00037
Epoch: 240 Train: 45182.61328 Test: 1603.14050
Epoch 320: New minimal relative error: 93.19%, model saved.
Epoch: 320 Train: 43399.64844 Test: 1506.36377
Epoch 400: New minimal relative error: 71.16%, model saved.
Epoch: 400 Train: 46354.60156 Test: 1588.17590
Epoch 480: New minimal relative error: 70.68%, model saved.
Epoch: 480 Train: 42597.89062 Test: 1453.64905
Epoch 560: New minimal relative error: 62.72%, model saved.
Epoch: 560 Train: 43263.96875 Test: 1589.28308
Epoch: 640 Train: 43361.96875 Test: 1633.97656
Epoch: 720 Train: 43692.44922 Test: 1563.97375
Epoch: 800 Train: 43093.07422 Test: 1414.00244
Epoch: 880 Train: 42186.65234 Test: 1447.90332
Epoch: 960 Train: 46426.19531 Test: 1582.86096
Epoch: 1040 Train: 41193.93750 Test: 1502.78369
Epoch: 1120 Train: 44566.98828 Test: 1579.18616
Epoch: 1200 Train: 40139.54297 Test: 1408.49170
Epoch 1280: New minimal relative error: 58.34%, model saved.
Epoch: 1280 Train: 39855.87500 Test: 1436.92688
Epoch: 1360 Train: 46903.67969 Test: 1564.53430
Epoch: 1440 Train: 41777.07812 Test: 1533.20227
Epoch: 1520 Train: 44043.50781 Test: 1597.94629
Epoch: 1600 Train: 39730.09766 Test: 1399.98840
Epoch: 1680 Train: 42493.23438 Test: 1456.04651
Epoch: 1760 Train: 44187.47656 Test: 1542.03577
Epoch: 1840 Train: 43018.27344 Test: 1530.65247
Epoch: 1920 Train: 43316.71875 Test: 1523.88562
Epoch: 2000 Train: 41769.43359 Test: 1525.34473
Epoch: 2080 Train: 42748.84766 Test: 1416.20203
Epoch: 2160 Train: 40555.63281 Test: 1363.15356
Epoch 2240: New minimal relative error: 57.03%, model saved.
Epoch: 2240 Train: 38900.78906 Test: 1449.94861
Epoch: 2320 Train: 42179.28125 Test: 1427.14868
Epoch: 2400 Train: 40802.03906 Test: 1423.95679
Epoch: 2480 Train: 41069.99609 Test: 1420.17896
Epoch: 2560 Train: 40960.89062 Test: 1442.42139
Epoch: 2640 Train: 43263.91016 Test: 1513.67981
Epoch: 2720 Train: 39928.36719 Test: 1454.71204
Epoch: 2800 Train: 39650.20703 Test: 1358.64441
Epoch: 2880 Train: 40979.11719 Test: 1435.72302
Epoch: 2960 Train: 40349.75781 Test: 1503.55725
Epoch: 3040 Train: 39475.95703 Test: 1448.65796
Epoch: 3120 Train: 39306.50000 Test: 1338.11389
Epoch: 3200 Train: 38810.43750 Test: 1347.71704
Epoch 3280: New minimal relative error: 56.56%, model saved.
Epoch: 3280 Train: 40041.11328 Test: 1337.56848
Epoch: 3360 Train: 36598.75391 Test: 1244.59143
Epoch: 3440 Train: 36287.75781 Test: 1200.27197
Epoch: 3520 Train: 34799.12500 Test: 1144.43542
Epoch: 3600 Train: 35784.13672 Test: 1092.24548
Epoch: 3680 Train: 33245.10156 Test: 1028.17529
Epoch: 3760 Train: 29971.85352 Test: 925.68781
Epoch 3840: New minimal relative error: 55.88%, model saved.
Epoch: 3840 Train: 28983.05078 Test: 810.26782
Epoch: 3920 Train: 27041.40625 Test: 685.06097
Epoch: 4000 Train: 25346.54688 Test: 589.08893
Epoch: 4080 Train: 24259.83398 Test: 507.77332
Epoch: 4160 Train: 23297.85742 Test: 469.59531
Epoch: 4240 Train: 22780.78711 Test: 458.78772
Epoch: 4320 Train: 21786.74414 Test: 431.67328
Epoch: 4400 Train: 20809.02344 Test: 405.79517
Epoch: 4480 Train: 19393.05859 Test: 358.38382
Epoch: 4560 Train: 18321.87305 Test: 307.78745
Epoch: 4640 Train: 16566.80469 Test: 252.47447
Epoch: 4720 Train: 13293.49805 Test: 165.18094
Epoch: 4800 Train: 10292.42090 Test: 123.39960
Epoch: 4880 Train: 7426.03857 Test: 101.38562
Epoch: 4960 Train: 5485.14893 Test: 68.41967
Epoch 5040: New minimal relative error: 31.15%, model saved.
Epoch: 5040 Train: 4280.00781 Test: 43.61030
Epoch: 5120 Train: 3560.02100 Test: 32.10862
Epoch: 5200 Train: 2996.83618 Test: 22.96392
Epoch 5280: New minimal relative error: 19.98%, model saved.
Epoch: 5280 Train: 2606.19727 Test: 16.95767
Epoch: 5360 Train: 2264.12451 Test: 11.63978
Epoch 5440: New minimal relative error: 8.75%, model saved.
Epoch: 5440 Train: 2069.23022 Test: 9.22980
Epoch: 5520 Train: 1901.98694 Test: 8.35624
Epoch: 5600 Train: 1734.67175 Test: 7.01549
Epoch: 5680 Train: 1630.04346 Test: 6.36155
Epoch: 5760 Train: 1538.27258 Test: 5.71078
Epoch: 5840 Train: 1499.02466 Test: 5.27738
Epoch: 5920 Train: 1420.33972 Test: 5.01881
Epoch 6000: New minimal relative error: 8.59%, model saved.
Epoch: 6000 Train: 1377.01245 Test: 4.34156
Epoch: 6080 Train: 1336.75061 Test: 5.08148
Epoch: 6160 Train: 1334.98962 Test: 7.17797
Epoch: 6240 Train: 1276.72119 Test: 10.28910
Epoch: 6320 Train: 1297.21582 Test: 6.89044
Epoch: 6400 Train: 1300.06299 Test: 4.50886
Epoch: 6480 Train: 1155.09985 Test: 7.66206
Epoch 6560: New minimal relative error: 4.46%, model saved.
Epoch: 6560 Train: 1158.31506 Test: 3.38491
Epoch: 6640 Train: 1146.39441 Test: 4.59548
Epoch: 6720 Train: 1168.16968 Test: 4.82280
Epoch: 6800 Train: 1145.89624 Test: 3.87372
Epoch: 6880 Train: 1096.61426 Test: 4.31115
Epoch: 6960 Train: 1014.43170 Test: 3.24118
Epoch: 7040 Train: 959.44659 Test: 2.79406
Epoch: 7120 Train: 926.11633 Test: 2.30051
Epoch: 7200 Train: 903.88965 Test: 1.91223
Epoch: 7280 Train: 864.76001 Test: 1.81585
Epoch: 7360 Train: 831.21149 Test: 1.77226
Epoch: 7440 Train: 795.53711 Test: 1.61918
Epoch 7520: New minimal relative error: 4.06%, model saved.
Epoch: 7520 Train: 784.46460 Test: 1.58250
Epoch: 7600 Train: 767.51276 Test: 1.37845
Epoch: 7680 Train: 737.86609 Test: 1.32487
Epoch: 7760 Train: 705.73407 Test: 1.27274
Epoch: 7840 Train: 687.91010 Test: 1.04063
Epoch: 7920 Train: 667.93420 Test: 1.04047
Epoch: 7999 Train: 663.30029 Test: 1.26657
Training Loss: tensor(663.3003)
Test Loss: tensor(1.2666)
Learned LE: [ 8.7081677e-01 -9.2995502e-03 -1.4517228e+01]
True LE: [ 8.5894495e-01  1.1693463e-02 -1.4539968e+01]
Relative Error: [4.489788   4.17565    3.709871   3.0884805  2.3130465  1.8205926
 1.3912632  1.1975591  1.4149585  1.6617496  1.8731737  2.042881
 2.2126188  2.4076176  1.9876566  1.5056338  1.2395726  1.0149609
 0.92626053 1.1632355  1.6554492  2.4668996  2.071492   1.783428
 1.6660022  1.7808431  2.1946208  2.7454636  3.1262393  3.278439
 3.6114314  4.198975   4.445633   4.815403   5.3472004  6.160764
 6.832939   6.6381087  6.0586023  5.7177563  5.519707   5.214273
 3.9631832  2.8631873  2.086993   1.6418118  1.4550948  1.3990438
 1.3786709  1.8523239  2.2011666  2.417038   2.535189   2.5821273
 2.4912574  2.5107236  2.9348154  3.1780317  3.385022   3.795727
 4.220687   4.4321804  4.2164273  3.977822   3.5689871  2.9891248
 2.015994   1.4131029  0.90497816 0.84158874 1.2031484  1.6194733
 1.9586616  2.2599504  2.542284   2.7729993  2.3840513  1.7989987
 1.1342887  0.941421   0.8938801  1.1098042  1.6150621  2.082047
 1.6542643  1.4196312  1.3359039  1.3918396  1.7840922  2.3423636
 2.8541384  3.0254762  3.3449357  3.9361603  4.1675153  4.519135
 5.064923   5.885055   6.3161793  6.1655774  5.783884   5.3923173
 5.1456404  5.08835    3.978293   2.9563875  2.2347822  1.801875
 1.5929407  1.4856035  1.6921738  2.1052544  2.3886755  2.5492651
 2.6138399  2.6332324  2.5747573  2.618241   2.7291574  2.7327876
 2.9678142  3.3830836  3.89237    4.1787605  3.985127   3.8377085
 3.5000026  2.8101976  1.933824   1.3286853  0.6886932  0.51725215
 1.0103097  1.5567598  2.0267015  2.447965   2.8412075  3.1156065
 2.7800393  1.968605   1.1375394  0.85515183 0.7637183  0.95747906
 1.4765563  1.704627   1.3612468  1.1787336  1.1248387  1.1824006
 1.4670291  2.0330994  2.6998222  2.85283    3.1484003  3.755898
 3.9751153  4.302565   4.9066963  5.646514   5.8813868  5.805129
 5.5659995  5.0405426  4.729453   4.611545   4.13464    3.1199045
 2.3830445  1.9154869  1.6596953  1.5079713  1.9325416  2.2918394
 2.511616   2.6073537  2.6168053  2.5938568  2.5948772  2.644494
 2.562077   2.340952   2.545867   2.946054   3.5586     3.9681158
 3.8378448  3.7689779  3.5215168  2.7826636  2.0073006  1.5506972
 1.0486354  0.49646822 0.8454738  1.4628303  2.0443597  2.586825
 3.054131   3.479516   3.009633   2.2270658  1.4427706  0.8830643
 0.7562933  0.849218   1.3146176  1.3782545  1.2273986  1.0467353
 1.0038419  1.0565704  1.2481751  1.7978003  2.5060272  2.7668424
 2.9932573  3.6550217  3.8690221  4.167833   4.7524014  5.287743
 5.35475    5.349594   5.2150164  4.650732   4.2738085  4.1321025
 4.193534   3.2821364  2.529102   1.9993488  1.676077   1.6138488
 2.0414143  2.378893   2.5786982  2.6080093  2.552308   2.4810927
 2.4826057  2.6061394  2.3549023  2.1749048  2.1941261  2.5759637
 3.2186058  3.8095217  3.8316336  3.7931774  3.6573548  2.9523346
 2.2584724  1.8526319  1.7609046  0.9780041  0.7943943  1.3269099
 1.9931082  2.615089   3.2240644  3.7664587  3.2376506  2.5553956
 1.7969121  1.045868   0.7693498  0.7873138  1.1362066  1.145999
 1.1621526  1.1130303  0.940703   0.9696193  1.1486796  1.5945253
 1.913785   1.9886248  1.9126498  2.5540373  3.0157928  3.6249235
 4.504615   4.970588   4.9381647  4.963277   4.756279   4.3801913
 3.9051268  3.774517   3.8484342  3.322861   2.644994   2.0887964
 1.6849451  1.7041434  2.0972838  2.3888693  2.5315845  2.5430589
 2.4333608  2.298691   2.279201   2.3998902  2.1170595  1.9893242
 2.0797114  2.381097   2.9288478  3.7090764  3.9780006  3.9376478
 3.918802   3.3489194  2.7039242  2.3256443  2.2489495  1.7434765
 1.0795876  1.2200341  1.850856   2.5631227  3.3766394  4.0684266
 3.6727183  2.910636   2.1950812  1.4492697  0.942785   0.91307396
 1.0668073  1.0166858  1.0447329  1.3396466  1.0650903  0.8851855
 1.049142   1.0629439  1.2505376  1.401687   1.2060663  1.5661217
 2.09299    2.3971307  3.4864182  4.765224   4.657419   4.585602
 4.4160285  4.2362013  3.710106   3.4991593  3.4837537  3.4447641
 2.6411216  2.17373    1.7507795  1.7693568  2.125575   2.377743
 2.46632    2.4011204  2.238711   2.0550354  1.9911299  2.0710285
 1.8325362  1.7937342  1.9961201  2.4293606  2.9033606  3.614356
 4.2730026  4.27659    4.343381   3.9872866  3.401916   2.9970565
 2.8151135  2.5442996  1.8061194  1.3545414  1.6576521  2.5434303
 3.4379117  4.2078667  3.8515172  3.2015786  2.630133   1.9858437
 1.2624258  1.0461149  1.1981744  1.1797389  1.0765976  1.2382193
 1.3385413  0.9515824  0.8393193  1.0028038 ]
