time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 10000
num_test: 8000
num_val: 3000
num_trans: 0
loss_type: Jacobian
dyn_sys: plucked_tent_map
model_type: MLP
s: 0.2
n_hidden: 512
n_layers: 3
reg_param: 500
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 2038.604980469 Test: 2.158196926
Epoch 0: New minimal relative error: 2.16%, model saved.
Epoch: 100 Train: 145.862670898 Test: 2.280641317
Epoch: 200 Train: 111.263633728 Test: 0.000325807
Epoch 200: New minimal relative error: 0.00%, model saved.
Epoch: 300 Train: 108.851295471 Test: 0.001904964
Epoch: 400 Train: 98.363632202 Test: 0.002030028
Epoch: 500 Train: 96.973106384 Test: 0.001345990
Epoch: 600 Train: 95.858238220 Test: 0.003199423
Epoch: 700 Train: 94.908851624 Test: 0.000096649
Epoch 700: New minimal relative error: 0.00%, model saved.
Epoch: 800 Train: 94.603385925 Test: 0.007867537
Epoch: 900 Train: 95.551765442 Test: 0.006210693
Epoch: 1000 Train: 94.688461304 Test: 0.001956139
Epoch: 1100 Train: 89.888648987 Test: 0.000933446
Epoch: 1200 Train: 85.897743225 Test: 0.002423998
Epoch: 1300 Train: 79.547340393 Test: 0.001091419
Epoch: 1400 Train: 79.096282959 Test: 0.001159178
Epoch: 1500 Train: 81.691238403 Test: 0.010909135
Epoch: 1600 Train: 76.193496704 Test: 0.002181664
Epoch: 1700 Train: 72.591972351 Test: 0.005573269
Epoch: 1800 Train: 71.043319702 Test: 0.000107294
Epoch: 1900 Train: 71.718772888 Test: 0.001736087
Epoch: 2000 Train: 69.045425415 Test: 0.002513309
Epoch: 2100 Train: 74.529678345 Test: 0.013379664
Epoch: 2200 Train: 66.477058411 Test: 0.002116796
Epoch: 2300 Train: 64.967247009 Test: 0.017598342
Epoch: 2400 Train: 62.090995789 Test: 0.001044261
Epoch: 2500 Train: 63.943653107 Test: 0.000464793
Epoch: 2600 Train: 59.980266571 Test: 0.005535662
Epoch: 2700 Train: 59.014896393 Test: 0.000190505
Epoch: 2800 Train: 58.290882111 Test: 0.000057989
Epoch 2800: New minimal relative error: 0.00%, model saved.
Epoch: 2900 Train: 57.330631256 Test: 0.000488785
Epoch: 3000 Train: 54.329994202 Test: 0.004606483
Epoch: 3100 Train: 53.937171936 Test: 0.000197126
Epoch: 3200 Train: 47.647563934 Test: 0.000510485
Epoch: 3300 Train: 47.037567139 Test: 0.006186888
Epoch: 3400 Train: 45.053272247 Test: 0.000646170
Epoch: 3500 Train: 40.343284607 Test: 0.002467440
Epoch: 3600 Train: 37.948829651 Test: 0.000196428
Epoch: 3700 Train: 35.542148590 Test: 0.000673030
Epoch: 3800 Train: 34.117309570 Test: 0.000184832
Epoch: 3900 Train: 33.554985046 Test: 0.000707269
Epoch: 4000 Train: 33.213447571 Test: 0.000163675
Epoch: 4100 Train: 33.330928802 Test: 0.000321880
Epoch: 4200 Train: 32.427963257 Test: 0.000425645
Epoch: 4300 Train: 34.747100830 Test: 0.001236920
Epoch: 4400 Train: 31.692806244 Test: 0.000283959
Epoch: 4500 Train: 31.280378342 Test: 0.000568253
Epoch: 4600 Train: 30.986848831 Test: 0.000388890
Epoch: 4700 Train: 30.803443909 Test: 0.000334375
Epoch: 4800 Train: 30.687400818 Test: 0.000091811
Epoch: 4900 Train: 29.611639023 Test: 0.006114780
Epoch: 5000 Train: 24.857524872 Test: 0.000033383
Epoch 5000: New minimal relative error: 0.00%, model saved.
Epoch: 5100 Train: 23.201360703 Test: 0.000459608
Epoch: 5200 Train: 21.801879883 Test: 0.000120626
Epoch: 5300 Train: 22.611316681 Test: 0.000075988
Epoch: 5400 Train: 20.988819122 Test: 0.000040727
Epoch: 5500 Train: 20.105808258 Test: 0.000076663
Epoch: 5600 Train: 19.234205246 Test: 0.000148274
Epoch: 5700 Train: 18.391111374 Test: 0.000029073
Epoch 5700: New minimal relative error: 0.00%, model saved.
Epoch: 5800 Train: 23.029298782 Test: 0.000871212
Epoch: 5900 Train: 19.237445831 Test: 0.001150828
Epoch: 6000 Train: 18.728929520 Test: 0.000091784
Epoch: 6100 Train: 17.256910324 Test: 0.000122358
Epoch: 6200 Train: 17.057928085 Test: 0.000061221
Epoch: 6300 Train: 16.865913391 Test: 0.000057975
Epoch: 6400 Train: 16.620029449 Test: 0.000162431
Epoch: 6500 Train: 16.429714203 Test: 0.000038180
Epoch: 6600 Train: 16.283407211 Test: 0.000037363
Epoch: 6700 Train: 21.214179993 Test: 0.000730455
Epoch: 6800 Train: 15.910571098 Test: 0.000120718
Epoch: 6900 Train: 15.807433128 Test: 0.000048430
Epoch: 7000 Train: 15.777925491 Test: 0.000076449
Epoch: 7100 Train: 15.538191795 Test: 0.000152171
Epoch: 7200 Train: 15.464997292 Test: 0.000056513
Epoch: 7300 Train: 15.355718613 Test: 0.000084270
Epoch: 7400 Train: 15.324448586 Test: 0.000013132
Epoch 7400: New minimal relative error: 0.00%, model saved.
Epoch: 7500 Train: 15.241255760 Test: 0.000059059
Epoch: 7600 Train: 15.278915405 Test: 0.000037530
Epoch: 7700 Train: 15.158671379 Test: 0.000047000
Epoch: 7800 Train: 20.262075424 Test: 0.000268888
Epoch: 7900 Train: 15.093605995 Test: 0.000043463
Epoch: 8000 Train: 18.711206436 Test: 0.001325876
Epoch: 8100 Train: 15.036334991 Test: 0.000036822
Epoch: 8200 Train: 15.101068497 Test: 0.000048390
Epoch: 8300 Train: 15.019330978 Test: 0.000036265
Epoch: 8400 Train: 15.018331528 Test: 0.000020235
Epoch: 8500 Train: 15.056855202 Test: 0.000006051
Epoch 8500: New minimal relative error: 0.00%, model saved.
Epoch: 8600 Train: 14.910686493 Test: 0.000013889
Epoch: 8700 Train: 14.882068634 Test: 0.000031358
Epoch: 8800 Train: 14.857218742 Test: 0.000020408
Epoch: 8900 Train: 14.847212791 Test: 0.000011232
Epoch: 9000 Train: 14.827165604 Test: 0.000010849
Epoch: 9100 Train: 15.174778938 Test: 0.000047280
Epoch: 9200 Train: 14.746574402 Test: 0.000026261
Epoch: 9300 Train: 14.721583366 Test: 0.000029254
Epoch: 9400 Train: 14.698082924 Test: 0.000016731
Epoch: 9500 Train: 14.682679176 Test: 0.000015056
Epoch: 9600 Train: 14.641406059 Test: 0.000022327
Epoch: 9700 Train: 14.682792664 Test: 0.000042777
Epoch: 9800 Train: 14.594784737 Test: 0.000019493
Epoch: 9900 Train: 14.564060211 Test: 0.000025530
Epoch: 9999 Train: 14.565453529 Test: 0.000012948
Training Loss: tensor(14.5655)
Test Loss: tensor(1.2948e-05)
True Mean x: tensor(1.0986, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(1.0762, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(0.2580, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(0.2775, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(0.0291)
Jacobian term Test Loss: tensor(0.0292)
Learned LE: [[0.67841405]]
True LE: [[0.6668132]]
Norm Diff:: tensor(0.0116)
