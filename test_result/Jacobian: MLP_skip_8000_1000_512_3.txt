time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 1000
loss_type: Jacobian
dyn_sys: lorenz
model_type: MLP_skip
n_hidden: 512
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_Jac/
Epoch 0: New minimal relative error: 99.81%, model saved.
Epoch: 0 Train: 172297.43750 Test: 4111.67676
Epoch: 80 Train: 46587.92578 Test: 1888.02844
Epoch: 160 Train: 42501.91406 Test: 1567.45325
Epoch 240: New minimal relative error: 79.92%, model saved.
Epoch: 240 Train: 40316.44531 Test: 1271.67029
Epoch: 320 Train: 43754.52344 Test: 1430.66516
Epoch: 400 Train: 40446.50000 Test: 1428.55457
Epoch: 480 Train: 44247.18750 Test: 1589.59387
Epoch: 560 Train: 37467.51172 Test: 1304.17383
Epoch: 640 Train: 50469.90234 Test: 1516.39673
Epoch 720: New minimal relative error: 70.74%, model saved.
Epoch: 720 Train: 36306.06250 Test: 1395.96094
Epoch: 800 Train: 40014.87109 Test: 1406.58447
Epoch: 880 Train: 45812.23438 Test: 1557.65747
Epoch: 960 Train: 42384.26953 Test: 1599.49988
Epoch: 1040 Train: 43115.61719 Test: 1437.87402
Epoch: 1120 Train: 42216.51172 Test: 1508.89307
Epoch 1200: New minimal relative error: 64.15%, model saved.
Epoch: 1200 Train: 41294.08984 Test: 1498.09656
Epoch 1280: New minimal relative error: 61.91%, model saved.
Epoch: 1280 Train: 40524.07422 Test: 1432.45105
Epoch: 1360 Train: 43497.78125 Test: 1554.69885
Epoch 1440: New minimal relative error: 60.00%, model saved.
Epoch: 1440 Train: 42634.70312 Test: 1529.58337
Epoch: 1520 Train: 42613.58594 Test: 1459.87708
Epoch: 1600 Train: 42126.50000 Test: 1430.38391
Epoch: 1680 Train: 40470.25781 Test: 1463.80786
Epoch: 1760 Train: 41006.17578 Test: 1424.03711
Epoch: 1840 Train: 43204.14453 Test: 1550.94385
Epoch 1920: New minimal relative error: 58.43%, model saved.
Epoch: 1920 Train: 38219.10156 Test: 1450.08655
Epoch: 2000 Train: 39519.87891 Test: 1367.53162
Epoch: 2080 Train: 40148.38281 Test: 1429.73157
Epoch: 2160 Train: 38580.07812 Test: 1401.51831
Epoch: 2240 Train: 39208.58984 Test: 1379.75110
Epoch: 2320 Train: 36734.44922 Test: 1283.13171
Epoch: 2400 Train: 33392.93359 Test: 1109.63440
Epoch: 2480 Train: 33753.37500 Test: 1087.68347
Epoch: 2560 Train: 31614.32031 Test: 1008.67810
Epoch: 2640 Train: 30177.28516 Test: 881.29175
Epoch: 2720 Train: 30007.41406 Test: 869.66534
Epoch: 2800 Train: 28714.89648 Test: 837.04523
Epoch: 2880 Train: 27450.95508 Test: 707.92535
Epoch: 2960 Train: 28035.62305 Test: 769.27966
Epoch: 3040 Train: 27532.17188 Test: 757.13293
Epoch: 3120 Train: 26440.11914 Test: 637.75458
Epoch: 3200 Train: 26682.07422 Test: 693.70001
Epoch: 3280 Train: 25599.44531 Test: 630.85022
Epoch: 3360 Train: 25365.51562 Test: 606.03448
Epoch: 3440 Train: 24458.35742 Test: 549.72009
Epoch: 3520 Train: 23222.20508 Test: 496.88370
Epoch: 3600 Train: 23390.67969 Test: 518.66779
Epoch: 3680 Train: 23997.81445 Test: 533.35059
Epoch: 3760 Train: 21352.80273 Test: 447.45450
Epoch: 3840 Train: 20496.77344 Test: 379.32269
Epoch: 3920 Train: 19419.20312 Test: 344.75583
Epoch: 4000 Train: 18706.04297 Test: 301.02701
Epoch: 4080 Train: 17161.23242 Test: 249.72917
Epoch: 4160 Train: 16192.89355 Test: 218.41949
Epoch: 4240 Train: 14707.89746 Test: 181.92783
Epoch: 4320 Train: 12989.44727 Test: 148.33360
Epoch: 4400 Train: 10913.45898 Test: 120.53990
Epoch: 4480 Train: 6972.31299 Test: 99.47006
Epoch 4560: New minimal relative error: 53.55%, model saved.
Epoch: 4560 Train: 4563.36523 Test: 54.29331
Epoch 4640: New minimal relative error: 31.93%, model saved.
Epoch: 4640 Train: 3704.91064 Test: 38.54039
Epoch 4720: New minimal relative error: 11.12%, model saved.
Epoch: 4720 Train: 3070.33765 Test: 20.90378
Epoch: 4800 Train: 3094.62988 Test: 43.78716
Epoch: 4880 Train: 2888.11084 Test: 24.30245
Epoch: 4960 Train: 2420.09790 Test: 13.33934
Epoch: 5040 Train: 2146.11182 Test: 8.77547
Epoch: 5120 Train: 2025.87634 Test: 8.29178
Epoch: 5200 Train: 1871.74768 Test: 7.00268
Epoch: 5280 Train: 1758.00342 Test: 7.15483
Epoch: 5360 Train: 1732.24072 Test: 12.79333
Epoch: 5440 Train: 1801.12390 Test: 25.58771
Epoch: 5520 Train: 1719.65503 Test: 11.05757
Epoch: 5600 Train: 1575.92419 Test: 16.66327
Epoch: 5680 Train: 1513.91504 Test: 11.98767
Epoch: 5760 Train: 1477.61072 Test: 6.98843
Epoch: 5840 Train: 1368.88000 Test: 4.63492
Epoch: 5920 Train: 1292.43921 Test: 4.09052
Epoch: 6000 Train: 1229.87451 Test: 3.35815
Epoch: 6080 Train: 1172.71899 Test: 3.70486
Epoch: 6160 Train: 1153.34875 Test: 3.65405
Epoch: 6240 Train: 1073.31006 Test: 2.78489
Epoch: 6320 Train: 999.30762 Test: 3.11014
Epoch: 6400 Train: 973.24359 Test: 3.62655
Epoch: 6480 Train: 903.92175 Test: 2.39810
Epoch: 6560 Train: 866.47882 Test: 3.66080
Epoch: 6640 Train: 913.10278 Test: 3.54773
Epoch: 6720 Train: 895.19409 Test: 2.70703
Epoch: 6800 Train: 813.67377 Test: 2.49266
Epoch: 6880 Train: 791.53064 Test: 3.97265
Epoch: 6960 Train: 757.87512 Test: 1.75281
Epoch 7040: New minimal relative error: 9.26%, model saved.
Epoch: 7040 Train: 727.79987 Test: 1.83804
Epoch: 7120 Train: 743.50226 Test: 2.47819
Epoch: 7200 Train: 722.62781 Test: 1.93370
Epoch: 7280 Train: 696.41510 Test: 2.45279
Epoch 7360: New minimal relative error: 8.99%, model saved.
Epoch: 7360 Train: 750.19409 Test: 2.46170
Epoch 7440: New minimal relative error: 4.85%, model saved.
Epoch: 7440 Train: 703.72443 Test: 1.57210
Epoch: 7520 Train: 634.54083 Test: 1.23893
Epoch: 7600 Train: 612.02563 Test: 1.19572
Epoch: 7680 Train: 603.66589 Test: 1.31969
Epoch: 7760 Train: 587.68768 Test: 1.48110
Epoch: 7840 Train: 648.65826 Test: 2.90623
Epoch: 7920 Train: 665.02393 Test: 2.15812
Epoch: 7999 Train: 685.71649 Test: 2.34727
Training Loss: tensor(685.7165)
Test Loss: tensor(2.3473)
Learned LE: [  0.9577182   -0.08447693 -14.499363  ]
True LE: [ 8.6807925e-01  1.1021867e-03 -1.4538665e+01]
Relative Error: [0.53020626 1.0553877  1.4637519  1.2366651  1.0540472  0.71476835
 0.6917886  0.44399178 0.8986595  1.2816904  1.5836626  1.633107
 1.6929569  1.6991625  1.6032265  1.3946733  1.5850796  1.838455
 2.192213   2.620315   2.9832     3.4854405  3.2659478  3.0313199
 2.6987848  2.7766378  3.1485503  3.6744058  4.2332935  4.783524
 5.4759703  5.9835944  6.075162   5.9194574  5.767125   5.6329327
 5.567386   5.7905703  5.9527936  6.0888414  6.258612   6.486585
 6.1586185  6.0327406  5.959096   5.553108   4.7327847  4.059586
 3.6232677  3.2338648  2.6001425  1.8907281  1.1738232  0.86463594
 1.0798146  1.234176   1.1738043  1.040478   0.72323966 0.7488333
 0.8717027  0.73694056 0.5601861  0.7917207  1.4620957  1.4215207
 1.1623231  0.8350748  0.62611353 0.5213938  0.86960244 1.2802277
 1.5470221  1.5484935  1.4425294  1.4033916  1.515621   2.0078297
 2.5155976  2.7132974  2.9450736  3.2901776  3.5054789  3.5365455
 3.3416276  3.1740108  3.0049694  2.613238   2.7588942  2.8743918
 3.2075691  3.9315765  4.8814793  5.5558405  5.822375   5.8130417
 5.7560005  5.626453   5.403884   5.27795    5.4461155  5.579605
 5.6474714  5.922143   5.704253   5.5381417  5.588745   5.311323
 4.190087   3.468271   3.025051   2.683327   2.293734   1.5338798
 0.9628364  0.60344577 0.9668246  1.4012512  1.6138147  1.6932942
 1.5626624  1.172468   1.0959061  1.0686561  0.95137966 0.8375467
 1.2238005  1.6042218  1.3206211  1.0457606  0.819548   0.67790675
 0.82586527 1.184989   1.4656695  1.4690961  1.3022033  1.461564
 1.8227428  2.6102657  3.18055    3.497702   3.6637838  3.8188193
 4.1371183  4.2023087  4.242834   3.8191066  3.382237   2.8784978
 2.5873597  2.5482762  2.6815114  2.7133636  3.9382207  4.8874846
 5.4445853  5.7375865  5.793197   5.7351274  5.4702926  5.138724
 5.0310297  5.0152626  5.0922537  5.1742306  5.437356   5.0661173
 4.8286686  4.8925457  4.075233   3.0371344  2.5461106  2.339703
 2.034289   1.5762532  1.0934641  0.9681407  0.8929435  1.268719
 1.7678328  2.0519276  2.1829154  2.0238578  1.5325028  1.3147569
 1.3009077  1.1530261  1.1365376  1.5318328  1.4456342  1.2005963
 1.0852811  0.9091485  0.8519627  1.160053   1.3781148  1.3309819
 1.3770618  1.613036   2.2196553  3.0809534  3.735831   4.0702524
 4.2121997  4.3439426  4.4553504  4.6135473  4.6661744  4.574195
 4.183479   3.7757118  3.1872842  2.438636   2.2491205  2.4462938
 2.8297803  3.7345524  4.7698455  5.42717    5.629543   5.750175
 5.496658   5.0885963  4.6939316  4.5958576  4.5818286  4.5407434
 4.6475945  4.784548   4.2460256  4.0569215  3.9724145  3.0543768
 2.1906168  1.8818984  1.7180159  1.633213   1.3395855  1.2257178
 1.3316251  1.4620751  1.4900184  2.0322683  2.4509876  2.6415045
 2.4132755  1.878407   1.500622   1.373786   1.2644384  1.265956
 1.5270112  1.2798051  1.2276989  1.1378688  0.92485815 0.98381543
 1.3585505  1.4416795  1.4811893  1.6866429  2.2629418  3.197648
 3.9736536  4.592544   4.825756   4.814644   4.7410235  4.7973886
 4.8078938  4.8881392  4.73576    4.432834   4.0729356  3.6517887
 2.804724   1.9333687  2.1463661  2.7437217  3.580767   4.563997
 5.2145267  5.401101   5.44861    5.187113   4.7114296  4.225433
 4.047818   4.018467   3.9757104  4.134607   3.928862   3.4727867
 3.3487313  3.0017288  2.3352952  1.5903596  1.3476487  1.2875332
 1.3456233  1.3376136  1.4761157  1.639076   1.9018452  2.0213275
 2.1552207  2.7286365  2.9657004  2.8004317  2.1999192  1.4925464
 1.4861684  1.3967103  1.4341367  1.4059963  1.2100066  1.2245862
 1.1401621  0.8683864  0.9290362  1.3613205  1.6489121  1.9107262
 2.1919272  2.9400508  3.7593257  4.4635506  5.0680423  5.3762894
 5.279237   5.1943793  4.8869166  4.7239227  4.820097   4.6542163
 4.50515    4.2382183  3.9825222  3.2841227  2.4132676  1.7209047
 2.5060744  3.52274    3.9800186  4.6051702  5.0000596  5.170331
 4.950138   4.4392276  3.8199022  3.4621484  3.3353307  3.3054783
 3.5053692  3.3409462  2.7919347  2.6101754  2.152463   1.8828975
 1.2231159  0.83405393 0.8777519  1.0446062  1.2422258  1.5523793
 1.7210838  2.1131926  2.3993661  2.3093653  2.8378317  3.2035499
 3.0699131  2.4916735  1.7023329  1.5818152  1.4723847  1.4020875
 1.182254   1.1958683  1.3226427  1.2545978  0.9429476  0.73116124
 1.1203507  1.7532982  2.156518   2.9025254  3.545794   4.1475687
 4.705959   5.3351526  5.7887197  5.779392   5.547285   5.339966
 4.806625   4.5331116  4.3333936  4.2500596 ]
