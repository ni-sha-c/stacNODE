time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 1000
num_test: 1000
num_val: 0
num_trans: 0
loss_type: Jacobian
dyn_sys: baker
model_type: MLP_skip
s: 0.2
n_hidden: 256
n_layers: 4
reg_param: 200.0
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 12.571329117 Test: 10.131813049
Epoch 0: New minimal relative error: 10.13%, model saved.
Epoch: 100 Train: 2.483039379 Test: 2.538752556
Epoch 100: New minimal relative error: 2.54%, model saved.
Epoch: 200 Train: 2.371314526 Test: 2.411807775
Epoch 200: New minimal relative error: 2.41%, model saved.
Epoch: 300 Train: 2.208976746 Test: 2.233326912
Epoch 300: New minimal relative error: 2.23%, model saved.
Epoch: 400 Train: 2.207683563 Test: 2.229071140
Epoch 400: New minimal relative error: 2.23%, model saved.
Epoch: 500 Train: 2.183254719 Test: 2.206157923
Epoch 500: New minimal relative error: 2.21%, model saved.
Epoch: 600 Train: 2.177692890 Test: 2.224702835
Epoch: 700 Train: 2.131661654 Test: 2.158823490
Epoch 700: New minimal relative error: 2.16%, model saved.
Epoch: 800 Train: 2.129110813 Test: 2.129397154
Epoch 800: New minimal relative error: 2.13%, model saved.
Epoch: 900 Train: 2.197856665 Test: 2.225428581
Epoch: 1000 Train: 2.205826521 Test: 2.241215706
Epoch: 1100 Train: 2.187789917 Test: 2.217325211
Epoch: 1200 Train: 2.185264826 Test: 2.222975016
Epoch: 1300 Train: 2.198816061 Test: 2.233002186
Epoch: 1400 Train: 2.189785480 Test: 2.248064995
Epoch: 1500 Train: 2.187023401 Test: 2.215932369
Epoch: 1600 Train: 2.176973343 Test: 2.201867104
Epoch: 1700 Train: 2.187482357 Test: 2.217076778
Epoch: 1800 Train: 2.190418005 Test: 2.237961292
Epoch: 1900 Train: 2.224568367 Test: 2.250533581
Epoch: 2000 Train: 2.226550579 Test: 2.253589630
Epoch: 2100 Train: 2.212405682 Test: 2.236669540
Epoch: 2200 Train: 2.196293831 Test: 2.223124266
Epoch: 2300 Train: 2.188413620 Test: 2.213803530
Epoch: 2400 Train: 2.193827391 Test: 2.211410761
Epoch: 2500 Train: 2.192523718 Test: 2.212272167
Epoch: 2600 Train: 2.201803446 Test: 2.229764938
Epoch: 2700 Train: 2.166072369 Test: 2.186861753
Epoch: 2800 Train: 2.204921722 Test: 2.235125065
Epoch: 2900 Train: 2.190442801 Test: 2.216949224
Epoch: 3000 Train: 2.158518791 Test: 2.190849066
Epoch: 3100 Train: 2.134909153 Test: 2.137617350
Epoch: 3200 Train: 2.158495188 Test: 2.178813457
Epoch: 3300 Train: 2.205407858 Test: 2.223841906
Epoch: 3400 Train: 2.213199377 Test: 2.232256413
Epoch: 3500 Train: 2.208873987 Test: 2.228307962
Epoch: 3600 Train: 2.219562054 Test: 2.234702349
Epoch: 3700 Train: 2.220849276 Test: 2.236695290
Epoch: 3800 Train: 2.215306520 Test: 2.235315800
Epoch: 3900 Train: 2.214749336 Test: 2.234143257
Epoch: 4000 Train: 2.214211702 Test: 2.230225086
Epoch: 4100 Train: 2.216564417 Test: 2.235426903
Epoch: 4200 Train: 2.213691950 Test: 2.230976105
Epoch: 4300 Train: 2.214073658 Test: 2.230541468
Epoch: 4400 Train: 2.217890739 Test: 2.231782436
Epoch: 4500 Train: 2.224329233 Test: 2.239245892
Epoch: 4600 Train: 2.241687775 Test: 2.264819860
Epoch: 4700 Train: 2.146465778 Test: 2.161509514
Epoch: 4800 Train: 2.179182053 Test: 2.192778826
Epoch: 4900 Train: 2.200988770 Test: 2.212373257
Epoch: 5000 Train: 2.210222483 Test: 2.230399609
Epoch: 5100 Train: 2.229039192 Test: 2.247867584
Epoch: 5200 Train: 2.235218048 Test: 2.249437809
Epoch: 5300 Train: 2.237874508 Test: 2.249296427
Epoch: 5400 Train: 2.236324310 Test: 2.244835377
Epoch: 5500 Train: 2.231688261 Test: 2.239452124
Epoch: 5600 Train: 2.246619701 Test: 2.252808332
Epoch: 5700 Train: 2.272175550 Test: 2.283832550
Epoch: 5800 Train: 2.265427113 Test: 2.272921085
Epoch: 5900 Train: 2.249465942 Test: 2.258434772
Epoch: 6000 Train: 2.240373611 Test: 2.249661922
Epoch: 6100 Train: 2.250266790 Test: 2.258602858
Epoch: 6200 Train: 2.254227400 Test: 2.260767937
Epoch: 6300 Train: 2.249072075 Test: 2.254528284
Epoch: 6400 Train: 2.234459400 Test: 2.244846582
Epoch: 6500 Train: 2.223198891 Test: 2.246188402
Epoch: 6600 Train: 2.206130505 Test: 2.223866463
Epoch: 6700 Train: 2.115658760 Test: 2.128903389
Epoch 6700: New minimal relative error: 2.13%, model saved.
Epoch: 6800 Train: 2.113274097 Test: 2.114805937
Epoch 6800: New minimal relative error: 2.11%, model saved.
Epoch: 6900 Train: 2.144426584 Test: 2.149749756
Epoch: 7000 Train: 2.224996090 Test: 2.231061697
Epoch: 7100 Train: 2.236402750 Test: 2.248896122
Epoch: 7200 Train: 2.266120672 Test: 2.275347710
Epoch: 7300 Train: 2.274191856 Test: 2.290463448
Epoch: 7400 Train: 2.257868767 Test: 2.278672218
Epoch: 7500 Train: 2.242557287 Test: 2.262726307
Epoch: 7600 Train: 2.218746185 Test: 2.234965324
Epoch: 7700 Train: 2.219792128 Test: 2.235206842
Epoch: 7800 Train: 2.226030350 Test: 2.245498180
Epoch: 7900 Train: 2.226469994 Test: 2.245665550
Epoch: 8000 Train: 2.225937366 Test: 2.240541458
Epoch: 8100 Train: 2.229600191 Test: 2.244643688
Epoch: 8200 Train: 2.239320278 Test: 2.249994755
Epoch: 8300 Train: 2.273023605 Test: 2.287055731
Epoch: 8400 Train: 2.229712486 Test: 2.235801458
Epoch: 8500 Train: 2.219891548 Test: 2.231436253
Epoch: 8600 Train: 2.221808195 Test: 2.231654882
Epoch: 8700 Train: 2.240597486 Test: 2.251587391
Epoch: 8800 Train: 2.245928764 Test: 2.256140709
Epoch: 8900 Train: 2.229496241 Test: 2.233501911
Epoch: 9000 Train: 2.229288816 Test: 2.230436802
Epoch: 9100 Train: 2.231000900 Test: 2.230264664
Epoch: 9200 Train: 2.236340284 Test: 2.241864681
Epoch: 9300 Train: 2.246351719 Test: 2.252218246
Epoch: 9400 Train: 2.241292953 Test: 2.243519306
Epoch: 9500 Train: 2.248036146 Test: 2.254678965
Epoch: 9600 Train: 2.251270771 Test: 2.262366533
Epoch: 9700 Train: 2.255532980 Test: 2.271768808
Epoch: 9800 Train: 2.231964588 Test: 2.245750427
Epoch: 9900 Train: 2.244107723 Test: 2.255074501
Epoch: 9999 Train: 2.242666245 Test: 2.254840374
Training Loss: tensor(2.2427)
Test Loss: tensor(2.2548)
True Mean x: tensor(3.3019, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(3.3662, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(nan, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(0.0038)
Jacobian term Test Loss: tensor(0.0039)
Learned LE: [6.8745785 0.6185046]
True LE: tensor([ 0.6932, -0.7017], dtype=torch.float64)
