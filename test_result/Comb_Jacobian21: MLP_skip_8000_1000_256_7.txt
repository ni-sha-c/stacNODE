time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 1000
loss_type: Jacobian
dyn_sys: lorenz
model_type: MLP_skip
n_hidden: 256
n_layers: 7
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_Jac/
Epoch 0: New minimal relative error: 103.25%, model saved.
Epoch: 0 Train: 171450.54688 Test: 4258.46680
Epoch: 80 Train: 49695.01172 Test: 2156.86768
Epoch 160: New minimal relative error: 86.48%, model saved.
Epoch: 160 Train: 47185.64844 Test: 1639.50916
Epoch: 240 Train: 43327.35156 Test: 1476.42224
Epoch: 320 Train: 47880.68750 Test: 1578.90186
Epoch: 400 Train: 44763.58984 Test: 1634.56982
Epoch: 480 Train: 42533.85938 Test: 1646.87866
Epoch: 560 Train: 44821.29688 Test: 1543.16443
Epoch 640: New minimal relative error: 66.98%, model saved.
Epoch: 640 Train: 43245.05078 Test: 1545.71741
Epoch: 720 Train: 51518.14844 Test: 1865.23511
Epoch: 800 Train: 41639.61719 Test: 1517.41748
Epoch: 880 Train: 46328.26172 Test: 1586.02490
Epoch: 960 Train: 46217.50781 Test: 1600.16138
Epoch: 1040 Train: 42391.60156 Test: 1510.34375
Epoch 1120: New minimal relative error: 61.60%, model saved.
Epoch: 1120 Train: 45511.89844 Test: 1642.84705
Epoch: 1200 Train: 44789.08594 Test: 1672.01514
Epoch: 1280 Train: 46284.72266 Test: 1644.17395
Epoch: 1360 Train: 43474.19141 Test: 1610.05261
Epoch: 1440 Train: 44003.34766 Test: 1644.36853
Epoch: 1520 Train: 46088.16406 Test: 1633.46106
Epoch: 1600 Train: 43005.19531 Test: 1773.95642
Epoch: 1680 Train: 44829.62891 Test: 2121.43823
Epoch: 1760 Train: 42691.79297 Test: 1602.69678
Epoch: 1840 Train: 43335.16406 Test: 1587.45984
Epoch: 1920 Train: 40830.94141 Test: 1472.88586
Epoch: 2000 Train: 44677.64453 Test: 1590.45776
Epoch 2080: New minimal relative error: 56.95%, model saved.
Epoch: 2080 Train: 39978.07031 Test: 1486.85608
Epoch: 2160 Train: 42048.89062 Test: 1512.48364
Epoch: 2240 Train: 41648.94141 Test: 1543.56921
Epoch: 2320 Train: 39770.06641 Test: 1490.83765
Epoch: 2400 Train: 41815.10938 Test: 1463.12122
Epoch: 2480 Train: 39139.99219 Test: 1444.51147
Epoch: 2560 Train: 41282.21484 Test: 1422.92322
Epoch: 2640 Train: 42352.16016 Test: 1693.33679
Epoch: 2720 Train: 39367.17969 Test: 1404.24316
Epoch: 2800 Train: 41752.35938 Test: 1384.55627
Epoch: 2880 Train: 39909.12891 Test: 1419.64722
Epoch: 2960 Train: 39713.23438 Test: 1384.81763
Epoch: 3040 Train: 40942.14062 Test: 1413.76709
Epoch: 3120 Train: 37541.57422 Test: 1325.73169
Epoch: 3200 Train: 38807.83594 Test: 1337.45789
Epoch: 3280 Train: 36676.35938 Test: 1331.90942
Epoch: 3360 Train: 37371.25781 Test: 1207.48279
Epoch: 3440 Train: 37819.81641 Test: 1244.12134
Epoch: 3520 Train: 36718.10156 Test: 1238.68433
Epoch: 3600 Train: 36942.53125 Test: 1219.24268
Epoch: 3680 Train: 35597.64453 Test: 1210.55981
Epoch: 3760 Train: 37045.89062 Test: 1217.64160
Epoch: 3840 Train: 33591.08984 Test: 1118.09473
Epoch: 3920 Train: 31394.84180 Test: 897.88159
Epoch: 4000 Train: 32421.48828 Test: 925.99646
Epoch: 4080 Train: 34215.06250 Test: 1094.46106
Epoch: 4160 Train: 33998.51953 Test: 1082.19360
Epoch: 4240 Train: 32697.23438 Test: 999.00677
Epoch: 4320 Train: 31615.61914 Test: 891.19525
Epoch: 4400 Train: 32189.56055 Test: 826.00281
Epoch: 4480 Train: 31261.54883 Test: 940.46185
Epoch: 4560 Train: 28991.06250 Test: 796.83691
Epoch: 4640 Train: 27419.27930 Test: 749.30371
Epoch: 4720 Train: 28077.59766 Test: 746.49512
Epoch: 4800 Train: 27386.64648 Test: 693.37500
Epoch: 4880 Train: 25654.32422 Test: 666.60107
Epoch: 4960 Train: 24451.83203 Test: 539.76959
Epoch: 5040 Train: 22753.83594 Test: 475.48566
Epoch: 5120 Train: 20650.48047 Test: 385.54129
Epoch: 5200 Train: 20440.66602 Test: 401.47296
Epoch: 5280 Train: 22027.10352 Test: 412.32721
Epoch: 5360 Train: 22927.95508 Test: 363.17499
Epoch: 5440 Train: 19032.41992 Test: 302.05240
Epoch: 5520 Train: 16831.08594 Test: 250.78091
Epoch: 5600 Train: 14620.57812 Test: 179.17676
Epoch: 5680 Train: 10447.68652 Test: 122.53235
Epoch: 5760 Train: 6282.94287 Test: 63.84246
Epoch 5840: New minimal relative error: 20.76%, model saved.
Epoch: 5840 Train: 4347.67236 Test: 31.87880
Epoch 5920: New minimal relative error: 16.99%, model saved.
Epoch: 5920 Train: 3188.37012 Test: 18.00617
Epoch: 6000 Train: 2551.86694 Test: 13.08690
Epoch: 6080 Train: 2175.64844 Test: 8.08168
Epoch 6160: New minimal relative error: 15.15%, model saved.
Epoch: 6160 Train: 1939.31799 Test: 6.34995
Epoch: 6240 Train: 1759.66162 Test: 5.00644
Epoch 6320: New minimal relative error: 9.49%, model saved.
Epoch: 6320 Train: 1665.91052 Test: 4.63066
Epoch: 6400 Train: 1600.16406 Test: 3.90700
Epoch: 6480 Train: 1536.99658 Test: 4.12407
Epoch: 6560 Train: 1537.54980 Test: 3.95922
Epoch: 6640 Train: 1530.27441 Test: 3.25445
Epoch: 6720 Train: 1510.44751 Test: 3.38953
Epoch: 6800 Train: 1441.66284 Test: 3.11363
Epoch: 6880 Train: 1351.59729 Test: 2.84399
Epoch 6960: New minimal relative error: 6.13%, model saved.
Epoch: 6960 Train: 1284.24329 Test: 2.35394
Epoch: 7040 Train: 1304.57068 Test: 2.49058
Epoch: 7120 Train: 1227.99731 Test: 2.53148
Epoch: 7200 Train: 1155.01794 Test: 2.03235
Epoch: 7280 Train: 1095.61255 Test: 1.88940
Epoch: 7360 Train: 1062.96472 Test: 1.67920
Epoch: 7440 Train: 1014.81989 Test: 1.58094
Epoch: 7520 Train: 979.56915 Test: 1.49810
Epoch: 7600 Train: 939.40894 Test: 1.33787
Epoch: 7680 Train: 923.57074 Test: 1.35129
Epoch: 7760 Train: 931.62683 Test: 1.36394
Epoch: 7840 Train: 964.60126 Test: 1.44034
Epoch: 7920 Train: 1010.51642 Test: 3.29394
Epoch: 7999 Train: 947.10156 Test: 1.45674
Training Loss: tensor(947.1016)
Test Loss: tensor(1.4567)
Learned LE: [  1.0315809   -0.13534014 -14.566159  ]
True LE: [  0.8891122   -0.01492951 -14.548079  ]
Relative Error: [48.408657 49.441143 50.50319  51.421196 52.230507 52.960823 53.641148
 54.307163 54.992695 55.732506 56.555946 57.49023  58.55467  59.76959
 61.148964 62.704285 64.4418   66.36858  68.48144  70.7822   73.249176
 75.85704  78.56349  81.314644 84.03092  86.12122  87.30504  88.20808
 88.68707  88.73063  88.38138  87.36881  85.67941  83.40418  80.655136
 77.57216  74.17113  70.71839  67.32694  64.09052  61.071354 58.327694
 55.904896 53.202766 50.319313 47.729023 45.450966 43.51062  41.891624
 40.593758 39.581425 38.792725 38.29522  38.08839  38.163876 38.474907
 39.004494 39.739586 40.632885 41.645714 42.72101  43.802174 44.83861
 45.938526 46.981613 47.909313 48.754086 49.53464  50.27915  51.01946
 51.788044 52.61308  53.524162 54.54359  55.691303 56.98484  58.437084
 60.090427 61.89399  63.844532 65.994606 68.32421  70.80703  73.41201
 76.093636 78.79098  81.22056  82.454895 83.48568  84.19753  84.45687
 84.35776  83.767654 82.52748  80.655136 78.25392  75.43958  72.2306
 68.87522  65.512726 62.2437   59.160988 56.34775  53.790466 51.509792
 49.001827 46.22938  43.744614 41.55412  39.663013 38.135113 36.92159
 36.011562 35.294376 34.85352  34.695755 34.812717 35.14808  35.698387
 36.432346 37.32761  38.335068 39.399536 40.467773 41.514763 42.65597
 43.688423 44.640522 45.523964 46.35712  47.165363 47.976505 48.82117
 49.72622  50.71646  51.812614 53.072433 54.522324 56.094135 57.799477
 59.644943 61.631565 63.75655  66.02976  68.52451  71.121    73.77075
 76.40542  77.838745 78.94287  79.8178   80.337364 80.38202  80.141884
 79.33629  77.880325 75.854256 73.34838  70.38633  67.1751   63.87968
 60.612274 57.522064 54.626877 51.949566 49.525967 47.379868 45.02348
 42.35447  39.96719  37.869606 36.067043 34.575214 33.44189  32.615337
 31.978825 31.59295  31.48452  31.64264  32.00324  32.577324 33.31433
 34.214245 35.219948 36.280293 37.342327 38.44722  39.576202 40.621593
 41.602486 42.528347 43.413227 44.28094  45.159702 46.074757 47.051067
 48.112198 49.4017   50.795704 52.296955 53.915276 55.663925 57.54708
 59.566074 61.714375 63.98434  66.387985 68.9714   71.584114 73.44574
 74.6063   75.575294 76.29246  76.62231  76.49711  76.08953  75.06363
 73.43108  71.2724   68.6062   65.58348  62.397934 59.169846 56.090874
 53.135933 50.361996 47.812027 45.51545  43.492794 41.25212  38.67844
 36.382854 34.373188 32.651978 31.225761 30.145306 29.390675 28.836098
 28.506798 28.4477   28.647318 29.033161 29.630789 30.375746 31.282604
 32.293957 33.353485 34.405285 35.58021  36.700256 37.767437 38.782043
 39.749344 40.685932 41.61197  42.552177 43.530975 44.5974   45.884327
 47.23856  48.67951  50.22403  51.88428  53.67099  55.588524 57.635395
 59.80444  62.082207 64.44204  66.95319  69.27741  70.46088  71.514565
 72.34561  72.90648  73.04696  72.80658  72.19584  70.96559  69.17782
 66.858635 64.0684   61.037437 57.888847 54.843838 51.859455 49.01126
 46.35148  43.91964  41.740913 39.8332   37.673893 35.189384 32.97988
 31.051332 29.40997  28.058979 27.019787 26.33623  25.859776 25.586224
 25.577599 25.817167 26.232136 26.847702 27.61069  28.529081 29.548466
 30.61116  31.702477 32.888607 34.021793 35.11651  36.164932 37.17491
 38.160122 39.140934 40.137257 41.219604 42.501415 43.82922  45.224457
 46.7065   48.29029  49.988907 51.81021  53.757824 55.830276 58.01481
 60.298435 62.64957  65.05697  66.5078   67.609375 68.554016 69.25328
 69.65286  69.60738  69.258026 68.44298  67.04119  65.10981  62.596436
 59.76572  56.737453 53.753685 50.771038 47.87536  45.127808 42.57704
 40.256195 38.187153 36.38307  34.276012 31.874332 29.745272 27.894474
 26.328463 25.051441 24.067043 23.446522 23.045778 22.827665 22.869085
 23.144531 23.593998 24.22844  25.012707 25.94637  26.978546 28.036264
 29.197237 30.375475 31.531889 32.654667 33.74024  34.792202 35.82286
 36.851192 37.941517 39.234215 40.551853 41.915207 43.345467 44.863976
 46.48277  48.215862 50.06854  52.045677 54.139805 56.337906 58.62478
 60.964592 62.778103 63.872955 64.889366 65.71974  66.22487  66.252014
 66.180756]
