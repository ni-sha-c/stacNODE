time_step: 0.001
lr: 0.001
weight_decay: 0.0001
num_epoch: 20000
num_train: 10000
num_test: 8000
num_val: 3000
num_trans: 0
loss_type: Jacobian
dyn_sys: hyperchaos
model_type: MLP_skip
n_hidden: 256
n_layers: 4
reg_param: 1000
optim_name: AdamW
train_dir: ../plot/Vector_field/hyperchaos/train_MLPskip_Jac_fullbatch/
Epoch: 0 Train: 6794471.50000 Test: 4234217.00000
Epoch: 200 Train: 963225.31250 Test: 804160.37500
Epoch 400: New minimal relative error: 53.88%, model saved.
Epoch: 400 Train: 916789.25000 Test: 798838.31250
Epoch: 600 Train: 841341.00000 Test: 763595.87500
Epoch: 800 Train: 615415.06250 Test: 629204.31250
Epoch 1000: New minimal relative error: 31.72%, model saved.
Epoch: 1000 Train: 379070.12500 Test: 495044.06250
Epoch: 1200 Train: 208547.56250 Test: 341512.12500
Epoch: 1400 Train: 139266.18750 Test: 282827.25000
Epoch: 1600 Train: 105468.57812 Test: 267815.37500
Epoch: 1800 Train: 77944.92969 Test: 221672.48438
Epoch: 2000 Train: 67904.01562 Test: 225483.89062
Epoch 2200: New minimal relative error: 7.06%, model saved.
Epoch: 2200 Train: 57741.48438 Test: 206737.00000
Epoch: 2400 Train: 51980.99219 Test: 217825.21875
Epoch 2600: New minimal relative error: 5.55%, model saved.
Epoch: 2600 Train: 45112.00781 Test: 202474.32812
Epoch: 2800 Train: 44658.33984 Test: 205815.14062
Epoch: 3000 Train: 35941.37891 Test: 187540.92188
Epoch: 3200 Train: 39552.95312 Test: 191233.96875
Epoch: 3400 Train: 30098.20312 Test: 177566.10938
Epoch 3600: New minimal relative error: 3.85%, model saved.
Epoch: 3600 Train: 28197.20508 Test: 175373.89062
Epoch: 3800 Train: 26446.61328 Test: 170056.45312
Epoch: 4000 Train: 26183.56445 Test: 171977.54688
Epoch: 4200 Train: 24246.49805 Test: 166943.37500
Epoch: 4400 Train: 29761.41797 Test: 163996.67188
Epoch: 4600 Train: 21296.27930 Test: 153668.42188
Epoch: 4800 Train: 32871.37500 Test: 162706.82812
Epoch 5000: New minimal relative error: 2.43%, model saved.
Epoch: 5000 Train: 19058.31641 Test: 144651.09375
Epoch: 5200 Train: 18378.08984 Test: 143486.98438
Epoch: 5400 Train: 18963.50195 Test: 141573.07812
Epoch: 5600 Train: 20003.41211 Test: 140408.70312
Epoch: 5800 Train: 18828.14648 Test: 145874.92188
Epoch: 6000 Train: 18805.54297 Test: 144833.35938
Epoch: 6200 Train: 15901.22852 Test: 144279.46875
Epoch: 6400 Train: 14977.45020 Test: 143634.48438
Epoch: 6600 Train: 15336.83984 Test: 145681.50000
Epoch: 6800 Train: 13968.76855 Test: 141117.06250
Epoch 7000: New minimal relative error: 2.20%, model saved.
Epoch: 7000 Train: 14295.89258 Test: 140013.56250
Epoch: 7200 Train: 14346.46875 Test: 141375.62500
Epoch: 7400 Train: 13093.59766 Test: 141193.26562
Epoch: 7600 Train: 12954.47070 Test: 138850.23438
Epoch: 7800 Train: 12801.26074 Test: 135252.64062
Epoch: 8000 Train: 13532.23145 Test: 137826.28125
Epoch: 8200 Train: 11937.35352 Test: 135595.15625
Epoch 8400: New minimal relative error: 2.14%, model saved.
Epoch: 8400 Train: 11664.70996 Test: 135851.32812
Epoch: 8600 Train: 13645.70898 Test: 135197.43750
Epoch: 8800 Train: 11070.00781 Test: 131658.70312
Epoch 9000: New minimal relative error: 1.62%, model saved.
Epoch: 9000 Train: 10644.47949 Test: 127878.21875
Epoch: 9200 Train: 10933.39648 Test: 124065.56250
Epoch: 9400 Train: 10641.46191 Test: 122256.34375
Epoch: 9600 Train: 12670.68555 Test: 122094.94531
Epoch: 9800 Train: 10184.17383 Test: 118949.27344
Epoch: 10000 Train: 10596.40430 Test: 118452.42969
Epoch: 10200 Train: 10857.87109 Test: 119168.17969
Epoch: 10400 Train: 9671.07129 Test: 117639.50781
Epoch: 10600 Train: 9595.91211 Test: 117422.07031
Epoch: 10800 Train: 9202.40234 Test: 118149.60156
Epoch: 11000 Train: 9199.23828 Test: 119597.23438
Epoch: 11200 Train: 9242.33008 Test: 122830.32812
Epoch: 11400 Train: 9424.37402 Test: 124794.17969
Epoch: 11600 Train: 9201.04395 Test: 125755.77344
