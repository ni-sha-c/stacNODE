time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 10000
num_test: 6000
num_trans: 500
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 512
n_layers: 7
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 100.00%, model saved.
Epoch: 0 Train: 4147.59619 Test: 4251.48779
Epoch: 100 Train: 172.35368 Test: 60.37086
Epoch 200: New minimal relative error: 32.84%, model saved.
Epoch: 200 Train: 79.28200 Test: 42.97854
Epoch: 300 Train: 4.92977 Test: 7.58964
Epoch 400: New minimal relative error: 12.54%, model saved.
Epoch: 400 Train: 2.51946 Test: 3.80330
Epoch: 500 Train: 12.43962 Test: 17.43134
Epoch: 600 Train: 2.45616 Test: 4.69499
Epoch: 700 Train: 0.96132 Test: 2.27494
Epoch: 800 Train: 2.14409 Test: 3.35792
Epoch: 900 Train: 4.70096 Test: 7.46598
Epoch: 1000 Train: 3.32314 Test: 2.34802
Epoch: 1100 Train: 3.71422 Test: 5.37918
Epoch: 1200 Train: 2.37824 Test: 3.19887
Epoch: 1300 Train: 0.70299 Test: 2.45579
Epoch: 1400 Train: 4.01891 Test: 5.68695
Epoch: 1500 Train: 0.52682 Test: 1.86305
Epoch: 1600 Train: 15.49026 Test: 15.78417
Epoch: 1700 Train: 1.09954 Test: 2.09064
Epoch: 1800 Train: 0.47341 Test: 1.23697
Epoch: 1900 Train: 1.11078 Test: 1.41837
Epoch: 2000 Train: 0.44521 Test: 1.58319
Epoch: 2100 Train: 2.79446 Test: 2.98267
Epoch: 2200 Train: 3.45229 Test: 4.61397
Epoch: 2300 Train: 0.56219 Test: 1.59544
Epoch: 2400 Train: 3.03285 Test: 4.47236
Epoch: 2500 Train: 3.60871 Test: 4.57157
Epoch: 2600 Train: 0.83767 Test: 2.23715
Epoch: 2700 Train: 1.01532 Test: 2.25406
Epoch: 2800 Train: 0.61675 Test: 2.16842
Epoch: 2900 Train: 2.05641 Test: 3.87877
Epoch: 3000 Train: 1.41100 Test: 2.72228
Epoch: 3100 Train: 0.92821 Test: 2.28455
Epoch: 3200 Train: 0.24460 Test: 1.53914
Epoch: 3300 Train: 0.21550 Test: 1.52928
Epoch: 3400 Train: 0.14983 Test: 1.84266
Epoch: 3500 Train: 0.56349 Test: 2.25126
Epoch: 3600 Train: 0.16936 Test: 1.83190
Epoch: 3700 Train: 0.98284 Test: 2.75950
Epoch: 3800 Train: 0.20665 Test: 1.89224
Epoch: 3900 Train: 0.35019 Test: 2.17600
Epoch: 4000 Train: 1.24993 Test: 3.11318
Epoch: 4100 Train: 0.52141 Test: 2.45675
Epoch: 4200 Train: 1.11862 Test: 2.77799
Epoch: 4300 Train: 0.43227 Test: 2.19531
Epoch: 4400 Train: 0.15071 Test: 2.13190
Epoch: 4500 Train: 0.16280 Test: 2.32160
Epoch: 4600 Train: 0.57769 Test: 2.54289
Epoch: 4700 Train: 0.28284 Test: 2.33710
Epoch: 4800 Train: 0.30525 Test: 2.40820
Epoch: 4900 Train: 1.03762 Test: 3.32557
Epoch: 5000 Train: 0.16135 Test: 2.35719
Epoch: 5100 Train: 0.91582 Test: 3.39324
Epoch: 5200 Train: 0.81088 Test: 3.22176
Epoch: 5300 Train: 0.58059 Test: 2.85975
Epoch: 5400 Train: 0.95543 Test: 3.30974
Epoch: 5500 Train: 0.80042 Test: 3.24655
Epoch: 5600 Train: 0.16403 Test: 2.71698
Epoch: 5700 Train: 0.01472 Test: 2.64893
Epoch: 5800 Train: 0.14286 Test: 2.83525
Epoch: 5900 Train: 0.15509 Test: 2.91608
Epoch: 6000 Train: 0.06073 Test: 2.80609
Epoch: 6100 Train: 0.01012 Test: 2.82236
Epoch: 6200 Train: 0.01620 Test: 2.96102
Epoch: 6300 Train: 0.98569 Test: 3.85885
Epoch: 6400 Train: 0.33165 Test: 3.35865
Epoch: 6500 Train: 1.39808 Test: 3.82930
Epoch: 6600 Train: 0.13484 Test: 3.15514
Epoch: 6700 Train: 0.02552 Test: 3.11653
Epoch: 6800 Train: 0.04078 Test: 3.21362
Epoch: 6900 Train: 0.78784 Test: 3.89590
Epoch: 7000 Train: 0.14066 Test: 3.24502
Epoch: 7100 Train: 0.35604 Test: 3.64774
Epoch: 7200 Train: 0.27285 Test: 3.62588
Epoch: 7300 Train: 0.20439 Test: 3.56613
Epoch: 7400 Train: 0.06148 Test: 3.41525
Epoch: 7500 Train: 0.34281 Test: 3.89873
Epoch: 7600 Train: 0.79407 Test: 4.15660
Epoch: 7700 Train: 0.21861 Test: 3.63061
Epoch: 7800 Train: 0.15519 Test: 3.60935
Epoch: 7900 Train: 0.01015 Test: 3.51156
Epoch: 8000 Train: 0.02439 Test: 3.53983
Epoch: 8100 Train: 0.00715 Test: 3.54631
Epoch: 8200 Train: 0.03676 Test: 3.62421
Epoch: 8300 Train: 0.01903 Test: 3.63665
Epoch: 8400 Train: 0.33768 Test: 3.73791
Epoch: 8500 Train: 0.03522 Test: 3.64238
Epoch: 8600 Train: 0.01520 Test: 3.69172
Epoch: 8700 Train: 0.02159 Test: 3.71910
Epoch: 8800 Train: 0.25443 Test: 4.02364
Epoch: 8900 Train: 0.08363 Test: 3.78646
Epoch: 9000 Train: 0.03095 Test: 3.72798
Epoch: 9100 Train: 0.04982 Test: 3.74910
Epoch: 9200 Train: 0.00959 Test: 3.76159
Epoch: 9300 Train: 0.00935 Test: 3.78095
Epoch: 9400 Train: 0.03573 Test: 3.81674
Epoch: 9500 Train: 0.06561 Test: 3.87012
Epoch: 9600 Train: 0.06531 Test: 3.90351
Epoch: 9700 Train: 0.00655 Test: 3.82372
Epoch: 9800 Train: 0.01494 Test: 3.84521
Epoch: 9900 Train: 0.19362 Test: 3.99472
Epoch: 9999 Train: 0.03259 Test: 3.89327
Training Loss: tensor(0.0326)
Test Loss: tensor(3.8933)
Learned LE: [ 0.6102544  -0.33361757 -2.523664  ]
True LE: [ 8.8357681e-01  8.2152467e-03 -1.4567645e+01]
Relative Error: [6.540355   6.942246   7.3131227  7.6216707  7.8474245  7.996407
 8.09778    8.182224   8.26005    8.3123455  8.296731   8.167548
 7.9006476  7.5107627  7.0477357  6.576371   6.152932   5.812228
 5.5668216  5.413889   5.3407965  5.327922   5.3505325  5.3858356
 5.420734   5.440997   5.4068675  5.2486     4.89724    4.3143783
 3.5093296  2.6165552  2.0971313  2.5160978  3.4557967  4.3155017
 4.837074   4.945709   4.6721125  4.115723   3.410848   2.6925664
 2.0758772  1.6524583  1.4778457  1.5320016  1.7303957  1.9987892
 2.2958498  2.5994651  2.8943582  3.169193   3.4168105  3.63626
 3.8335845  4.0212317  4.2161093  4.4362683  4.695696   5.0005937
 5.3473854  5.725832   6.12268    6.521001   6.8953166  7.2127
 7.4508047  7.618018   7.747952   7.871257   7.9898543  8.06993
 8.053451   7.8849397  7.5435834  7.0604877  6.5074096  5.9662843
 5.500279   5.1420407  4.8977013  4.757217   4.703733   4.7157335
 4.766232   4.8296127  4.8954935  4.966764   5.028448   5.0252705
 4.87615    4.4972095  3.8351727  2.974637   2.329701   2.5451658
 3.4011855  4.237432   4.7327347  4.7904973  4.44149    3.799334
 3.0160472  2.2381692  1.5832546  1.1460025  1.0011746  1.115485
 1.3618189  1.6573713  1.9691912  2.281702   2.5830767  2.8628945
 3.114155   3.3350866  3.5305955  3.711811   3.895127   4.0989537
 4.3393793  4.6248546  4.9534535  5.316018   5.700881   6.094182
 6.4727097  6.801931   7.056187   7.244979   7.4068418  7.5727673
 7.735683   7.8456798  7.8276577  7.6163054  7.1957545  6.6163673
 5.973647   5.365334   4.859255   4.4844594  4.2401104  4.109853
 4.0727663  4.106231   4.182289   4.2691     4.351203   4.4427166
 4.559529   4.679039   4.7299786  4.5941706  4.134815   3.3493292
 2.5897017  2.5601773  3.3029172  4.1266093  4.6208677  4.6532054
 4.2487493  3.535554   2.6882834  1.8689064  1.1924973  0.7399192
 0.607179   0.7641749  1.0345346  1.3387111  1.6541941  1.9694223
 2.2736335  2.5565488  2.8111322  3.0348177  3.2310355  3.4088624
 3.5829146  3.771234   3.9914072  4.2546606  4.562069   4.9059196
 5.276028   5.6620407  6.0447073  6.3888803  6.6635647  6.8768015
 7.0723205  7.2833896  7.494692   7.639864   7.625764   7.3761873
 6.880201   6.2090225  5.4813943  4.80901    4.261532   3.8641405
 3.6111057  3.4815383  3.4515886  3.499165   3.59859    3.712709
 3.8095963  3.8995988  4.0252542  4.206767   4.412849   4.530645
 4.3471127  3.7232585  2.8980055  2.5843017  3.1535406  3.968196
 4.493402   4.536367   4.1053057  3.3419087  2.4509203  1.6232557
 0.9815036  0.57195765 0.41590157 0.5092947  0.73886484 1.0247488
 1.334737   1.6506596  1.9581724  2.2450988  2.503659   2.7311437
 2.93025    3.1079168  3.2761135  3.4512453  3.651445   3.8909957
 4.174718   4.4973674  4.850149   5.2258263  5.6109676  5.97261
 6.2729263  6.51365    6.7426877  6.999124   7.262811   7.452463
 7.4563394  7.184361   6.627632   5.8768454  5.0732384  4.339394
 3.7450378  3.3121984  3.0337865  2.8877883  2.848321   2.8933272
 3.0040803  3.1490657  3.2771244  3.3673398  3.4700587  3.6468115
 3.9193099  4.2354646  4.373887   4.0395803  3.2662451  2.6699243
 2.957955   3.7411566  4.3317957  4.434346   4.0180335  3.230476
 2.3167274  1.5197603  0.9919408  0.7162388  0.5445671  0.42155412
 0.4617975  0.6855137  0.98535836 1.3066055  1.62432    1.9219445
 2.189078   2.4228468  2.6261332  2.8055315  2.9708314  3.1358707
 3.3180792  3.5339794  3.7926295  4.0923724  4.425744   4.7874985
 5.171117   5.5505786  5.8825245  6.1552463  6.4158106  6.714204
 7.033038   7.280323   7.3261514  7.061525   6.471311   5.6606445
 4.7927046  4.000159   3.3511813  2.8656304  2.539509   2.3550458
 2.285967   2.3066123  2.400818   2.5558524  2.7295682  2.8534186
 2.9338577  3.0639439  3.3103547  3.6966562  4.1024613  4.170575
 3.6536462  2.8934755  2.7632625  3.4233801  4.102831   4.327669
 3.9856966  3.2083325  2.283049   1.5289453  1.1329573  0.96871126
 0.79494387 0.54131824 0.28038868 0.3038268  0.59687483 0.93056446
 1.2645913  1.5808818  1.8656267  2.1123383  2.3229399  2.5046537
 2.6672862  2.823348   2.9891424  3.1823502  3.4156635  3.6916964
 4.004673   4.3494935  4.725165   5.1177616  5.485902   5.7985024
 6.089354   6.4215474  6.7938952  7.1133137  7.234773   7.0241675
 6.4437413  5.6007624  4.6813545  3.8341463  3.1256597  2.571433
 2.1718838  1.9215746  1.8018706  1.7828898  1.8377974  1.95693
 2.1378014  2.3268387  2.4361281  2.5132208 ]
