time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 1000
num_test: 1000
num_val: 0
num_trans: 0
loss_type: Jacobian
dyn_sys: baker
model_type: MLP_skip
s: 0.2
n_hidden: 512
n_layers: 5
reg_param: 300.0
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 20.158985138 Test: 14.814592361
Epoch 0: New minimal relative error: 14.81%, model saved.
Epoch: 100 Train: 3.832829952 Test: 3.921858788
Epoch 100: New minimal relative error: 3.92%, model saved.
Epoch: 200 Train: 3.833211422 Test: 3.974984169
Epoch: 300 Train: 3.650136948 Test: 3.770947456
Epoch 300: New minimal relative error: 3.77%, model saved.
Epoch: 400 Train: 3.752836943 Test: 3.814901352
Epoch: 500 Train: 3.710311890 Test: 3.746805429
Epoch 500: New minimal relative error: 3.75%, model saved.
Epoch: 600 Train: 3.557865620 Test: 3.629894018
Epoch 600: New minimal relative error: 3.63%, model saved.
Epoch: 700 Train: 3.771465302 Test: 3.906081676
Epoch: 800 Train: 3.699086189 Test: 3.824294329
Epoch: 900 Train: 3.502400875 Test: 3.738454342
Epoch: 1000 Train: 3.823348284 Test: 3.824165821
Epoch: 1100 Train: 3.635493755 Test: 3.707306147
Epoch: 1200 Train: 3.600771904 Test: 3.735701084
Epoch: 1300 Train: 3.632784843 Test: 3.717387676
Epoch: 1400 Train: 3.565922737 Test: 3.771499157
Epoch: 1500 Train: 3.591483593 Test: 3.738944530
Epoch: 1600 Train: 3.531514883 Test: 3.703217030
Epoch: 1700 Train: 3.618355274 Test: 3.745925903
Epoch: 1800 Train: 3.859807253 Test: 3.944316149
Epoch: 1900 Train: 3.688962936 Test: 3.785490036
Epoch: 2000 Train: 3.772916079 Test: 3.873077631
Epoch: 2100 Train: 3.634951591 Test: 3.810494423
Epoch: 2200 Train: 3.599733829 Test: 3.695955992
Epoch: 2300 Train: 3.716228485 Test: 3.756031752
Epoch: 2400 Train: 3.693820238 Test: 3.799950123
Epoch: 2500 Train: 3.836984634 Test: 3.952015400
Epoch: 2600 Train: 3.808886051 Test: 3.903176546
Epoch: 2700 Train: 3.766354561 Test: 3.839454174
Epoch: 2800 Train: 3.767917156 Test: 3.881096363
Epoch: 2900 Train: 3.798349380 Test: 3.888023376
Epoch: 3000 Train: 3.606611967 Test: 3.679301739
Epoch: 3100 Train: 3.792058468 Test: 3.592956543
Epoch 3100: New minimal relative error: 3.59%, model saved.
Epoch: 3200 Train: 3.682119846 Test: 3.758398056
Epoch: 3300 Train: 3.761674881 Test: 3.832587719
Epoch: 3400 Train: 3.704494953 Test: 3.787265778
Epoch: 3500 Train: 3.719000340 Test: 3.823698997
Epoch: 3600 Train: 3.744092941 Test: 3.853856802
Epoch: 3700 Train: 3.748830318 Test: 3.843049765
Epoch: 3800 Train: 3.756861687 Test: 3.887687683
Epoch: 3900 Train: 3.801685810 Test: 3.898595333
Epoch: 4000 Train: 3.761261940 Test: 3.846171379
Epoch: 4100 Train: 3.728149891 Test: 3.844881058
Epoch: 4200 Train: 3.740823746 Test: 3.834382534
Epoch: 4300 Train: 3.753079414 Test: 3.875427246
Epoch: 4400 Train: 3.812715054 Test: 3.900828838
Epoch: 4500 Train: 3.802940369 Test: 3.908309937
Epoch: 4600 Train: 3.792384624 Test: 3.958629370
Epoch: 4700 Train: 3.789950371 Test: 3.917102337
Epoch: 4800 Train: 3.666164398 Test: 3.772496700
Epoch: 4900 Train: 3.793790817 Test: 3.882147789
Epoch: 5000 Train: 3.766386032 Test: 3.875529289
Epoch: 5100 Train: 3.768310547 Test: 3.873258114
Epoch: 5200 Train: 3.760084629 Test: 3.870033741
Epoch: 5300 Train: 3.778628349 Test: 3.863169670
Epoch: 5400 Train: 3.775466919 Test: 3.860044956
Epoch: 5500 Train: 3.774970293 Test: 3.847570419
Epoch: 5600 Train: 3.793354988 Test: 3.874231815
Epoch: 5700 Train: 3.725777864 Test: 3.844305515
Epoch: 5800 Train: 3.798943520 Test: 3.896507502
Epoch: 5900 Train: 3.807880402 Test: 3.920571089
Epoch: 6000 Train: 3.806274176 Test: 3.926728725
Epoch: 6100 Train: 3.782562494 Test: 3.914239168
Epoch: 6200 Train: 3.734009743 Test: 3.870988846
Epoch: 6300 Train: 3.732119083 Test: 3.900181293
Epoch: 6400 Train: 3.723048210 Test: 3.881033421
Epoch: 6500 Train: 3.712805271 Test: 3.923017740
Epoch: 6600 Train: 3.747476578 Test: 3.918504477
Epoch: 6700 Train: 3.745463371 Test: 3.910794735
Epoch: 6800 Train: 3.780452251 Test: 3.948519945
Epoch: 6900 Train: 3.820594549 Test: 3.964003086
Epoch: 7000 Train: 3.845068455 Test: 3.956093788
Epoch: 7100 Train: 3.826769829 Test: 3.951530457
Epoch: 7200 Train: 3.816602468 Test: 3.912285328
Epoch: 7300 Train: 3.813169003 Test: 3.894524574
Epoch: 7400 Train: 3.823361874 Test: 3.893821001
Epoch: 7500 Train: 3.547477245 Test: 3.680881977
Epoch: 7600 Train: 3.756007195 Test: 3.867842197
Epoch: 7700 Train: 3.786444664 Test: 3.923859119
Epoch: 7800 Train: 3.820933342 Test: 3.933820248
Epoch: 7900 Train: 3.819781065 Test: 3.920207739
Epoch: 8000 Train: 3.898880005 Test: 3.994784832
Epoch: 8100 Train: 3.830620289 Test: 3.916265488
Epoch: 8200 Train: 3.843410492 Test: 3.932951927
Epoch: 8300 Train: 3.849839211 Test: 3.936012030
Epoch: 8400 Train: 3.846905231 Test: 3.947222710
Epoch: 8500 Train: 3.868140221 Test: 3.956165314
Epoch: 8600 Train: 3.852971554 Test: 3.954882622
Epoch: 8700 Train: 3.861214161 Test: 3.960846901
Epoch: 8800 Train: 3.876445293 Test: 3.966307878
Epoch: 8900 Train: 3.878575325 Test: 3.977881193
Epoch: 9000 Train: 3.857530117 Test: 3.977768421
Epoch: 9100 Train: 3.839154243 Test: 3.936107397
Epoch: 9200 Train: 3.845196247 Test: 3.930916071
Epoch: 9300 Train: 3.840217590 Test: 3.933141232
Epoch: 9400 Train: 3.847029209 Test: 3.936473370
Epoch: 9500 Train: 3.846882343 Test: 3.935003281
Epoch: 9600 Train: 3.863560677 Test: 3.945861816
Epoch: 9700 Train: 3.877071381 Test: 3.945901871
Epoch: 9800 Train: 3.861002922 Test: 3.945602417
Epoch: 9900 Train: 3.659791231 Test: 3.795815945
Epoch: 9999 Train: 3.730121136 Test: 3.822915554
Training Loss: tensor(3.7301)
Test Loss: tensor(3.8229)
True Mean x: tensor(3.3019, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(2.8707, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(3.3662, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(0.0049, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(0.0065)
Jacobian term Test Loss: tensor(0.0066)
Learned LE: [0.52442986 0.5270264 ]
True LE: tensor([ 0.6932, -0.7017], dtype=torch.float64)
