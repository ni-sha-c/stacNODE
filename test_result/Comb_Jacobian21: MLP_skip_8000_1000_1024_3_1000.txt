time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 1000
loss_type: Jacobian
dyn_sys: lorenz
model_type: MLP_skip
n_hidden: 1024
n_layers: 3
reg_param: 1000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_Jac/
Epoch 0: New minimal relative error: 97.46%, model saved.
Epoch: 0 Train: 60354.27734 Test: 3952.15283
Epoch: 80 Train: 13681.65137 Test: 1355.90955
Epoch: 160 Train: 11797.00781 Test: 1050.00354
Epoch: 240 Train: 11646.33594 Test: 1141.55298
Epoch 320: New minimal relative error: 72.80%, model saved.
Epoch: 320 Train: 12251.77637 Test: 1193.65100
Epoch: 400 Train: 11111.41016 Test: 1296.95337
Epoch 480: New minimal relative error: 61.60%, model saved.
Epoch: 480 Train: 14255.59082 Test: 1231.25732
Epoch: 560 Train: 10921.48926 Test: 1078.46851
Epoch 640: New minimal relative error: 59.66%, model saved.
Epoch: 640 Train: 10745.78418 Test: 811.63959
Epoch: 720 Train: 9746.47559 Test: 807.89777
Epoch: 800 Train: 9379.72754 Test: 712.35919
Epoch: 880 Train: 7911.76611 Test: 525.23077
Epoch: 960 Train: 6611.05957 Test: 416.67923
Epoch: 1040 Train: 5638.22510 Test: 255.61221
Epoch: 1120 Train: 4577.40820 Test: 199.08667
Epoch: 1200 Train: 3388.45898 Test: 301.81812
Epoch 1280: New minimal relative error: 41.87%, model saved.
Epoch: 1280 Train: 1541.50562 Test: 36.93645
Epoch 1360: New minimal relative error: 21.49%, model saved.
Epoch: 1360 Train: 1161.55957 Test: 29.89057
Epoch: 1440 Train: 901.95935 Test: 15.01530
Epoch 1520: New minimal relative error: 18.35%, model saved.
Epoch: 1520 Train: 849.18158 Test: 14.83611
Epoch: 1600 Train: 676.88116 Test: 15.55654
Epoch: 1680 Train: 655.73773 Test: 22.90099
Epoch: 1760 Train: 519.37164 Test: 16.90886
Epoch 1840: New minimal relative error: 17.81%, model saved.
Epoch: 1840 Train: 498.44067 Test: 6.44022
Epoch 1920: New minimal relative error: 8.01%, model saved.
Epoch: 1920 Train: 436.13806 Test: 5.02681
Epoch: 2000 Train: 463.56552 Test: 27.75999
Epoch: 2080 Train: 474.52988 Test: 5.75837
Epoch: 2160 Train: 396.60550 Test: 5.83074
Epoch 2240: New minimal relative error: 4.31%, model saved.
Epoch: 2240 Train: 363.16626 Test: 3.28981
Epoch: 2320 Train: 402.72751 Test: 30.06015
Epoch: 2400 Train: 341.16696 Test: 5.31415
Epoch: 2480 Train: 315.88934 Test: 5.79204
Epoch: 2560 Train: 308.48453 Test: 3.07438
Epoch: 2640 Train: 297.33716 Test: 2.48937
Epoch: 2720 Train: 294.55707 Test: 2.47937
Epoch: 2800 Train: 284.29327 Test: 3.43438
Epoch: 2880 Train: 263.32733 Test: 2.17170
Epoch: 2960 Train: 263.57828 Test: 7.05653
Epoch: 3040 Train: 232.85252 Test: 1.64514
Epoch: 3120 Train: 243.55394 Test: 4.87093
Epoch: 3200 Train: 274.18799 Test: 2.42868
Epoch: 3280 Train: 272.05612 Test: 6.03135
Epoch: 3360 Train: 254.29346 Test: 6.05600
Epoch: 3440 Train: 315.86200 Test: 11.85961
Epoch: 3520 Train: 270.88712 Test: 8.70295
Epoch: 3600 Train: 261.66449 Test: 15.34401
Epoch: 3680 Train: 250.48592 Test: 4.07773
Epoch: 3760 Train: 249.02103 Test: 6.09395
Epoch: 3840 Train: 218.60393 Test: 1.80733
Epoch: 3920 Train: 208.18011 Test: 1.41877
Epoch: 4000 Train: 201.75475 Test: 1.64179
Epoch: 4080 Train: 195.10022 Test: 2.15040
Epoch: 4160 Train: 191.42026 Test: 3.61047
Epoch: 4240 Train: 205.97440 Test: 4.90842
Epoch: 4320 Train: 236.70779 Test: 4.56112
Epoch: 4400 Train: 285.87369 Test: 6.21512
Epoch: 4480 Train: 231.71582 Test: 1.84694
Epoch: 4560 Train: 213.62498 Test: 3.33956
Epoch: 4640 Train: 199.53123 Test: 1.27804
Epoch: 4720 Train: 198.86342 Test: 2.25794
Epoch: 4800 Train: 191.07639 Test: 1.80241
Epoch: 4880 Train: 185.58607 Test: 1.39110
Epoch: 4960 Train: 183.98489 Test: 1.30283
Epoch: 5040 Train: 181.55626 Test: 3.15758
Epoch: 5120 Train: 168.49768 Test: 0.77701
Epoch: 5200 Train: 169.89532 Test: 3.68550
Epoch: 5280 Train: 170.56543 Test: 1.34103
Epoch: 5360 Train: 165.95767 Test: 0.83664
Epoch: 5440 Train: 157.31645 Test: 0.94638
Epoch 5520: New minimal relative error: 3.93%, model saved.
Epoch: 5520 Train: 165.52867 Test: 1.00075
Epoch: 5600 Train: 176.75218 Test: 1.26799
Epoch: 5680 Train: 170.34750 Test: 1.08940
Epoch: 5760 Train: 152.42311 Test: 0.71239
Epoch: 5840 Train: 146.36688 Test: 0.80346
Epoch: 5920 Train: 167.04158 Test: 1.22319
Epoch: 6000 Train: 161.57440 Test: 1.39104
Epoch: 6080 Train: 146.41205 Test: 0.74787
Epoch: 6160 Train: 149.86200 Test: 2.40394
Epoch: 6240 Train: 150.02931 Test: 0.77594
Epoch: 6320 Train: 148.35515 Test: 1.42289
Epoch: 6400 Train: 137.17329 Test: 0.68456
Epoch: 6480 Train: 145.12964 Test: 0.88648
Epoch: 6560 Train: 138.91273 Test: 1.01312
Epoch: 6640 Train: 146.11838 Test: 0.78500
Epoch: 6720 Train: 144.99312 Test: 0.85978
Epoch: 6800 Train: 143.23422 Test: 0.71220
Epoch: 6880 Train: 229.87120 Test: 2.19864
Epoch: 6960 Train: 157.11394 Test: 0.74571
Epoch: 7040 Train: 138.26054 Test: 0.62313
Epoch: 7120 Train: 141.77258 Test: 1.00549
Epoch: 7200 Train: 125.90080 Test: 0.60855
Epoch: 7280 Train: 117.26257 Test: 0.59136
Epoch: 7360 Train: 119.23867 Test: 0.62098
Epoch: 7440 Train: 126.56908 Test: 0.78101
Epoch: 7520 Train: 125.44992 Test: 0.70355
Epoch: 7600 Train: 128.25490 Test: 1.05272
Epoch: 7680 Train: 121.74672 Test: 0.55234
Epoch: 7760 Train: 130.22827 Test: 0.66113
Epoch: 7840 Train: 111.83814 Test: 0.45494
Epoch: 7920 Train: 108.66272 Test: 0.45591
Epoch: 7999 Train: 105.77568 Test: 3.80007
Training Loss: tensor(105.7757)
Test Loss: tensor(3.8001)
Learned LE: [  0.85812074   0.02840009 -14.521718  ]
True LE: [ 8.6866850e-01  1.0186722e-02 -1.4557984e+01]
Relative Error: [ 2.341417    2.1859686   2.089838    2.049243    1.9412186   1.8520508
  1.8805599   2.1942172   2.3720286   2.7467      3.050842    2.9915376
  2.646393    2.217774    1.7980814   1.4958009   1.6420252   1.8666761
  2.1726825   2.3275506   2.6775825   2.8819864   2.7925208   2.5060647
  2.073515    1.4986355   0.8573635   0.6467043   0.45699248  0.6448879
  0.85004216  1.5006663   2.2978332   3.229599    4.318227    5.6487126
  6.917973    7.8115025   8.475479    8.850812    9.187814    9.526185
  9.718668    9.899424   10.11698    10.011873    9.362804    8.485248
  7.5202413   6.533575    5.501387    4.3823376   3.4687645   3.2719676
  3.0972438   2.8661032   2.561263    2.2042913   2.184935    2.3436315
  2.5053487   2.5158572   2.3594365   2.099167    1.8736591   1.7950654
  1.7446892   1.9865267   2.370224    2.6370416   2.7526748   3.112208
  3.463404    3.4748104   3.1388025   2.7012625   2.2125332   1.8115025
  1.3410287   1.508864    1.8092202   2.1998112   2.5953944   2.7365808
  2.6550593   2.4374468   2.0224667   1.4484504   0.8139306   0.5082817
  0.40351018  0.61955804  0.90706813  1.4338062   2.124671    3.0326853
  4.214912    5.4944534   6.8842545   7.791728    8.28765     8.467748
  8.842736    9.273219    9.469504    9.717087   10.026418   10.046202
  9.363886    8.4431095   7.539397    6.528857    5.4856977   4.4343467
  3.5180523   3.2584913   3.0536366   2.803124    2.4644592   2.1734805
  2.2450566   2.4098089   2.5099552   2.5454462   2.333821    2.0051482
  1.6353976   1.496176    1.966792    2.6238801   2.9371371   3.0586655
  3.112234    3.3968308   3.7740805   3.881253    3.5632741   3.1462948
  2.6035213   2.1968815   1.7570698   1.2343844   1.3953387   1.9829519
  2.397083    2.5510747   2.5608623   2.3665078   1.9872848   1.4385663
  0.83425426  0.50311387  0.37696686  0.7067579   1.0079242   1.4529933
  1.9814866   2.7997108   4.0314484   5.2164874   6.757503    7.503403
  7.869016    8.074994    8.544774    9.050645    9.293746    9.598681
  9.878958    9.711309    9.385958    8.518939    7.612178    6.6062884
  5.594913    4.5614643   3.5810907   3.2708862   3.0623107   2.7676747
  2.3672905   2.2024534   2.2422338   2.3882275   2.4851668   2.4732485
  2.2623246   1.8743589   1.3822349   1.6322964   2.5425694   3.2099166
  3.5224795   3.489884    3.4752593   3.5796263   3.9720423   4.188751
  3.90844     3.5253716   2.9878545   2.5702446   2.1186087   1.6339123
  1.0979527   1.6809968   2.1067767   2.3643165   2.4305649   2.3036892
  1.9057271   1.3522358   0.81025827  0.538412    0.38832566  0.7275197
  1.0424044   1.4616193   1.9002272   2.5614016   3.7446942   4.996394
  6.304173    7.0353227   7.466702    7.8016853   8.252786    8.835395
  9.157989    9.492512    9.70923     9.474845    9.07486     8.669646
  7.648456    6.547859    5.5835657   4.529248    3.5237823   3.2209828
  3.0721095   2.7415588   2.472307    2.3369946   2.332007    2.4140105
  2.4339068   2.3099089   2.150458    1.7203583   1.3613635   2.1673899
  2.948029    3.6229758   3.9528801   3.855085    3.7455678   3.6947594
  4.045463    4.3798018   4.15912     3.8235314   3.3216052   2.9480402
  2.4227996   2.0001988   1.5643312   1.1998457   1.7529362   2.1083229
  2.261668    2.100679    1.7376225   1.2543128   0.82082844  0.6062334
  0.36471486  0.6982172   0.9122792   1.390942    1.8127091   2.394608
  3.3721077   4.644629    5.5514264   6.563282    7.035057    7.537245
  8.004687    8.604523    9.023516    9.181396    9.217284    8.932817
  8.566588    8.22029     7.664559    6.5776987   5.564366    4.4645452
  3.4138508   3.0762072   2.9384718   2.8484662   2.7936459   2.6084208
  2.5071447   2.5334327   2.4764743   2.289936    1.9729074   1.5216153
  1.8829005   2.5905776   3.2607696   3.8862548   4.287969    4.263697
  4.00216     3.834911    3.9644215   4.4172125   4.2658653   4.0294986
  3.562416    3.2563019   2.7062197   2.2885628   1.9942102   1.6956545
  1.249416    1.7899874   1.9308405   1.8284438   1.563404    1.1820536
  0.8654427   0.7178551   0.39359018  0.5424594   0.7180765   1.1049038
  1.6373602   2.2039824   3.105226    3.9176338   4.8918834   5.9746966
  6.6183      7.191495    7.687687    8.372182    8.520404    8.652482
  8.67409     8.399763    7.813003    7.4994793   7.076058    6.5393023
  5.453476    4.3625784   3.2591534   2.9133961   2.9366255   2.8213406
  2.8995712   2.8082252   2.6010005   2.5471323   2.428264    2.2134278
  1.8698388   1.5221592   2.2618792   2.9194293   3.4854937   4.0257797
  4.4190254   4.4911246   4.239439    3.9212737   3.7711825   4.1865644
  4.2379966   4.100337    3.7362225   3.455882    2.9734504   2.49714
  2.3340929   2.1354458   1.6873157   1.2305164   1.4878824   1.5201836
  1.358203    1.0206718   0.71436954  0.5969074 ]
