time_step: 0.01
lr: 0.001
weight_decay: 0.0001
num_epoch: 10000
num_train: 10000
num_test: 8000
num_trans: 1000
batch_size: 2000
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 1024
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE_new/
Epoch 0: New minimal relative error: 101.06%, model saved.
Epoch: 0 Train: 4198.64404 Test: 4011.90869
Epoch 100: New minimal relative error: 69.29%, model saved.
Epoch: 100 Train: 34.45625 Test: 41.36591
Epoch 200: New minimal relative error: 41.21%, model saved.
Epoch: 200 Train: 26.77820 Test: 19.88816
Epoch 300: New minimal relative error: 37.98%, model saved.
Epoch: 300 Train: 5.92982 Test: 5.21800
Epoch: 400 Train: 4.58608 Test: 4.37696
Epoch: 500 Train: 18.11348 Test: 8.96869
Epoch 600: New minimal relative error: 34.63%, model saved.
Epoch: 600 Train: 8.68474 Test: 7.66506
Epoch 700: New minimal relative error: 32.23%, model saved.
Epoch: 700 Train: 1.07412 Test: 1.20854
Epoch 800: New minimal relative error: 31.98%, model saved.
Epoch: 800 Train: 0.86702 Test: 1.06247
Epoch 900: New minimal relative error: 17.05%, model saved.
Epoch: 900 Train: 1.74566 Test: 1.77637
Epoch: 1000 Train: 1.50291 Test: 1.77905
Epoch: 1100 Train: 5.55902 Test: 5.21936
Epoch: 1200 Train: 1.30662 Test: 1.35306
Epoch: 1300 Train: 3.32114 Test: 1.43092
Epoch 1400: New minimal relative error: 11.37%, model saved.
Epoch: 1400 Train: 0.41689 Test: 0.36722
Epoch: 1500 Train: 0.50068 Test: 0.55640
Epoch: 1600 Train: 0.83730 Test: 0.45298
Epoch: 1700 Train: 0.95777 Test: 0.97981
Epoch: 1800 Train: 0.23635 Test: 0.24633
Epoch: 1900 Train: 0.23494 Test: 0.41242
Epoch: 2000 Train: 1.30702 Test: 1.50913
Epoch: 2100 Train: 0.19319 Test: 0.22870
Epoch: 2200 Train: 0.29454 Test: 0.29321
Epoch: 2300 Train: 2.31565 Test: 2.96183
Epoch: 2400 Train: 0.56956 Test: 0.91077
Epoch: 2500 Train: 0.48859 Test: 0.55905
Epoch: 2600 Train: 0.41587 Test: 0.41400
Epoch 2700: New minimal relative error: 11.22%, model saved.
Epoch: 2700 Train: 0.31690 Test: 0.34711
Epoch: 2800 Train: 1.47283 Test: 1.44242
Epoch: 2900 Train: 0.20157 Test: 0.17895
Epoch: 3000 Train: 1.24583 Test: 1.47886
Epoch: 3100 Train: 0.64856 Test: 0.66219
Epoch: 3200 Train: 0.17570 Test: 0.27206
Epoch: 3300 Train: 0.46923 Test: 0.60795
Epoch: 3400 Train: 0.38893 Test: 0.62554
Epoch: 3500 Train: 0.11262 Test: 0.12497
Epoch: 3600 Train: 1.04399 Test: 1.01085
Epoch: 3700 Train: 0.32611 Test: 0.39839
Epoch: 3800 Train: 0.62575 Test: 0.69897
Epoch: 3900 Train: 1.75643 Test: 1.75303
Epoch: 4000 Train: 0.43291 Test: 0.45703
Epoch: 4100 Train: 0.08737 Test: 0.10153
Epoch: 4200 Train: 0.07671 Test: 0.08651
Epoch: 4300 Train: 0.07600 Test: 0.08180
Epoch: 4400 Train: 0.10451 Test: 0.16410
Epoch: 4500 Train: 0.66184 Test: 0.91750
Epoch: 4600 Train: 0.25919 Test: 0.26803
Epoch: 4700 Train: 0.26585 Test: 0.18860
Epoch: 4800 Train: 0.22880 Test: 0.22697
Epoch: 4900 Train: 0.08275 Test: 0.08646
Epoch: 5000 Train: 0.06367 Test: 0.07609
Epoch: 5100 Train: 0.15757 Test: 0.21767
Epoch: 5200 Train: 0.10324 Test: 0.13815
Epoch: 5300 Train: 0.07385 Test: 0.08832
Epoch: 5400 Train: 0.53741 Test: 0.36468
Epoch: 5500 Train: 0.12817 Test: 0.12985
Epoch: 5600 Train: 0.06734 Test: 0.07501
Epoch: 5700 Train: 0.45706 Test: 0.63788
Epoch: 5800 Train: 1.30364 Test: 1.25219
Epoch: 5900 Train: 0.98305 Test: 0.67952
Epoch: 6000 Train: 0.08253 Test: 0.08632
Epoch: 6100 Train: 0.08886 Test: 0.08468
Epoch: 6200 Train: 0.29652 Test: 0.25541
Epoch: 6300 Train: 0.08867 Test: 0.11230
Epoch: 6400 Train: 0.07401 Test: 0.06808
Epoch: 6500 Train: 0.06665 Test: 0.07165
Epoch: 6600 Train: 0.08490 Test: 0.09383
Epoch: 6700 Train: 0.07461 Test: 0.09361
Epoch: 6800 Train: 0.31602 Test: 0.26548
Epoch: 6900 Train: 0.19714 Test: 0.23228
Epoch: 7000 Train: 0.19007 Test: 0.19498
Epoch: 7100 Train: 0.04041 Test: 0.05585
Epoch: 7200 Train: 0.03713 Test: 0.04957
Epoch: 7300 Train: 0.34944 Test: 0.44044
Epoch: 7400 Train: 0.21083 Test: 0.18758
Epoch: 7500 Train: 0.08310 Test: 0.09995
Epoch: 7600 Train: 0.04188 Test: 0.05939
Epoch: 7700 Train: 0.04534 Test: 0.05593
Epoch: 7800 Train: 0.04077 Test: 0.05152
Epoch: 7900 Train: 0.05604 Test: 0.07380
Epoch: 8000 Train: 0.03137 Test: 0.04349
Epoch: 8100 Train: 0.03067 Test: 0.04263
Epoch: 8200 Train: 0.03540 Test: 0.04547
Epoch: 8300 Train: 0.03068 Test: 0.04332
Epoch: 8400 Train: 0.02932 Test: 0.04117
Epoch: 8500 Train: 0.03445 Test: 0.04892
Epoch: 8600 Train: 0.05083 Test: 0.06702
Epoch: 8700 Train: 0.30923 Test: 0.35986
Epoch: 8800 Train: 0.05618 Test: 0.06616
Epoch: 8900 Train: 0.02896 Test: 0.04228
Epoch: 9000 Train: 0.03015 Test: 0.04282
Epoch: 9100 Train: 0.02603 Test: 0.03781
Epoch: 9200 Train: 0.02680 Test: 0.03848
Epoch: 9300 Train: 0.02971 Test: 0.03970
Epoch: 9400 Train: 0.04489 Test: 0.06420
Epoch: 9500 Train: 0.02452 Test: 0.03620
Epoch: 9600 Train: 0.02610 Test: 0.03693
Epoch: 9700 Train: 0.05783 Test: 0.05204
Epoch: 9800 Train: 0.02352 Test: 0.03508
Epoch: 9900 Train: 0.02352 Test: 0.03524
Epoch: 9999 Train: 0.05741 Test: 0.04876
Training Loss: tensor(0.0574)
Test Loss: tensor(0.0488)
Learned LE: [ 0.8368323  -0.06140584 -4.945761  ]
True LE: [ 8.5266054e-01 -7.1370596e-04 -1.4524351e+01]
Relative Error: [7.1845098  7.019224   6.8179846  6.583655   6.296522   5.9346566
 5.602783   5.4757023  5.481603   5.411742   5.1733127  4.806396
 4.3925033  3.9823375  3.4979348  2.8818123  2.291592   1.8471988
 1.5304219  1.2894078  1.1489654  1.1255679  1.1308149  1.1420287
 1.154385   1.1504351  1.1478273  1.1909388  1.3859539  1.762402
 2.1625643  2.4952886  2.7209074  2.8302405  2.9009132  2.8989854
 3.0596027  3.4108057  3.660498   3.9245448  4.177486   4.3648953
 4.364419   4.10055    3.8749034  3.8000698  3.7828782  3.8634784
 4.038545   4.3384647  4.769285   5.139289   5.4142504  5.677868
 5.912235   6.111976   6.313038   6.523253   6.7165284  6.859386
 6.929225   6.9176054  6.8268356  6.672148   6.476528   6.250171
 5.981245   5.638627   5.2622876  5.0306263  4.956201   4.877345
 4.672567   4.330026   3.8907137  3.4610887  3.03975    2.504291
 1.9087173  1.4093595  1.0991524  0.9658577  0.94691795 1.0014673
 1.0696174  1.1403903  1.1783184  1.1481707  1.0840342  1.0627328
 1.166609   1.437865   1.8068919  2.159578   2.443686   2.605279
 2.7011018  2.7077334  2.7317111  2.9979467  3.2106411  3.4085484
 3.620622   3.7867703  3.829182   3.64641    3.3707495  3.270495
 3.2744474  3.37312    3.568828   3.864924   4.3074913  4.7010713
 4.9697065  5.2075768  5.40933    5.587385   5.7869253  6.0069184
 6.2105393  6.3624525  6.4476714  6.465419   6.416077   6.3015776
 6.1363554  5.9362955  5.696839   5.3922906  5.005458   4.668732
 4.4766436  4.352783   4.171831   3.8796158  3.4560065  2.9872835
 2.5566258  2.114337   1.5707672  1.0134329  0.7903995  0.86498165
 0.94459915 1.0272952  1.116842   1.2183545  1.2865115  1.2563819
 1.141372   1.0375817  1.0465268  1.1708372  1.412571   1.7717971
 2.1287477  2.3836482  2.511329   2.5867734  2.5430198  2.6535676
 2.8382785  2.9473326  3.0828815  3.2145169  3.2798853  3.209202
 2.969132   2.8004982  2.8037462  2.9043324  3.113314   3.3944833
 3.8235824  4.2518673  4.520261   4.7214413  4.8781233  5.02029
 5.206652   5.426922   5.626909   5.7704053  5.858751   5.9044714
 5.908834   5.862472   5.760629   5.6155214  5.432865   5.1929893
 4.8555503  4.4554105  4.1294947  3.8905158  3.6841114  3.42752
 3.0600297  2.5957823  2.1144483  1.6743522  1.2349055  0.7132785
 0.6655563  0.93701285 1.0706824  1.1489033  1.2295753  1.3343648
 1.4200588  1.4195484  1.2985048  1.1264216  1.0678306  1.0947937
 1.0939147  1.2663236  1.6456438  2.0264273  2.262912   2.3939917
 2.4451258  2.4337244  2.5601685  2.6083827  2.6433175  2.6833339
 2.7355063  2.7129784  2.6464713  2.4478073  2.386026   2.4532602
 2.6399462  2.9010537  3.2746196  3.7388027  4.046843   4.2281923
 4.345676   4.4381027  4.586964   4.7901034  4.974031   5.091964
 5.1630096  5.218      5.2612405  5.2800455  5.258908   5.191493
 5.089261   4.948941   4.7342186  4.3920712  4.000704   3.6275144
 3.3044643  3.0012708  2.6626506  2.244885   1.7747542  1.2802184
 0.8573126  0.5057687  0.5818376  0.90860194 1.1254895  1.2551506
 1.3609512  1.4906667  1.6000651  1.6018484  1.5001309  1.3112483
 1.1367255  1.147931   1.1125054  0.94424945 1.0039647  1.4081373
 1.8301215  2.0728462  2.211426   2.2681527  2.325302   2.4143493
 2.3730445  2.3050952  2.2669764  2.2149158  2.2142694  2.234798
 2.0765538  2.0520859  2.1518817  2.367821   2.64742    3.0782342
 3.4718866  3.6838155  3.7958477  3.8593042  3.9638746  4.1309686
 4.28277    4.3624415  4.3992844  4.4395995  4.494797   4.552643
 4.5963626  4.610207   4.5845237  4.528542   4.439318   4.2746334
 3.974804   3.6125367  3.188601   2.7778416  2.3526406  1.9042418
 1.4690409  1.0187716  0.5822223  0.35718566 0.5055032  0.67018074
 0.8972382  1.138383   1.3202299  1.4698133  1.6804533  1.8204603
 1.774224   1.5654495  1.3240664  1.1897477  1.1738201  1.0695703
 0.8512005  0.76607686 1.1452093  1.6070865  1.8800364  2.004768
 2.0703757  2.1573892  2.251538   2.1628206  2.0058339  1.8992629
 1.7688539  1.8547127  1.9559115  1.793905   1.7629775  1.8585689
 2.043795   2.3106189  2.716289   3.0224369  3.1670525  3.232356
 3.3134038  3.470485   3.6164873  3.656897   3.6394074  3.64335
 3.685761   3.7589989  3.8486857  3.9309833  3.977837   3.9693792
 3.9153676  3.8335137  3.7048106  3.476413   3.1922023  2.782895
 2.3266184  1.8000556  1.2414086  0.79294515 0.48787817 0.37777123
 0.5441922  0.5854924  0.5695999  0.8127292  1.1062266  1.2784017
 1.3769646  1.579475   1.7526547  1.7966287 ]
