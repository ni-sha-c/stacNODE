time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 10000
num_test: 6000
num_trans: 500
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 512
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 100.55%, model saved.
Epoch: 0 Train: 3630.52612 Test: 4399.19629
Epoch 100: New minimal relative error: 20.18%, model saved.
Epoch: 100 Train: 31.24523 Test: 28.78686
Epoch: 200 Train: 9.70827 Test: 5.76212
Epoch: 300 Train: 7.56065 Test: 5.27092
Epoch 400: New minimal relative error: 15.20%, model saved.
Epoch: 400 Train: 2.86967 Test: 2.30023
Epoch: 500 Train: 3.94019 Test: 4.13488
Epoch: 600 Train: 6.93353 Test: 4.41784
Epoch: 700 Train: 1.35725 Test: 0.86120
Epoch: 800 Train: 0.82355 Test: 0.47128
Epoch 900: New minimal relative error: 9.65%, model saved.
Epoch: 900 Train: 0.61115 Test: 0.24537
Epoch: 1000 Train: 0.68994 Test: 0.31284
Epoch: 1100 Train: 0.73431 Test: 0.54242
Epoch: 1200 Train: 1.03841 Test: 0.91500
Epoch: 1300 Train: 1.19500 Test: 1.32745
Epoch: 1400 Train: 1.14286 Test: 1.31091
Epoch 1500: New minimal relative error: 4.79%, model saved.
Epoch: 1500 Train: 0.30004 Test: 0.14565
Epoch: 1600 Train: 0.41056 Test: 0.40212
Epoch: 1700 Train: 1.78528 Test: 1.21086
Epoch: 1800 Train: 0.21920 Test: 0.11650
Epoch: 1900 Train: 1.11981 Test: 0.95054
Epoch: 2000 Train: 2.01428 Test: 3.30214
Epoch: 2100 Train: 0.15123 Test: 0.09334
Epoch: 2200 Train: 0.14703 Test: 0.09242
Epoch: 2300 Train: 0.26245 Test: 0.24861
Epoch: 2400 Train: 0.13733 Test: 0.10816
Epoch: 2500 Train: 0.12000 Test: 0.08228
Epoch: 2600 Train: 0.11517 Test: 0.07984
Epoch: 2700 Train: 0.12399 Test: 0.09308
Epoch: 2800 Train: 0.35229 Test: 0.44505
Epoch: 2900 Train: 0.10037 Test: 0.07185
Epoch: 3000 Train: 0.10442 Test: 0.07316
Epoch: 3100 Train: 0.11071 Test: 0.11372
Epoch: 3200 Train: 0.78664 Test: 1.12935
Epoch: 3300 Train: 1.73248 Test: 2.38735
Epoch: 3400 Train: 1.61530 Test: 0.63881
Epoch: 3500 Train: 0.56341 Test: 0.36539
Epoch: 3600 Train: 0.68320 Test: 0.63614
Epoch: 3700 Train: 0.70458 Test: 0.66309
Epoch: 3800 Train: 0.15082 Test: 0.08485
Epoch: 3900 Train: 0.06690 Test: 0.05525
Epoch: 4000 Train: 0.06763 Test: 0.05455
Epoch: 4100 Train: 0.48980 Test: 0.34045
Epoch: 4200 Train: 0.15644 Test: 0.23327
Epoch: 4300 Train: 2.04889 Test: 2.34248
Epoch: 4400 Train: 0.05701 Test: 0.04809
Epoch: 4500 Train: 0.05745 Test: 0.05172
Epoch: 4600 Train: 0.12753 Test: 0.16529
Epoch: 4700 Train: 0.05233 Test: 0.04566
Epoch: 4800 Train: 0.07692 Test: 0.06796
Epoch: 4900 Train: 0.86869 Test: 1.22834
Epoch: 5000 Train: 0.48258 Test: 0.66926
Epoch: 5100 Train: 0.04807 Test: 0.04433
Epoch: 5200 Train: 0.04822 Test: 0.04244
Epoch: 5300 Train: 0.05043 Test: 0.04790
Epoch: 5400 Train: 0.06733 Test: 0.06023
Epoch: 5500 Train: 0.04242 Test: 0.03912
Epoch: 5600 Train: 0.04618 Test: 0.04078
Epoch: 5700 Train: 0.04292 Test: 0.04081
Epoch: 5800 Train: 0.04059 Test: 0.03747
Epoch: 5900 Train: 0.04057 Test: 0.03741
Epoch: 6000 Train: 0.21508 Test: 0.10790
Epoch: 6100 Train: 0.03751 Test: 0.03562
Epoch: 6200 Train: 0.04170 Test: 0.03648
Epoch: 6300 Train: 0.04316 Test: 0.04808
Epoch: 6400 Train: 0.86178 Test: 0.61408
Epoch: 6500 Train: 0.03457 Test: 0.03369
Epoch: 6600 Train: 0.03672 Test: 0.03656
Epoch: 6700 Train: 0.03514 Test: 0.03334
Epoch: 6800 Train: 0.07022 Test: 0.09088
Epoch: 6900 Train: 0.03207 Test: 0.03155
Epoch: 7000 Train: 0.04988 Test: 0.03899
Epoch: 7100 Train: 0.05092 Test: 0.08543
Epoch: 7200 Train: 0.03053 Test: 0.03051
Epoch: 7300 Train: 0.03060 Test: 0.02998
Epoch: 7400 Train: 0.03057 Test: 0.03177
Epoch: 7500 Train: 0.02938 Test: 0.02948
Epoch: 7600 Train: 0.03142 Test: 0.02910
Epoch: 7700 Train: 0.09692 Test: 0.07123
Epoch: 7800 Train: 0.02754 Test: 0.02791
Epoch: 7900 Train: 0.03115 Test: 0.03041
Epoch: 8000 Train: 0.13562 Test: 0.10588
Epoch: 8100 Train: 0.02774 Test: 0.03431
Epoch: 8200 Train: 0.02598 Test: 0.02655
Epoch: 8300 Train: 0.02599 Test: 0.02639
Epoch: 8400 Train: 0.02966 Test: 0.04457
Epoch: 8500 Train: 0.07806 Test: 0.07420
Epoch: 8600 Train: 0.02443 Test: 0.02542
Epoch: 8700 Train: 0.09880 Test: 0.14028
Epoch: 8800 Train: 0.02381 Test: 0.02505
Epoch: 8900 Train: 0.04489 Test: 0.02840
Epoch: 9000 Train: 0.02860 Test: 0.02984
Epoch: 9100 Train: 0.02271 Test: 0.02398
Epoch: 9200 Train: 0.02707 Test: 0.03300
Epoch: 9300 Train: 0.02215 Test: 0.02378
Epoch: 9400 Train: 0.02305 Test: 0.02436
Epoch: 9500 Train: 0.02156 Test: 0.02303
Epoch: 9600 Train: 0.03544 Test: 0.09832
Epoch: 9700 Train: 0.02101 Test: 0.02267
Epoch: 9800 Train: 0.05325 Test: 0.08488
Epoch: 9900 Train: 0.07663 Test: 0.07593
Epoch: 9999 Train: 0.02016 Test: 0.02193
Training Loss: tensor(0.0202)
Test Loss: tensor(0.0219)
Learned LE: [ 0.8193013  0.0535194 -4.600128 ]
True LE: [ 8.8564122e-01  8.1955234e-04 -1.4558980e+01]
Relative Error: [1.7742925  1.8260015  1.8527584  1.8786855  1.9022936  1.9077725
 1.7841027  1.2130151  0.89689183 0.9508985  1.2793809  1.5413561
 1.6305404  1.638293   1.5965048  1.46474    1.2470679  1.0003742
 0.84966767 0.81109905 0.7961983  0.80388737 0.86610615 0.9506231
 0.99108154 1.0038463  1.0106462  0.9679525  0.9184962  0.97270834
 1.0637635  1.1377137  1.3161544  1.4530977  1.3636004  1.1648343
 0.90432304 0.69019085 0.69561535 0.68220544 0.6479205  0.57887083
 0.14127645 0.49221796 0.22861998 0.33685106 0.5503358  0.64737254
 0.9313709  1.1870112  1.2483687  1.1753749  0.98127246 0.80491143
 0.6770556  0.6042527  0.6271513  0.7259371  0.97675174 1.2683113
 1.4896808  1.6462234  1.7422576  1.7559817  1.6798681  1.5541947
 1.4496303  1.3527104  1.3000367  1.0656788  0.64498323 0.7498008
 1.1877781  1.4808302  1.4699056  1.3619432  1.2943461  1.2356476
 1.0943189  0.9226353  0.9678457  0.9684187  0.84206367 0.7568878
 0.7751694  0.84395397 0.86591494 0.8732039  0.9240024  0.9102541
 0.8487582  0.9199379  1.013646   1.0445064  1.0819237  1.2339586
 1.298781   1.1060929  0.8656103  0.6163558  0.55803126 0.5866839
 0.53068864 0.5026384  0.2714886  0.5371133  0.3967244  0.38858485
 0.5488201  0.68407726 0.8278203  1.0930319  1.183754   1.1283705
 0.9602462  0.79468244 0.6760589  0.54253614 0.50498796 0.5245922
 0.7164701  1.0333507  1.3117553  1.5343161  1.6989179  1.742951
 1.6148462  1.3643638  1.1276346  0.9728356  0.81667507 0.73213965
 0.4894049  0.5205214  1.0376139  1.4871471  1.5165743  1.2729523
 1.0308483  0.94599926 0.94017357 0.88672864 1.1302013  1.1662942
 0.96582013 0.77976704 0.71823233 0.7826681  0.8127118  0.76867193
 0.7545572  0.75719875 0.6864299  0.6588641  0.8556222  1.003525
 0.99235755 0.99877685 1.1075752  1.0987206  0.8521447  0.6310582
 0.48797262 0.5218171  0.51363546 0.45856288 0.3324009  0.50611323
 0.5151666  0.49018538 0.6092136  0.7888638  0.87002635 0.95807797
 1.0091151  0.9804666  0.89116347 0.7818968  0.75817275 0.6119462
 0.47249553 0.38472366 0.4519877  0.7532684  1.0886115  1.3658326
 1.5797142  1.6742381  1.5814052  1.298676   0.9801803  0.8405056
 0.76772225 0.5867369  0.32093078 0.19682613 0.70792276 1.3078845
 1.5921954  1.41783    1.0348467  0.640862   0.73004425 0.8657772
 1.1775922  1.2950945  1.1587026  0.95763576 0.774261   0.7728941
 0.83549935 0.80450743 0.7220236  0.61202186 0.48806378 0.43296638
 0.52120566 0.76089674 0.9764849  0.92757744 0.8815573  0.9338765
 0.88909733 0.6600981  0.53911936 0.5369449  0.6032259  0.57150865
 0.43310243 0.42730904 0.6990886  0.52769643 0.6112996  0.79559416
 0.97944766 0.9848404  0.88871866 0.76375914 0.74842864 0.74217665
 0.8433824  0.8082772  0.6119709  0.4338724  0.3252331  0.47865626
 0.8215909  1.1431446  1.3921784  1.522411   1.4814799  1.2763214
 0.9856385  0.829872   0.92319345 0.9126811  0.7068424  0.21756539
 0.17044973 0.78771263 1.3661577  1.522248   1.2750925  0.76744556
 0.3819192  0.7761846  1.1684642  1.298678   1.3172718  1.2612946
 1.0976363  0.914524   0.9341978  0.9411168  0.86937475 0.7609892
 0.61496156 0.4712307  0.34482092 0.5094538  0.69173735 0.90076125
 0.90017784 0.7501014  0.72464186 0.7151869  0.46999994 0.56319916
 0.69228536 0.7408596  0.6594872  0.49811235 0.7296416  0.70379835
 0.60322887 0.709557   0.9106599  1.037543   0.9356764  0.75323176
 0.5658994  0.6224646  0.7858105  0.9560944  0.82449234 0.6602547
 0.46380004 0.3681632  0.5545126  0.90833324 1.1783919  1.3078684
 1.3107855  1.2112892  1.0261439  0.8421121  0.84593046 1.0327715
 1.0566698  0.83170635 0.37463388 0.35637695 0.6134721  1.1661936
 1.3406991  1.1228572  0.59290004 0.5855723  1.0357646  1.322842
 1.3316741  1.4508526  1.5024096  1.3753548  1.180295   1.1931803
 1.151185   1.0218655  0.88490146 0.78246415 0.649375   0.46263492
 0.47295672 0.5728327  0.718811   0.9599061  0.7178399  0.5679206
 0.7309556  0.3197054  0.68235886 0.8776206  0.8307988  0.75220364
 0.6146168  0.90469503 0.7829135  0.6860555  0.7696579  0.93834114
 0.9554078  0.80992526 0.6891407  0.518911   0.58726954 0.84016395
 0.96421975 0.84837174 0.7288904  0.5054732  0.36772946 0.55272293
 0.94371074 1.1682776  1.2087889  1.1394321  1.0164005  0.88037646
 0.7762959  0.82151806 1.0196321  1.1365119  0.94668746 0.57984984
 0.6450417  0.67780143 0.7660177  1.0350585  0.9801504  0.69759905
 0.9669759  1.2502966  1.3614788  1.4490845  1.6312506  1.8097188
 1.8342825  1.6951716  1.6253974  1.5100634 ]
