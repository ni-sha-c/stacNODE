time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 10000
num_test: 6000
num_trans: 500
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 1024
n_layers: 7
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 100.06%, model saved.
Epoch: 0 Train: 3769.33667 Test: 4157.29102
Epoch 100: New minimal relative error: 41.82%, model saved.
Epoch: 100 Train: 8.88177 Test: 14.70059
Epoch 200: New minimal relative error: 25.22%, model saved.
Epoch: 200 Train: 1.80640 Test: 8.56349
Epoch: 300 Train: 18.20894 Test: 19.79975
Epoch: 400 Train: 3.86400 Test: 12.06289
Epoch: 500 Train: 0.49176 Test: 8.35000
Epoch 600: New minimal relative error: 22.34%, model saved.
Epoch: 600 Train: 7.29141 Test: 11.54352
Epoch: 700 Train: 1.64973 Test: 11.09313
Epoch: 800 Train: 3.55030 Test: 15.23042
Epoch: 900 Train: 3.29208 Test: 16.39429
Epoch: 1000 Train: 2.62243 Test: 16.76461
Epoch: 1100 Train: 5.10334 Test: 19.24260
Epoch: 1200 Train: 3.41039 Test: 17.64442
Epoch: 1300 Train: 2.41835 Test: 19.07446
Epoch: 1400 Train: 0.07949 Test: 16.94857
Epoch: 1500 Train: 5.53495 Test: 21.39824
Epoch: 1600 Train: 5.02177 Test: 26.38139
Epoch: 1700 Train: 2.04842 Test: 22.58111
Epoch: 1800 Train: 0.83120 Test: 21.13923
Epoch: 1900 Train: 10.87539 Test: 32.36496
Epoch: 2000 Train: 0.87187 Test: 21.27337
Epoch: 2100 Train: 4.60422 Test: 28.84951
Epoch: 2200 Train: 3.32860 Test: 27.54118
Epoch: 2300 Train: 0.49672 Test: 25.34013
Epoch: 2400 Train: 0.22000 Test: 26.74236
Epoch: 2500 Train: 0.03126 Test: 26.96445
Epoch: 2600 Train: 0.93521 Test: 27.04998
Epoch: 2700 Train: 1.09738 Test: 29.53410
Epoch: 2800 Train: 0.33920 Test: 29.95096
Epoch: 2900 Train: 1.14699 Test: 31.54618
Epoch: 3000 Train: 2.21222 Test: 32.55637
Epoch: 3100 Train: 0.82852 Test: 32.11425
Epoch: 3200 Train: 0.84159 Test: 34.09034
Epoch: 3300 Train: 1.69539 Test: 34.43324
Epoch: 3400 Train: 1.72168 Test: 37.13987
Epoch: 3500 Train: 0.13890 Test: 35.31535
Epoch: 3600 Train: 0.35862 Test: 35.54008
Epoch: 3700 Train: 0.62463 Test: 37.23677
Epoch: 3800 Train: 0.93147 Test: 38.01014
Epoch: 3900 Train: 1.23526 Test: 39.10099
Epoch: 4000 Train: 0.58765 Test: 39.09191
Epoch: 4100 Train: 1.03858 Test: 40.96938
Epoch: 4200 Train: 1.08334 Test: 40.73170
Epoch: 4300 Train: 0.43230 Test: 41.80155
Epoch: 4400 Train: 0.40504 Test: 40.80265
Epoch: 4500 Train: 0.14569 Test: 41.28542
Epoch: 4600 Train: 0.09232 Test: 42.34584
Epoch 4700: New minimal relative error: 20.28%, model saved.
Epoch: 4700 Train: 0.28522 Test: 43.55522
Epoch: 4800 Train: 1.00767 Test: 44.22303
Epoch: 4900 Train: 0.35877 Test: 44.38741
Epoch: 5000 Train: 0.11361 Test: 45.32360
Epoch: 5100 Train: 0.20633 Test: 45.20045
Epoch: 5200 Train: 0.11360 Test: 45.93295
Epoch: 5300 Train: 0.12558 Test: 46.40932
Epoch: 5400 Train: 0.04330 Test: 46.88966
Epoch: 5500 Train: 0.58513 Test: 47.23121
Epoch: 5600 Train: 1.19770 Test: 47.66280
Epoch: 5700 Train: 0.03686 Test: 47.85641
Epoch: 5800 Train: 0.26095 Test: 48.57088
Epoch: 5900 Train: 0.30859 Test: 49.46087
Epoch: 6000 Train: 1.24199 Test: 51.36992
Epoch: 6100 Train: 0.66384 Test: 51.05594
Epoch: 6200 Train: 0.25375 Test: 51.19592
Epoch: 6300 Train: 0.02038 Test: 50.34318
Epoch: 6400 Train: 0.14156 Test: 51.72097
Epoch: 6500 Train: 0.48040 Test: 51.94653
Epoch: 6600 Train: 0.01120 Test: 51.91923
Epoch: 6700 Train: 0.00885 Test: 52.12037
Epoch: 6800 Train: 0.07522 Test: 53.41516
Epoch: 6900 Train: 0.02617 Test: 52.95623
Epoch: 7000 Train: 0.62511 Test: 53.24858
Epoch: 7100 Train: 0.36093 Test: 53.78455
Epoch: 7200 Train: 0.15491 Test: 54.08570
Epoch: 7300 Train: 0.22244 Test: 54.93007
Epoch: 7400 Train: 0.03568 Test: 54.71991
Epoch: 7500 Train: 0.24392 Test: 55.84490
Epoch: 7600 Train: 0.03153 Test: 55.93272
Epoch: 7700 Train: 0.01233 Test: 55.99961
Epoch: 7800 Train: 0.18860 Test: 56.82767
Epoch: 7900 Train: 0.03427 Test: 57.25203
Epoch: 8000 Train: 0.01316 Test: 57.19848
Epoch: 8100 Train: 0.01680 Test: 57.25765
Epoch: 8200 Train: 0.04255 Test: 58.59354
Epoch: 8300 Train: 0.09713 Test: 58.47372
Epoch: 8400 Train: 0.26310 Test: 58.44597
Epoch: 8500 Train: 0.02003 Test: 59.09246
Epoch: 8600 Train: 0.25607 Test: 60.13402
Epoch: 8700 Train: 0.19929 Test: 59.46906
Epoch: 8800 Train: 0.16175 Test: 60.00428
Epoch: 8900 Train: 0.00323 Test: 60.35248
Epoch: 9000 Train: 0.00566 Test: 60.34647
Epoch: 9100 Train: 0.25771 Test: 60.15627
Epoch: 9200 Train: 0.01040 Test: 61.11133
Epoch: 9300 Train: 0.18195 Test: 61.67552
Epoch: 9400 Train: 0.03354 Test: 61.60132
Epoch: 9500 Train: 0.00826 Test: 62.14682
Epoch: 9600 Train: 0.00360 Test: 62.33077
Epoch: 9700 Train: 0.00315 Test: 62.23759
Epoch: 9800 Train: 0.01653 Test: 62.98621
Epoch: 9900 Train: 0.01001 Test: 62.74650
Epoch: 9999 Train: 0.03013 Test: 63.28410
Training Loss: tensor(0.0301)
Test Loss: tensor(63.2841)
Learned LE: [ 0.8610416  -0.11740638 -5.884311  ]
True LE: [ 8.6395562e-01  1.1266034e-02 -1.4548941e+01]
Relative Error: [ 8.60399    8.640516   9.608215  11.032612  12.449632  13.659326
 14.642157  15.400985  15.899183  16.09688   15.9999075 15.674548
 15.237898  14.84662   14.670918  14.846013  15.445654  16.481709
 17.90291   19.605095  21.463984  23.350925  25.13456   26.67815
 27.823835  28.415758  28.358889  27.664465  26.45004   24.901209
 23.235136  21.667204  20.367308  19.433386  18.894325  18.716202
 18.817495  19.098047  19.463945  19.840649  20.17839   20.452463
 20.65754   20.798754  20.88253   20.910728  20.87777   20.770203
 20.567709  20.246565  19.787096  19.184456  18.457266  17.645468
 16.793789  15.92422   15.013517  14.0002985 12.830242  11.503036
 10.083417   8.71345    7.6700673  7.372289   8.031882   9.310959
 10.692904  11.896388  12.879729  13.6617985 14.212068  14.472671
 14.421047  14.099068  13.6052265 13.08462   12.714609  12.653129
 12.994877  13.773015  14.960216  16.465307  18.162975  19.92614
 21.630932  23.15428   24.348318  25.04629   25.129604  24.588583
 23.530384  22.132698  20.601519  19.14368   17.927135  17.052265
 16.553692  16.405573  16.531126  16.831928  17.214684  17.60492
 17.952467  18.23305   18.443562  18.592533  18.68989   18.740114
 18.739319  18.674608  18.525347  18.265667  17.871147  17.330002
 16.655401  15.8889265 15.087971  14.297006  13.514669  12.683457
 11.727933  10.61712    9.387925   8.13341    7.027944   6.4094887
  6.6554503  7.6920977  9.017962  10.232194  11.224316  12.026362
 12.633197  12.979877  13.012639  12.739858  12.235646  11.623444
 11.074484  10.769256  10.829077  11.307606  12.207088  13.465886
 14.966204  16.579065  18.183908  19.670143  20.91086   21.73616
 21.99743   21.65002   20.78002   19.556196  18.172232  16.823627
 15.6772375 14.837128  14.345667  14.190586  14.306952  14.60187
 14.984276  15.379451  15.73479   16.023312  16.241486  16.400232
 16.513475  16.58957   16.627373  16.61574   16.534517  16.356337
 16.051882  15.599767  15.001394  14.291186  13.532048  12.791284
 12.1015415 11.4283695 10.685005   9.801733   8.781895   7.6893864
  6.62579    5.79214    5.5695786  6.205524   7.3945403  8.6303005
  9.656906  10.477747  11.132908  11.577708  11.733994  11.566748
 11.114216  10.472998   9.788716   9.251907   9.021726   9.173923
  9.733154  10.679629  11.926901  13.347636  14.819191  16.23549
 17.496458  18.451141  18.922325  18.813753  18.170925  17.14866
 15.930835  14.698855  13.617262  12.796304  12.2843075 12.085173
 12.15421   12.410787  12.769452  13.156681  13.516259  13.814489
 14.042746  14.211617  14.338901  14.438444  14.514197  14.558855
 14.55435   14.473593  14.283583  13.953129  13.4668455 12.841397
 12.131611  11.417703  10.770646  10.203937   9.648482   8.999683
  8.207237   7.305463   6.3670673  5.485677   4.8894978  4.9696937
  5.8253684  7.030365   8.133494   8.996526   9.682604  10.212653
 10.514862  10.51307   10.190664   9.606411   8.870952   8.149415
  7.6394386  7.46255    7.655835   8.225915   9.1401415 10.3023
 11.588725  12.888143  14.11355   15.160869  15.851052  16.026373
 15.661303  14.877137  13.852845  12.756991  11.746478  10.941969
 10.396895  10.124538  10.106486  10.284696  10.585893  10.942638
 11.297364  11.606576  11.849502  12.029783  12.1663065 12.279517
 12.381638  12.472719  12.540552  12.561306  12.50159   12.323175
 11.993393  11.502823  10.881231  10.199777   9.552327   9.012436
  8.57484    8.140881   7.5970135  6.9132404  6.1438427  5.354458
  4.624722   4.1978445  4.4525113  5.3958335  6.558041   7.535181
  8.263954   8.838088   9.264066   9.459346   9.352638   8.934021
  8.270971   7.4797273  6.738016   6.242895   6.079288   6.2561193
  6.765669   7.573688   8.591004   9.706211  10.822557  11.870334
 12.731428  13.210602  13.184482  12.69273   11.899606  10.973849
 10.057918   9.280241   8.711885   8.36171    8.227787   8.285204
  8.4838085  8.771145   9.097329   9.41286    9.678186   9.878097
 10.023235  10.137587  10.24369   10.353734  10.466949  10.569012
 10.632282  10.617865  10.481643  10.187747   9.728157   9.139346
  8.502018   7.92204    7.481278   7.166557   6.8584533  6.4338436
  5.872001   5.2358265  4.5806785  3.9667912  3.621114   3.9129474
  4.848713   5.955427   6.834156   7.449538   7.9224935  8.2690735
  8.407643   8.266433   7.824699   7.144039   6.335849   5.5753202
  5.063866   4.8692665  4.9812837  5.3725424  6.012284   6.834749
  7.7514977  8.681078   9.568084  10.28634  ]
