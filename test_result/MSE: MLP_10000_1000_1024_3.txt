time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 10000
num_test: 6000
num_trans: 1000
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 1024
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 99.52%, model saved.
Epoch: 0 Train: 4242.73975 Test: 3918.35278
Epoch 100: New minimal relative error: 39.22%, model saved.
Epoch: 100 Train: 19.78142 Test: 24.34798
Epoch 200: New minimal relative error: 25.40%, model saved.
Epoch: 200 Train: 5.36113 Test: 8.26483
Epoch: 300 Train: 13.85638 Test: 32.81113
Epoch: 400 Train: 3.80392 Test: 6.09787
Epoch: 500 Train: 1.61772 Test: 3.92393
Epoch: 600 Train: 1.10966 Test: 2.71891
Epoch: 700 Train: 11.58089 Test: 14.31650
Epoch: 800 Train: 4.66657 Test: 6.93588
Epoch: 900 Train: 0.72875 Test: 2.39951
Epoch: 1000 Train: 1.23829 Test: 2.08536
Epoch: 1100 Train: 1.29785 Test: 2.75823
Epoch: 1200 Train: 3.21494 Test: 4.99323
Epoch: 1300 Train: 0.77302 Test: 2.28576
Epoch: 1400 Train: 3.44094 Test: 4.81372
Epoch: 1500 Train: 0.41138 Test: 1.72572
Epoch: 1600 Train: 6.66636 Test: 8.50103
Epoch 1700: New minimal relative error: 23.60%, model saved.
Epoch: 1700 Train: 0.19125 Test: 1.47338
Epoch: 1800 Train: 0.70391 Test: 2.20691
Epoch: 1900 Train: 4.41340 Test: 5.52296
Epoch: 2000 Train: 0.55989 Test: 1.83317
Epoch: 2100 Train: 1.79177 Test: 3.55873
Epoch: 2200 Train: 2.12230 Test: 3.17853
Epoch: 2300 Train: 0.40360 Test: 1.59039
Epoch 2400: New minimal relative error: 10.96%, model saved.
Epoch: 2400 Train: 0.10662 Test: 1.39338
Epoch: 2500 Train: 0.16067 Test: 1.50015
Epoch: 2600 Train: 0.18239 Test: 1.56296
Epoch: 2700 Train: 0.27910 Test: 1.61421
Epoch: 2800 Train: 0.21007 Test: 1.51860
Epoch: 2900 Train: 0.80064 Test: 2.05342
Epoch: 3000 Train: 0.58154 Test: 1.98492
Epoch: 3100 Train: 0.31165 Test: 1.62415
Epoch: 3200 Train: 0.19274 Test: 1.50866
Epoch: 3300 Train: 0.11897 Test: 1.46929
Epoch: 3400 Train: 0.27106 Test: 1.67302
Epoch: 3500 Train: 0.11715 Test: 1.45256
Epoch: 3600 Train: 1.51925 Test: 2.84204
Epoch: 3700 Train: 1.76674 Test: 3.43865
Epoch: 3800 Train: 0.18077 Test: 1.58090
Epoch: 3900 Train: 0.07889 Test: 1.46355
Epoch: 4000 Train: 0.07348 Test: 1.44932
Epoch: 4100 Train: 0.12315 Test: 1.53356
Epoch: 4200 Train: 0.07107 Test: 1.47445
Epoch: 4300 Train: 0.10029 Test: 1.48543
Epoch: 4400 Train: 1.72835 Test: 3.38013
Epoch: 4500 Train: 0.09754 Test: 1.48456
Epoch: 4600 Train: 0.09112 Test: 1.48603
Epoch: 4700 Train: 0.21281 Test: 1.60114
Epoch: 4800 Train: 0.07052 Test: 1.49231
Epoch: 4900 Train: 0.28695 Test: 1.68273
Epoch: 5000 Train: 1.47562 Test: 3.14035
Epoch: 5100 Train: 1.19433 Test: 2.11180
Epoch: 5200 Train: 0.13279 Test: 1.53994
Epoch: 5300 Train: 0.08981 Test: 1.49155
Epoch: 5400 Train: 0.08163 Test: 1.55221
Epoch: 5500 Train: 0.28804 Test: 1.78135
Epoch: 5600 Train: 0.23558 Test: 1.68045
Epoch: 5700 Train: 0.10106 Test: 1.56722
Epoch: 5800 Train: 0.03594 Test: 1.49169
Epoch: 5900 Train: 0.26241 Test: 1.68067
Epoch: 6000 Train: 0.18294 Test: 1.65728
Epoch: 6100 Train: 0.12061 Test: 1.57828
Epoch: 6200 Train: 0.15803 Test: 1.60408
Epoch: 6300 Train: 0.04055 Test: 1.50817
Epoch: 6400 Train: 0.03501 Test: 1.51129
Epoch: 6500 Train: 0.04157 Test: 1.51435
Epoch: 6600 Train: 0.11985 Test: 1.62829
Epoch: 6700 Train: 0.09472 Test: 1.58278
Epoch: 6800 Train: 0.03910 Test: 1.52704
Epoch: 6900 Train: 0.11405 Test: 1.61433
Epoch: 7000 Train: 0.13332 Test: 1.60863
Epoch: 7100 Train: 0.04016 Test: 1.55059
Epoch: 7200 Train: 0.09094 Test: 1.65716
Epoch: 7300 Train: 0.86009 Test: 2.51226
Epoch: 7400 Train: 0.03422 Test: 1.52914
Epoch: 7500 Train: 0.78056 Test: 2.35525
Epoch: 7600 Train: 0.03026 Test: 1.52907
Epoch: 7700 Train: 0.05648 Test: 1.57601
Epoch: 7800 Train: 0.02397 Test: 1.52574
Epoch: 7900 Train: 0.02433 Test: 1.54087
Epoch: 8000 Train: 0.02478 Test: 1.54010
Epoch: 8100 Train: 0.93901 Test: 2.26599
Epoch: 8200 Train: 0.02249 Test: 1.53785
Epoch: 8300 Train: 0.02277 Test: 1.53658
Epoch: 8400 Train: 0.03369 Test: 1.54986
Epoch: 8500 Train: 0.06813 Test: 1.58090
Epoch: 8600 Train: 0.04265 Test: 1.57920
Epoch: 8700 Train: 0.40979 Test: 2.01326
Epoch: 8800 Train: 0.02043 Test: 1.53602
Epoch: 8900 Train: 0.02020 Test: 1.54800
Epoch: 9000 Train: 0.12660 Test: 1.61389
Epoch: 9100 Train: 0.03064 Test: 1.55150
Epoch: 9200 Train: 0.01926 Test: 1.54003
Epoch: 9300 Train: 0.02315 Test: 1.55011
Epoch: 9400 Train: 0.04328 Test: 1.57439
Epoch: 9500 Train: 0.03670 Test: 1.55840
Epoch: 9600 Train: 0.01838 Test: 1.53866
Epoch: 9700 Train: 0.01811 Test: 1.54516
Epoch: 9800 Train: 0.01849 Test: 1.54390
Epoch: 9900 Train: 0.02068 Test: 1.54994
Epoch: 9999 Train: 0.02466 Test: 1.55793
Training Loss: tensor(0.0247)
Test Loss: tensor(1.5579)
Learned LE: [ 0.91920745 -0.08134469 -4.5666122 ]
True LE: [ 8.6570120e-01  8.4470399e-03 -1.4543833e+01]
Relative Error: [7.342472   7.303978   7.175557   6.9429874  6.597051   6.132338
 5.5800877  5.030167   4.5468793  4.1217237  3.7321482  3.4132707
 3.3376     3.706874   4.437061   5.28389    6.1024165  6.7109
 6.714576   6.329869   5.973391   5.7124596  5.4543667  5.0805483
 4.777807   4.676433   4.719587   4.842764   4.9406962  4.8952675
 4.781756   4.5547295  3.9354317  3.4073262  3.1179225  3.0361972
 3.154172   3.4850292  3.7872996  3.843012   3.9242654  4.0842257
 4.122449   4.0576797  4.0365415  4.1107     4.2602577  4.476759
 4.662253   4.745361   4.8784027  4.990043   5.0486197  5.0910687
 5.245018   5.505453   5.785401   6.053783   6.2918158  6.485981
 6.622346   6.7034855  6.740333   6.727363   6.6436825  6.4670706
 6.179427   5.767114   5.2346773  4.654902   4.1295757  3.6916077
 3.2965467  2.9467375  2.8374937  3.2338402  4.047704   4.9585285
 5.8774548  6.6586876  6.7862945  6.448628   6.0436406  5.7390366
 5.524664   5.208594   4.82256    4.5888734  4.4846864  4.4958453
 4.6236115  4.7364416  4.6695256  4.5947323  4.416886   3.7478771
 3.2592232  2.993278   2.8400004  2.8922906  3.1547043  3.2141943
 3.1737044  3.3079042  3.4376252  3.423904   3.401261   3.4480736
 3.5613942  3.7451484  3.9857333  4.121141   4.2501645  4.414267
 4.490758   4.506759   4.5334682  4.716674   4.972825   5.232105
 5.492408   5.7437096  5.947618   6.071012   6.117458   6.110793
 6.056911   5.9383082  5.729217   5.404086   4.9441953  4.37299
 3.794078   3.3057158  2.9037192  2.5211039  2.321888   2.6321902
 3.4495094  4.423877   5.3972473  6.3604565  6.7246847  6.535986
 6.1389856  5.7522907  5.507629   5.306599   4.977576   4.673193
 4.464124   4.278945   4.205222   4.3041697  4.4336543  4.41842
 4.3557634  4.250986   3.6211305  3.14911    2.8197954  2.5670142
 2.5827105  2.7108176  2.5739172  2.5291789  2.675899   2.7571034
 2.774636   2.814512   2.8854334  3.0144348  3.2266867  3.4745362
 3.6002986  3.786783   3.9304566  3.9648123  3.9426382  3.9632764
 4.1486363  4.3630934  4.5966487  4.8621597  5.1238966  5.330157
 5.4465685  5.4706087  5.428255   5.341642   5.2038326  4.986093
 4.650276   4.170121   3.5839822  3.0089357  2.5445158  2.1494825
 1.8408921  2.0029135  2.7120023  3.6796813  4.68578    5.705235
 6.383448   6.3589797  6.1027923  5.6826463  5.3485913  5.1935067
 5.0385365  4.7384343  4.501208   4.307204   4.0593534  3.8937378
 3.908458   4.0179687  4.0914984  4.0499244  3.9986703  3.5449739
 3.0276747  2.628233   2.2821841  2.240995   2.2143962  1.951418
 1.907104   2.0198092  2.1066015  2.193739   2.2630637  2.3358529
 2.4668438  2.6939602  2.951952   3.1001642  3.3032284  3.4036438
 3.4087896  3.366487   3.3767252  3.52483    3.68482    3.895359
 4.1494603  4.3997254  4.6085587  4.740881   4.7728257  4.7181225
 4.616457   4.4817524  4.2861314  3.9771519  3.514274   2.9312518
 2.3309736  1.837708   1.4768859  1.4059081  1.9502612  2.8258498
 3.7700827  4.6958566  5.591081   5.948018   5.870154   5.596017
 5.1477523  4.811412   4.696854   4.635311   4.455739   4.254941
 4.0756397  3.845083   3.5943224  3.4737616  3.4907281  3.6215816
 3.6934593  3.6102693  3.4759355  2.9034905  2.4877791  2.0656915
 1.9096652  1.7676467  1.4092363  1.3026551  1.3750746  1.511881
 1.6532359  1.7354091  1.7967694  1.9110057  2.1308205  2.4113395
 2.585406   2.7747922  2.8318026  2.8236775  2.785122   2.765389
 2.8612108  2.974426   3.143753   3.3561482  3.5779252  3.7839103
 3.93879    4.0149937  4.004675   3.9294984  3.8232412  3.6760302
 3.4333966  3.0395103  2.5031989  1.8806325  1.3134184  0.99290276
 1.0703387  1.8047259  2.7596588  3.564144   4.252552   5.0687923
 5.3900337  5.344414   5.0734377  4.644247   4.2481236  4.0975223
 4.063081   3.9369597  3.84577    3.7863083  3.584192   3.3361084
 3.0808723  2.9830804  3.0536242  3.252903   3.2453306  3.1762044
 2.870623   2.4080188  1.9388252  1.6452446  1.4508375  1.0305964
 0.759844   0.7776883  0.9453368  1.1365215  1.2103016  1.2415986
 1.3293208  1.5132722  1.8233348  2.0409114  2.2358944  2.2650087
 2.2457707  2.2150452  2.1546087  2.187881   2.2747893  2.389183
 2.5418108  2.7130573  2.8839817  3.0363114  3.1666656  3.2625885
 3.2881682  3.2427814  3.1546571  2.997167   2.7145798  2.2944617
 1.7801211  1.1832011  0.6990592  0.5154199  1.2686806  2.3358445
 3.090825   3.612874   4.2970614  4.682269   4.68766    4.5838723
 4.3427935  3.9809027  3.737437   3.630842  ]
