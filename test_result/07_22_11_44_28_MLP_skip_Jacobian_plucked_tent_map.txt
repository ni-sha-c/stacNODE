time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 3000
num_test: 3000
num_val: 0
num_trans: 0
loss_type: Jacobian
dyn_sys: plucked_tent_map
model_type: MLP_skip
s: 0.2
n_hidden: 512
n_layers: 2
reg_param: 200.0
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 9.759664536 Test: 7.437874317
Epoch 0: New minimal relative error: 7.44%, model saved.
Epoch: 80 Train: 0.519183755 Test: 0.528582692
Epoch 80: New minimal relative error: 0.53%, model saved.
Epoch: 160 Train: 0.367649168 Test: 0.405687183
Epoch 160: New minimal relative error: 0.41%, model saved.
Epoch: 240 Train: 0.340188622 Test: 0.350476444
Epoch 240: New minimal relative error: 0.35%, model saved.
Epoch: 320 Train: 0.266863793 Test: 0.283109367
Epoch 320: New minimal relative error: 0.28%, model saved.
Epoch: 400 Train: 0.287771791 Test: 0.322373867
Epoch: 480 Train: 0.254447818 Test: 0.262932599
Epoch 480: New minimal relative error: 0.26%, model saved.
Epoch: 560 Train: 0.230927542 Test: 0.232095823
Epoch 560: New minimal relative error: 0.23%, model saved.
Epoch: 640 Train: 0.219769597 Test: 0.220004261
Epoch 640: New minimal relative error: 0.22%, model saved.
Epoch: 720 Train: 0.229567766 Test: 0.237998649
Epoch: 800 Train: 0.219714984 Test: 0.217230543
Epoch 800: New minimal relative error: 0.22%, model saved.
Epoch: 880 Train: 0.225178465 Test: 0.226481035
Epoch: 960 Train: 0.225131899 Test: 0.220207512
Epoch: 1040 Train: 0.230879262 Test: 0.236797869
Epoch: 1120 Train: 0.218816385 Test: 0.214808345
Epoch 1120: New minimal relative error: 0.21%, model saved.
Epoch: 1200 Train: 0.197539687 Test: 0.197283670
Epoch 1200: New minimal relative error: 0.20%, model saved.
Epoch: 1280 Train: 0.200573489 Test: 0.211588308
Epoch: 1360 Train: 0.194641829 Test: 0.200288102
Epoch: 1440 Train: 0.190018669 Test: 0.192707017
Epoch 1440: New minimal relative error: 0.19%, model saved.
Epoch: 1520 Train: 0.195519567 Test: 0.209943801
Epoch: 1600 Train: 0.190910548 Test: 0.205803007
Epoch: 1680 Train: 0.193288028 Test: 0.208115757
Epoch: 1760 Train: 0.177637726 Test: 0.178322658
Epoch 1760: New minimal relative error: 0.18%, model saved.
Epoch: 1840 Train: 0.181602970 Test: 0.183190912
Epoch: 1920 Train: 0.173961908 Test: 0.176092610
Epoch 1920: New minimal relative error: 0.18%, model saved.
Epoch: 2000 Train: 0.166940510 Test: 0.170961574
Epoch 2000: New minimal relative error: 0.17%, model saved.
Epoch: 2080 Train: 0.171967417 Test: 0.185479224
Epoch: 2160 Train: 0.178209618 Test: 0.187240049
Epoch: 2240 Train: 0.168105379 Test: 0.181549057
Epoch: 2320 Train: 0.155527145 Test: 0.160969198
Epoch 2320: New minimal relative error: 0.16%, model saved.
Epoch: 2400 Train: 0.157324523 Test: 0.158745870
Epoch 2400: New minimal relative error: 0.16%, model saved.
Epoch: 2480 Train: 0.161831215 Test: 0.158922553
Epoch: 2560 Train: 0.152630717 Test: 0.152142033
Epoch 2560: New minimal relative error: 0.15%, model saved.
Epoch: 2640 Train: 0.151844323 Test: 0.150931254
Epoch 2640: New minimal relative error: 0.15%, model saved.
Epoch: 2720 Train: 0.150934726 Test: 0.152312309
Epoch: 2800 Train: 0.148025513 Test: 0.146244064
Epoch 2800: New minimal relative error: 0.15%, model saved.
Epoch: 2880 Train: 0.145652428 Test: 0.143065229
Epoch 2880: New minimal relative error: 0.14%, model saved.
Epoch: 2960 Train: 0.144358575 Test: 0.143144533
Epoch: 3040 Train: 0.144103095 Test: 0.143332928
Epoch: 3120 Train: 0.142479882 Test: 0.142248943
Epoch 3120: New minimal relative error: 0.14%, model saved.
Epoch: 3200 Train: 0.139701530 Test: 0.137874469
Epoch 3200: New minimal relative error: 0.14%, model saved.
Epoch: 3280 Train: 0.140624419 Test: 0.137828633
Epoch 3280: New minimal relative error: 0.14%, model saved.
Epoch: 3360 Train: 0.136796266 Test: 0.134054735
Epoch 3360: New minimal relative error: 0.13%, model saved.
Epoch: 3440 Train: 0.141552970 Test: 0.135928139
Epoch: 3520 Train: 0.145861119 Test: 0.143000618
Epoch: 3600 Train: 0.156533286 Test: 0.154970676
Epoch: 3680 Train: 0.157122642 Test: 0.156470910
Epoch: 3760 Train: 0.157400638 Test: 0.157282248
Epoch: 3840 Train: 0.160212383 Test: 0.160478726
Epoch: 3920 Train: 0.162682563 Test: 0.163032591
Epoch: 4000 Train: 0.158569843 Test: 0.159114778
Epoch: 4080 Train: 0.161126778 Test: 0.160240561
Epoch: 4160 Train: 0.163286701 Test: 0.164036959
Epoch: 4240 Train: 0.165036336 Test: 0.166532144
Epoch: 4320 Train: 0.162384018 Test: 0.161254048
Epoch: 4400 Train: 0.145173773 Test: 0.145553067
Epoch: 4480 Train: 0.142051831 Test: 0.141991377
Epoch: 4560 Train: 0.142458737 Test: 0.142237797
Epoch: 4640 Train: 0.141947657 Test: 0.140590891
Epoch: 4720 Train: 0.142528892 Test: 0.142801121
Epoch: 4800 Train: 0.144053474 Test: 0.146933928
Epoch: 4880 Train: 0.137486801 Test: 0.136452883
Epoch: 4960 Train: 0.137605295 Test: 0.134791434
Epoch: 5040 Train: 0.138249040 Test: 0.137541622
Epoch: 5120 Train: 0.144784912 Test: 0.143209130
Epoch: 5200 Train: 0.144831806 Test: 0.143745795
Epoch: 5280 Train: 0.144401610 Test: 0.144805029
Epoch: 5360 Train: 0.145499080 Test: 0.145550877
Epoch: 5440 Train: 0.149448022 Test: 0.150185868
Epoch: 5520 Train: 0.157949537 Test: 0.158657461
Epoch: 5600 Train: 0.151674539 Test: 0.152896509
Epoch: 5680 Train: 0.157972053 Test: 0.159672096
Epoch: 5760 Train: 0.151174098 Test: 0.150774747
Epoch: 5840 Train: 0.154694408 Test: 0.154532433
Epoch: 5920 Train: 0.149715349 Test: 0.148359135
Epoch: 6000 Train: 0.149322495 Test: 0.147208676
Epoch: 6080 Train: 0.160637453 Test: 0.159790382
Epoch: 6160 Train: 0.157597870 Test: 0.156786248
Epoch: 6240 Train: 0.159119055 Test: 0.157656699
Epoch: 6320 Train: 0.151682734 Test: 0.150119171
Epoch: 6400 Train: 0.148679793 Test: 0.148705095
Epoch: 6480 Train: 0.147935316 Test: 0.145525381
Epoch: 6560 Train: 0.145376325 Test: 0.143627346
Epoch: 6640 Train: 0.140669867 Test: 0.139152855
Epoch: 6720 Train: 0.139286533 Test: 0.139429525
Epoch: 6800 Train: 0.143087566 Test: 0.145141348
Epoch: 6880 Train: 0.141785547 Test: 0.142364368
Epoch: 6960 Train: 0.161954686 Test: 0.175791055
Epoch: 7040 Train: 0.162946239 Test: 0.176284924
Epoch: 7120 Train: 0.142725855 Test: 0.141294718
Epoch: 7200 Train: 0.141643569 Test: 0.140366495
Epoch: 7280 Train: 0.146917477 Test: 0.149902686
Epoch: 7360 Train: 0.154200286 Test: 0.159006238
Epoch: 7440 Train: 0.152809262 Test: 0.155640379
Epoch: 7520 Train: 0.170374274 Test: 0.180356219
Epoch: 7600 Train: 0.165441215 Test: 0.178566709
Epoch: 7680 Train: 0.143170446 Test: 0.143447965
Epoch: 7760 Train: 0.144355342 Test: 0.143432587
Epoch: 7840 Train: 0.144412145 Test: 0.143481120
Epoch: 7920 Train: 0.141280964 Test: 0.140279904
Epoch: 7999 Train: 0.140217528 Test: 0.138938695
Training Loss: tensor(0.1402)
Test Loss: tensor(0.1389)
True Mean x: tensor(1.0583, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(1.0641, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(0.3035, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(0.2918, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(0.0007)
Jacobian term Test Loss: tensor(0.0007)
Learned LE: [[0.67814714]]
True LE: [[0.693285]]
Norm Diff:: tensor(0.0151)
