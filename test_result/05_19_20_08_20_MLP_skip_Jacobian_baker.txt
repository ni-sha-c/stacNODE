time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 100
num_train: 1000
num_test: 8000
num_val: 3000
num_trans: 0
loss_type: Jacobian
dyn_sys: baker
model_type: MLP_skip
s: 0.2
n_hidden: 512
n_layers: 3
reg_param: 500
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 1007.589477539 Test: 5.595122337
Epoch 0: New minimal relative error: 5.60%, model saved.
Epoch: 1 Train: 729.426635742 Test: 2.195677042
Epoch 1: New minimal relative error: 2.20%, model saved.
Epoch: 2 Train: 473.509521484 Test: 4.105971813
Epoch: 3 Train: 233.779281616 Test: 16.191995621
Epoch: 4 Train: 68.601776123 Test: 43.402805328
Epoch: 5 Train: 68.748352051 Test: 69.789985657
Epoch: 6 Train: 179.845306396 Test: 72.759407043
Epoch: 7 Train: 195.345001221 Test: 60.578533173
Epoch: 8 Train: 133.518157959 Test: 44.653072357
Epoch: 9 Train: 69.622276306 Test: 30.988231659
Epoch: 10 Train: 37.924449921 Test: 21.453281403
Epoch: 11 Train: 37.492828369 Test: 15.607706070
Epoch: 12 Train: 52.259670258 Test: 12.390654564
Epoch: 13 Train: 68.125877380 Test: 10.904747009
Epoch: 14 Train: 77.526519775 Test: 10.575098038
Epoch: 15 Train: 78.669624329 Test: 11.105237961
Epoch: 16 Train: 72.945304871 Test: 12.358958244
Epoch: 17 Train: 62.737953186 Test: 14.282287598
Epoch: 18 Train: 51.239830017 Test: 16.824918747
Epoch: 19 Train: 41.009483337 Test: 19.880064011
Epoch: 20 Train: 33.918285370 Test: 23.233673096
Epoch: 21 Train: 30.964452744 Test: 26.581222534
Epoch: 22 Train: 31.840566635 Test: 29.497385025
Epoch: 23 Train: 35.034545898 Test: 31.644481659
Epoch: 24 Train: 38.494331360 Test: 32.824089050
Epoch: 25 Train: 40.641033173 Test: 32.977909088
Epoch: 26 Train: 40.778907776 Test: 32.219959259
Epoch: 27 Train: 38.994766235 Test: 30.773376465
Epoch: 28 Train: 36.114635468 Test: 28.910236359
Epoch: 29 Train: 33.132400513 Test: 26.887052536
Epoch: 30 Train: 30.794189453 Test: 24.913171768
Epoch: 31 Train: 29.473527908 Test: 23.143985748
Epoch: 32 Train: 29.123306274 Test: 21.638250351
Epoch: 33 Train: 29.524532318 Test: 20.443403244
Epoch: 34 Train: 30.273124695 Test: 19.558961868
Epoch: 35 Train: 31.051988602 Test: 18.971853256
Epoch: 36 Train: 31.576255798 Test: 18.656738281
Epoch: 37 Train: 31.714271545 Test: 18.582525253
Epoch: 38 Train: 31.489589691 Test: 18.714933395
Epoch: 39 Train: 30.969404221 Test: 19.017583847
Epoch: 40 Train: 30.250617981 Test: 19.456291199
Epoch: 41 Train: 29.464067459 Test: 20.003566742
Epoch: 42 Train: 28.706268311 Test: 20.612117767
Epoch: 43 Train: 28.109771729 Test: 21.230255127
Epoch: 44 Train: 27.742301941 Test: 21.807765961
Epoch: 45 Train: 27.562759399 Test: 22.302490234
Epoch: 46 Train: 27.524141312 Test: 22.673191071
Epoch: 47 Train: 27.562971115 Test: 22.904317856
Epoch: 48 Train: 27.607204437 Test: 22.982280731
Epoch: 49 Train: 27.552654266 Test: 22.929283142
Epoch: 50 Train: 27.421377182 Test: 22.764875412
Epoch: 51 Train: 27.268070221 Test: 22.510425568
Epoch: 52 Train: 27.072294235 Test: 22.182426453
Epoch: 53 Train: 26.850957870 Test: 21.802181244
Epoch: 54 Train: 26.698215485 Test: 21.416399002
Epoch: 55 Train: 26.534036636 Test: 21.042091370
Epoch: 56 Train: 26.430398941 Test: 20.692449570
Epoch: 57 Train: 26.374309540 Test: 20.382434845
Epoch: 58 Train: 26.330083847 Test: 20.118543625
Epoch: 59 Train: 26.347179413 Test: 19.904552460
Epoch: 60 Train: 26.323726654 Test: 19.740262985
Epoch: 61 Train: 26.328456879 Test: 19.624221802
Epoch: 62 Train: 26.357370377 Test: 19.552680969
Epoch: 63 Train: 26.335239410 Test: 19.522005081
Epoch: 64 Train: 26.296955109 Test: 19.526044846
Epoch: 65 Train: 26.259181976 Test: 19.555524826
Epoch: 66 Train: 26.148803711 Test: 19.601943970
Epoch: 67 Train: 26.091068268 Test: 19.658206940
Epoch: 68 Train: 26.027080536 Test: 19.717428207
Epoch: 69 Train: 25.961330414 Test: 19.773590088
Epoch: 70 Train: 25.889026642 Test: 19.821727753
Epoch: 71 Train: 25.824867249 Test: 19.858058929
Epoch: 72 Train: 25.769044876 Test: 19.880355835
Epoch: 73 Train: 25.739257812 Test: 19.887872696
Epoch: 74 Train: 25.689647675 Test: 19.880218506
Epoch: 75 Train: 25.646665573 Test: 19.859867096
Epoch: 76 Train: 25.597839355 Test: 19.825571060
Epoch: 77 Train: 25.568944931 Test: 19.777853012
Epoch: 78 Train: 25.536729813 Test: 19.719110489
Epoch: 79 Train: 25.551666260 Test: 19.651090622
Epoch: 80 Train: 25.534210205 Test: 19.577211380
Epoch: 81 Train: 25.529146194 Test: 19.498924255
Epoch: 82 Train: 25.519134521 Test: 19.418313980
Epoch: 83 Train: 25.492017746 Test: 19.335559845
Epoch: 84 Train: 25.471050262 Test: 19.254341125
Epoch: 85 Train: 25.412523270 Test: 19.176723480
Epoch: 86 Train: 25.421564102 Test: 19.103862762
Epoch: 87 Train: 25.396137238 Test: 19.036243439
Epoch: 88 Train: 25.376430511 Test: 18.976995468
Epoch: 89 Train: 25.388309479 Test: 18.923475266
Epoch: 90 Train: 25.411855698 Test: 18.873563766
Epoch: 91 Train: 25.431076050 Test: 18.828413010
Epoch: 92 Train: 25.448070526 Test: 18.788438797
Epoch: 93 Train: 25.411457062 Test: 18.754026413
Epoch: 94 Train: 25.419265747 Test: 18.725086212
Epoch: 95 Train: 25.401414871 Test: 18.700204849
Epoch: 96 Train: 25.359346390 Test: 18.679246902
Epoch: 97 Train: 25.338886261 Test: 18.660949707
Epoch: 98 Train: 25.344129562 Test: 18.644966125
Epoch: 99 Train: 25.346548080 Test: 18.630397797
Training Loss: tensor(-0.0314)
Test Loss: tensor(0.)
True Mean x: tensor(3.1818, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(0.4765, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(3.2344, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(0.0033, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(13.6263)
Jacobian term Test Loss: tensor(2.2967e-39)
Learned LE: [0.5788263  0.09956548]
True LE: None
