time_step: 0.01
lr: 0.001
weight_decay: 0.0001
num_epoch: 20000
num_train: 10000
num_test: 8000
num_val: 3000
num_trans: 0
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
s: 0.5
n_hidden: 256
n_layers: 5
reg_param: 1000
optim_name: AdamW
Epoch: 0 Train: 1.38889 Test: 4089.55957
Epoch 0: New minimal relative error: 99.95%, model saved.
Epoch: 200 Train: 0.00363 Test: 12.02579
Epoch 200: New minimal relative error: 5.18%, model saved.
Epoch: 400 Train: 0.00123 Test: 5.24760
Epoch 400: New minimal relative error: 3.45%, model saved.
Epoch: 600 Train: 0.01971 Test: 33.37936
Epoch: 800 Train: 0.00048 Test: 2.85060
Epoch: 1000 Train: 0.00097 Test: 5.54079
Epoch: 1200 Train: 0.00022 Test: 2.35507
Epoch: 1400 Train: 0.00063 Test: 2.25494
Epoch 1400: New minimal relative error: 2.08%, model saved.
Epoch: 1600 Train: 0.00176 Test: 9.27091
Epoch: 1800 Train: 0.00017 Test: 1.77931
Epoch: 2000 Train: 0.00073 Test: 3.69896
Epoch: 2200 Train: 0.00031 Test: 2.29798
Epoch: 2400 Train: 0.00168 Test: 7.07191
Epoch: 2600 Train: 0.00065 Test: 2.61923
Epoch: 2800 Train: 0.00248 Test: 10.02235
Epoch: 3000 Train: 0.00061 Test: 2.89468
Epoch: 3200 Train: 0.00101 Test: 2.01840
Epoch: 3400 Train: 0.00046 Test: 1.78852
Epoch: 3600 Train: 0.00052 Test: 2.37177
Epoch: 3800 Train: 0.00023 Test: 1.76839
Epoch: 4000 Train: 0.00053 Test: 2.65645
Epoch: 4200 Train: 0.00013 Test: 1.51327
Epoch 4200: New minimal relative error: 1.78%, model saved.
Training Loss: tensor(0.)
Test Loss: tensor(2.0259e-34)
Learned LE: [-0.51301944 -0.52410185 -1.7610799 ]
True LE: [ 8.74935567e-01 -3.70403402e-03 -1.45460205e+01]
Relative Error: [11.080621   11.004966   10.891402   ...  0.56918675  0.6005131
  0.38512638]
