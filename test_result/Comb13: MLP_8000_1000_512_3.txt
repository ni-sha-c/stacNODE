time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 1000
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 512
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 99.46%, model saved.
Epoch: 0 Train: 3970.20435 Test: 4067.38525
Epoch 80: New minimal relative error: 49.06%, model saved.
Epoch: 80 Train: 88.14558 Test: 81.20139
Epoch: 160 Train: 48.26656 Test: 53.55924
Epoch 240: New minimal relative error: 27.58%, model saved.
Epoch: 240 Train: 4.87670 Test: 6.10861
Epoch 320: New minimal relative error: 18.15%, model saved.
Epoch: 320 Train: 3.17268 Test: 3.81408
Epoch: 400 Train: 30.08223 Test: 38.57967
Epoch: 480 Train: 1.71164 Test: 2.45734
Epoch: 560 Train: 1.52664 Test: 2.84380
Epoch 640: New minimal relative error: 9.31%, model saved.
Epoch: 640 Train: 1.08556 Test: 1.66987
Epoch: 720 Train: 1.04892 Test: 1.45349
Epoch: 800 Train: 0.75652 Test: 1.22283
Epoch: 880 Train: 0.67126 Test: 1.20180
Epoch: 960 Train: 0.87236 Test: 1.12798
Epoch: 1040 Train: 0.63461 Test: 2.31069
Epoch: 1120 Train: 0.44039 Test: 0.84313
Epoch: 1200 Train: 0.46506 Test: 0.88244
Epoch: 1280 Train: 0.38978 Test: 0.78968
Epoch: 1360 Train: 0.45828 Test: 0.80698
Epoch: 1440 Train: 0.43964 Test: 0.72916
Epoch: 1520 Train: 0.79224 Test: 2.29343
Epoch: 1600 Train: 0.30558 Test: 0.70782
Epoch 1680: New minimal relative error: 9.26%, model saved.
Epoch: 1680 Train: 0.34181 Test: 0.73925
Epoch: 1760 Train: 0.23244 Test: 0.61771
Epoch: 1840 Train: 0.24560 Test: 0.66496
Epoch: 1920 Train: 0.64855 Test: 0.79306
Epoch: 2000 Train: 1.51529 Test: 1.69079
Epoch: 2080 Train: 3.60063 Test: 3.84407
Epoch: 2160 Train: 0.18350 Test: 0.58582
Epoch: 2240 Train: 0.17617 Test: 0.54037
Epoch: 2320 Train: 0.27581 Test: 0.56112
Epoch: 2400 Train: 1.03864 Test: 1.61832
Epoch: 2480 Train: 0.30832 Test: 0.77555
Epoch: 2560 Train: 0.17989 Test: 0.52164
Epoch: 2640 Train: 1.29326 Test: 1.96996
Epoch: 2720 Train: 0.23699 Test: 0.61510
Epoch: 2800 Train: 0.39327 Test: 0.79975
Epoch: 2880 Train: 0.12687 Test: 0.49319
Epoch: 2960 Train: 0.25747 Test: 0.53985
Epoch: 3040 Train: 0.12167 Test: 0.49032
Epoch: 3120 Train: 1.09330 Test: 0.87879
Epoch: 3200 Train: 0.32109 Test: 0.73216
Epoch: 3280 Train: 0.12710 Test: 0.48522
Epoch: 3360 Train: 0.11283 Test: 0.47068
Epoch: 3440 Train: 0.12312 Test: 0.47355
Epoch: 3520 Train: 0.14908 Test: 0.48382
Epoch: 3600 Train: 0.61974 Test: 1.07881
Epoch: 3680 Train: 0.14656 Test: 0.55131
Epoch: 3760 Train: 0.24919 Test: 0.62067
Epoch: 3840 Train: 0.12644 Test: 0.48117
Epoch: 3920 Train: 0.09602 Test: 0.44221
Epoch: 4000 Train: 0.12151 Test: 0.46881
Epoch: 4080 Train: 0.35856 Test: 0.71704
Epoch: 4160 Train: 0.10859 Test: 0.44903
Epoch: 4240 Train: 0.18379 Test: 0.55220
Epoch: 4320 Train: 0.20096 Test: 0.50134
Epoch: 4400 Train: 0.09863 Test: 0.46373
Epoch: 4480 Train: 0.09765 Test: 0.45486
Epoch: 4560 Train: 0.18094 Test: 0.47811
Epoch: 4640 Train: 0.07610 Test: 0.42000
Epoch: 4720 Train: 0.08712 Test: 0.43124
Epoch: 4800 Train: 0.58560 Test: 1.04445
Epoch: 4880 Train: 0.07235 Test: 0.41527
Epoch 4960: New minimal relative error: 7.21%, model saved.
Epoch: 4960 Train: 0.13661 Test: 0.49645
Epoch: 5040 Train: 0.18042 Test: 0.52328
Epoch: 5120 Train: 0.14685 Test: 0.49963
Epoch: 5200 Train: 0.74246 Test: 1.09446
Epoch: 5280 Train: 0.07476 Test: 0.41639
Epoch: 5360 Train: 0.06519 Test: 0.40789
Epoch: 5440 Train: 0.06851 Test: 0.41215
Epoch: 5520 Train: 0.06587 Test: 0.41281
Epoch: 5600 Train: 0.06274 Test: 0.40855
Epoch: 5680 Train: 0.06638 Test: 0.41909
Epoch: 5760 Train: 0.06000 Test: 0.40610
Epoch: 5840 Train: 0.10486 Test: 0.44776
Epoch: 5920 Train: 0.05802 Test: 0.40566
Epoch: 6000 Train: 0.05773 Test: 0.40866
Epoch: 6080 Train: 0.06002 Test: 0.40976
Epoch: 6160 Train: 0.05561 Test: 0.40596
Epoch: 6240 Train: 0.09052 Test: 0.42096
Epoch: 6320 Train: 0.05391 Test: 0.40753
Epoch: 6400 Train: 0.05524 Test: 0.42107
Epoch: 6480 Train: 0.05237 Test: 0.40867
Epoch: 6560 Train: 0.05206 Test: 0.40947
Epoch: 6640 Train: 0.23953 Test: 0.61219
Epoch: 6720 Train: 0.20929 Test: 0.61405
Epoch: 6800 Train: 0.04978 Test: 0.40932
Epoch: 6880 Train: 0.05785 Test: 0.41877
Epoch: 6960 Train: 0.08057 Test: 0.44814
Epoch: 7040 Train: 0.12001 Test: 0.49031
Epoch: 7120 Train: 0.15544 Test: 0.54846
Epoch: 7200 Train: 0.04645 Test: 0.41223
Epoch: 7280 Train: 0.05177 Test: 0.41305
Epoch: 7360 Train: 0.04536 Test: 0.41440
Epoch: 7440 Train: 0.04580 Test: 0.41741
Epoch: 7520 Train: 0.04414 Test: 0.41831
Epoch: 7600 Train: 0.07306 Test: 0.42450
Epoch: 7680 Train: 0.04322 Test: 0.42129
Epoch: 7760 Train: 0.04257 Test: 0.42239
Epoch: 7840 Train: 0.04602 Test: 0.42627
Epoch: 7920 Train: 0.13726 Test: 0.53988
Epoch: 7999 Train: 0.04115 Test: 0.42631
Training Loss: tensor(0.0412)
Test Loss: tensor(0.4263)
Learned LE: [ 0.8875833   0.03274977 -5.1161513 ]
True LE: [ 8.6979783e-01  1.8873990e-03 -1.4541075e+01]
Relative Error: [7.5776157 7.614985  7.5401554 7.227757  6.6396976 5.8489633 4.9987597
 4.2435412 3.6869388 3.342041  3.1570077 3.0719688 3.0482917 3.0747716
 3.1630297 3.33485   3.6087687 3.992925  4.4773226 5.0040393 5.433797
 5.618864  5.575149  5.4592047 5.3745227 5.3309546 5.35566   5.5592847
 6.022774  6.539695  6.7810426 6.783892  6.78327   6.863324  6.968361
 7.0465736 7.1000896 7.1448603 7.1688323 7.132647  7.005147  6.8104224
 6.6324234 6.5374928 6.5091147 6.489911  6.4470463 6.382579  6.3166523
 6.2732315 6.268737  6.3039846 6.3694873 6.4614563 6.585548  6.740647
 6.8868794 6.9541326 6.944717  6.937728  6.964913  7.0193253 7.103131
 7.159939  7.047705  6.650661  5.9689384 5.108698  4.230737  3.4957886
 3.0053945 2.7511427 2.648491  2.6168265 2.6149344 2.640781  2.7164464
 2.8698854 3.120662  3.4766192 3.9392724 4.4816236 4.9830284 5.2445073
 5.212388  5.0584135 4.938575  4.877312  4.89274   5.104001  5.5807548
 6.036334  6.167132  6.1558514 6.253167  6.4494805 6.6268973 6.73062
 6.7808204 6.808772  6.811019  6.7492113 6.5921125 6.3736873 6.19231
 6.107159  6.0803432 6.049987  5.99121   5.908609  5.818931  5.746043
 5.7122264 5.7231607 5.768125  5.8405876 5.9475336 6.0925016 6.24162
 6.3199086 6.322436  6.3378124 6.4004965 6.4993753 6.6269093 6.693048
 6.535919  6.0616126 5.304065  4.3986306 3.520114  2.8340302 2.4398134
 2.2958066 2.2739022 2.279828  2.2827306 2.2947404 2.3455405 2.4672844
 2.6798534 2.9874725 3.398158  3.9174902 4.4694257 4.830627  4.843456
 4.659445  4.499398  4.4180384 4.420875  4.635782  5.1236043 5.5136237
 5.554548  5.5722    5.792721  6.1027617 6.3390903 6.4521775 6.4786024
 6.467711  6.430649  6.3328466 6.1406217 5.895288  5.7076097 5.6266723
 5.5966215 5.557779  5.4941    5.408259  5.30916   5.2181907 5.163197
 5.1572194 5.189186  5.246874  5.3370757 5.46822   5.6159863 5.702855
 5.710664  5.7386293 5.8309484 5.9718556 6.138477  6.2082505 6.0124135
 5.477297  4.663086  3.7368004 2.8865783 2.2780175 2.0051012 1.9754455
 2.013918  2.032836  2.0265648 2.0192337 2.0404353 2.1236196 2.2898269
 2.5369697 2.8726768 3.3281102 3.888132  4.3559856 4.4598217 4.2670245
 4.0606833 3.9529617 3.937295  4.147553  4.647813  4.9869127 4.9713025
 5.0491853 5.3974824 5.811505  6.0943356 6.201845  6.1844783 6.112546
 6.0194006 5.8775935 5.646472  5.369254  5.168649  5.0837374 5.044938
 5.000587  4.942701  4.8691263 4.779825  4.6908116 4.631246  4.620734
 4.649929  4.6989317 4.7722287 4.884848  5.0240703 5.116948  5.122962
 5.1480713 5.257834  5.4323134 5.6296725 5.7030873 5.486384  4.91177
 4.0609384 3.1401272 2.345306  1.8329391 1.6863102 1.7525878 1.8191758
 1.8272076 1.8041551 1.7802414 1.776221  1.8229043 1.9450305 2.133854
 2.3858337 2.7445138 3.2533624 3.8007135 4.045723  3.8877685 3.6330075
 3.4860487 3.4416187 3.630538  4.1469364 4.471096  4.4434485 4.5974545
 5.0630913 5.566039  5.8781824 5.963612  5.8879223 5.7421274 5.584056
 5.3935003 5.119421  4.8025537 4.5784307 4.479355  4.4257803 4.3759847
 4.329033  4.2796855 4.221876  4.163554  4.126403  4.1288056 4.165558
 4.2118597 4.2663894 4.3534007 4.4742775 4.570719  4.5735817 4.5792627
 4.688806  4.8827796 5.0990334 5.179288  4.9646945 4.37474   3.5110478
 2.6224866 1.9004663 1.4790124 1.4373395 1.5738964 1.6433179 1.6240064
 1.5810162 1.5461832 1.525449  1.5424231 1.6277205 1.7739443 1.9574484
 2.2071638 2.6070056 3.161051  3.5759158 3.5279024 3.2410934 3.0334854
 2.9429228 3.080224  3.608248  3.9711032 3.984838  4.22104   4.7739024
 5.3265247 5.6288285 5.67036   5.537809  5.333726  5.1298003 4.9041004
 4.5880365 4.220444  3.9591908 3.8364806 3.7616062 3.7005417 3.6593628
 3.63626   3.626458  3.630223  3.6499012 3.687899  3.7407439 3.7886996
 3.8227096 3.8743432 3.9644208 4.0583267 4.067126  4.0440516 4.134383
 4.333378  4.556632  4.643791  4.451575  3.8731415 3.0253541 2.1919477
 1.5422299 1.1815877 1.2090025 1.4016064 1.4653718 1.4088426 1.3427145
 1.3014195 1.2739933 1.2708439 1.3240558 1.43804   1.5863731 1.7539448
 2.0168815 2.480252  3.0222504 3.183607  2.9261577 2.6378748 2.474139
 2.511163 ]
