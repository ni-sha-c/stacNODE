time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 1000
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 512
n_layers: 5
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 99.88%, model saved.
Epoch: 0 Train: 4106.63037 Test: 4205.78760
Epoch: 80 Train: 52.56540 Test: 53.97298
Epoch 160: New minimal relative error: 56.41%, model saved.
Epoch: 160 Train: 16.41178 Test: 18.60468
Epoch: 240 Train: 6.78159 Test: 8.58050
Epoch 320: New minimal relative error: 46.02%, model saved.
Epoch: 320 Train: 4.12755 Test: 6.47637
Epoch 400: New minimal relative error: 40.87%, model saved.
Epoch: 400 Train: 6.55704 Test: 8.80248
Epoch 480: New minimal relative error: 21.73%, model saved.
Epoch: 480 Train: 2.10528 Test: 2.27441
Epoch 560: New minimal relative error: 20.78%, model saved.
Epoch: 560 Train: 1.83411 Test: 2.28646
Epoch: 640 Train: 4.56147 Test: 7.15757
Epoch: 720 Train: 11.47747 Test: 8.83614
Epoch: 800 Train: 2.34877 Test: 3.20687
Epoch: 880 Train: 0.73547 Test: 1.02994
Epoch: 960 Train: 2.00261 Test: 1.90029
Epoch: 1040 Train: 0.96965 Test: 1.21844
Epoch: 1120 Train: 0.73011 Test: 0.89684
Epoch: 1200 Train: 13.29996 Test: 15.20120
Epoch: 1280 Train: 15.09696 Test: 16.73398
Epoch: 1360 Train: 3.89110 Test: 5.18382
Epoch: 1440 Train: 7.00070 Test: 6.09085
Epoch: 1520 Train: 1.43876 Test: 1.09933
Epoch: 1600 Train: 1.15167 Test: 1.11082
Epoch: 1680 Train: 0.29472 Test: 0.51422
Epoch 1760: New minimal relative error: 17.35%, model saved.
Epoch: 1760 Train: 2.02613 Test: 1.79349
Epoch: 1840 Train: 0.99575 Test: 1.35132
Epoch: 1920 Train: 0.70794 Test: 0.63847
Epoch: 2000 Train: 0.91311 Test: 1.28604
Epoch: 2080 Train: 1.36098 Test: 1.45033
Epoch: 2160 Train: 3.15027 Test: 3.71602
Epoch: 2240 Train: 1.47985 Test: 1.55753
Epoch: 2320 Train: 0.31316 Test: 0.35230
Epoch: 2400 Train: 0.95053 Test: 0.95288
Epoch: 2480 Train: 0.26093 Test: 0.30820
Epoch: 2560 Train: 0.86945 Test: 1.26860
Epoch: 2640 Train: 0.96618 Test: 1.29216
Epoch: 2720 Train: 0.39141 Test: 0.40619
Epoch: 2800 Train: 0.14918 Test: 0.26710
Epoch: 2880 Train: 0.17087 Test: 0.33534
Epoch: 2960 Train: 0.72529 Test: 0.81584
Epoch: 3040 Train: 1.70174 Test: 1.26822
Epoch: 3120 Train: 0.56856 Test: 0.68893
Epoch: 3200 Train: 1.62891 Test: 1.92679
Epoch: 3280 Train: 1.28007 Test: 1.34630
Epoch: 3360 Train: 0.16822 Test: 0.24722
Epoch: 3440 Train: 0.10220 Test: 0.15347
Epoch 3520: New minimal relative error: 13.99%, model saved.
Epoch: 3520 Train: 0.50096 Test: 0.88566
Epoch: 3600 Train: 1.54416 Test: 1.45647
Epoch: 3680 Train: 0.22378 Test: 0.43594
Epoch: 3760 Train: 0.19167 Test: 0.32590
Epoch: 3840 Train: 0.30771 Test: 0.34064
Epoch: 3920 Train: 0.93804 Test: 1.21824
Epoch: 4000 Train: 1.17735 Test: 0.84352
Epoch: 4080 Train: 0.55276 Test: 0.62456
Epoch: 4160 Train: 0.29315 Test: 0.38883
Epoch: 4240 Train: 0.16049 Test: 0.19717
Epoch: 4320 Train: 0.28035 Test: 0.35519
Epoch: 4400 Train: 0.44156 Test: 0.40106
Epoch: 4480 Train: 0.25633 Test: 0.36483
Epoch: 4560 Train: 0.02897 Test: 0.10202
Epoch: 4640 Train: 0.23355 Test: 0.31903
Epoch: 4720 Train: 0.74941 Test: 0.84103
Epoch: 4800 Train: 0.29602 Test: 0.43303
Epoch: 4880 Train: 0.04502 Test: 0.10371
Epoch: 4960 Train: 0.28631 Test: 0.27309
Epoch: 5040 Train: 0.18735 Test: 0.20058
Epoch: 5120 Train: 0.24181 Test: 0.16862
Epoch: 5200 Train: 0.02919 Test: 0.09017
Epoch: 5280 Train: 0.09038 Test: 0.14930
Epoch: 5360 Train: 0.17534 Test: 0.23358
Epoch: 5440 Train: 0.11608 Test: 0.15772
Epoch: 5520 Train: 0.08174 Test: 0.10151
Epoch: 5600 Train: 0.09285 Test: 0.14329
Epoch: 5680 Train: 1.11673 Test: 1.23911
Epoch: 5760 Train: 0.54497 Test: 0.64818
Epoch: 5840 Train: 0.60356 Test: 0.84752
Epoch: 5920 Train: 0.02665 Test: 0.07993
Epoch: 6000 Train: 0.03386 Test: 0.09672
Epoch: 6080 Train: 0.02542 Test: 0.08466
Epoch: 6160 Train: 0.03254 Test: 0.09596
Epoch: 6240 Train: 0.02029 Test: 0.07340
Epoch: 6320 Train: 0.01904 Test: 0.07637
Epoch: 6400 Train: 0.31570 Test: 0.34003
Epoch: 6480 Train: 0.01638 Test: 0.06887
Epoch: 6560 Train: 0.01771 Test: 0.07737
Epoch: 6640 Train: 0.04374 Test: 0.09949
Epoch: 6720 Train: 0.01586 Test: 0.06972
Epoch: 6800 Train: 0.58437 Test: 0.80938
Epoch: 6880 Train: 0.11426 Test: 0.21210
Epoch: 6960 Train: 0.01513 Test: 0.06636
Epoch: 7040 Train: 0.08559 Test: 0.14449
Epoch: 7120 Train: 0.01425 Test: 0.06413
Epoch: 7200 Train: 0.05623 Test: 0.10695
Epoch: 7280 Train: 0.05712 Test: 0.13416
Epoch: 7360 Train: 0.15659 Test: 0.25720
Epoch: 7440 Train: 0.01405 Test: 0.06368
Epoch: 7520 Train: 0.01745 Test: 0.06695
Epoch: 7600 Train: 0.01688 Test: 0.09324
Epoch: 7680 Train: 0.01974 Test: 0.11326
Epoch: 7760 Train: 0.01282 Test: 0.06009
Epoch: 7840 Train: 0.20319 Test: 0.16832
Epoch: 7920 Train: 0.01248 Test: 0.05994
Epoch: 7999 Train: 0.02444 Test: 0.09586
Training Loss: tensor(0.0244)
Test Loss: tensor(0.0959)
Learned LE: [ 0.84357095  0.07424185 -4.706079  ]
True LE: [ 8.6456752e-01  5.0321105e-03 -1.4543223e+01]
Relative Error: [5.6914234 5.7673683 5.7439437 5.6151404 5.3913054 5.100709  4.7834954
 4.482394  4.2353077 4.0684657 3.985566  3.967771  3.9929092 4.0572114
 4.17455   4.355425  4.5912066 4.856675  5.123731  5.3708696 5.588868
 5.780237  5.953641  6.1152034 6.264036  6.3920965 6.4908066 6.5607452
 6.619601  6.6951365 6.8111315 6.9804044 7.209639  7.4951134 7.8139014
 8.126735  8.388178  8.561108  8.623884  8.565984  8.384616  8.08575
 7.685011  7.2046757 6.671206  6.11348   5.5627565 5.0507894 4.6054335
 4.2446113 3.9729395 3.7857223 3.676794  3.6444974 3.6916652 3.8204067
 4.0245047 4.286454  4.581645  4.8831806 5.1634083 5.394577  5.55081
 5.6111493 5.563309  5.4089065 5.1669664 4.8705535 4.5570097 4.261072
 4.014113  3.8401597 3.7422485 3.6999912 3.6935549 3.7288406 3.8319666
 4.0187855 4.276604  4.5725317 4.8715687 5.147233  5.38752   5.5954256
 5.7814026 5.951969  6.1045604 6.2282467 6.311251  6.3539634 6.3797317
 6.424443  6.5157824 6.667242  6.885248  7.16608   7.487153  7.8080797
 8.079133  8.257708  8.320925  8.26003   8.07438   7.770958  7.366576
 6.883467  6.3466935 5.7838697 5.2262726 4.707579  4.2574277 3.8928099
 3.6152642 3.419571  3.3045187 3.2749698 3.3383508 3.4970012 3.7401676
 4.0437503 4.3776875 4.711482  5.0144377 5.255505  5.4069104 5.4485164
 5.3739743 5.1952353 4.94133   4.6485286 4.348195  4.064364  3.8216994
 3.6431358 3.5310042 3.4627364 3.4208648 3.4222822 3.507605  3.6991217
 3.9793901 4.307375  4.640639  4.946774  5.2101784 5.433952  5.6307025
 5.8080063 5.961428  6.077474  6.142328  6.1558385 6.1459208 6.1581335
 6.224718  6.358217  6.564758  6.8416247 7.1688347 7.504878  7.7912664
 7.97756   8.042087  7.980127  7.79156   7.4841456 7.075622  6.5885544
 6.046754  5.4760704 4.9073114 4.3773217 3.9197416 3.5511107 3.2680671
 3.0626369 2.9382896 2.9091268 2.9882793 3.1771128 3.4584556 3.800603
 4.1690826 4.5314164 4.8546443 5.1041102 5.2488227 5.2691193 5.166315
 4.965018  4.7055874 4.4257936 4.1478424 3.8835988 3.6512632 3.4728956
 3.3498764 3.257095  3.1784112 3.1416233 3.2038643 3.3962142 3.6969635
 4.0567355 4.4253683 4.763364  5.050531  5.289657  5.4960237 5.678375
 5.830326  5.936536  5.98244   5.966552  5.9200025 5.8985095 5.94055
 6.056876  6.2518253 6.5246873 6.8611317 7.2175937 7.5217023 7.7159696
 7.784634  7.7263227 7.5382404 7.227593  6.814175  6.3229027 5.7759037
 5.195159  4.6102924 4.0619893 3.5911992 3.2171278 2.930944  2.7173266
 2.5818727 2.5501037 2.6431665 2.8602262 3.175433  3.5495558 3.9450884
 4.3299313 4.670258  4.9274473 5.0654097 5.063877  4.9320602 4.71015
 4.4508004 4.1918864 3.9443884 3.7075124 3.4927547 3.321288  3.1935182
 3.081752  2.9691036 2.891249  2.923035  3.1088965 3.4255188 3.8145905
 4.2180166 4.5882506 4.8988714 5.152541  5.3678675 5.5550356 5.7049885
 5.8008337 5.8287396 5.7860365 5.7038813 5.6485133 5.667154  5.7679906
 5.9506373 6.21817   6.5643153 6.941868  7.261773  7.4649444 7.544928
 7.4980526 7.314232  7.001016  6.583222  6.0889163 5.538517  4.9481654
 4.3435354 3.768906  3.2756984 2.8919501 2.6054382 2.3885038 2.2422414
 2.2038329 2.3065512 2.5464747 2.887457  3.2829158 3.6947398 4.0935674
 4.446543  4.711657  4.845848  4.824998  4.6653814 4.424122  4.1682415
 3.9353027 3.7243538 3.522341  3.3335295 3.1766706 3.0524676 2.9316156
 2.7932866 2.6749818 2.6681228 2.8375902 3.1626468 3.57632   4.01194
 4.4125385 4.744707  5.010856  5.2347484 5.428547  5.579466  5.666577
 5.6792083 5.614776  5.500023  5.4105563 5.407702  5.4959273 5.66584
 5.923698  6.275159  6.667666  6.9986677 7.214108  7.314494  7.2861085
 7.1104774 6.7975507 6.3790693 5.8862143 5.3372498 4.741123  4.116722
 3.5094981 2.9833    2.5812664 2.294602  2.0817287 1.9283841 1.8788232
 1.9834878 2.2369568 2.5910916 2.9936955 3.4080102 3.809554  4.1694036
 4.4435363 4.5806103 4.5479035 4.364338  4.1042166 3.8515847 3.645217
 3.473629  3.3125415 3.1578503 3.0241115 2.9129157 2.7955883 2.645683
 2.494028  2.4426563 2.5844266 2.9093568 3.3413563 3.8036108 4.230447
 4.5800295 4.8546333 5.0855236 5.289716  5.4486914 5.5332813 5.534592
 5.454714 ]
