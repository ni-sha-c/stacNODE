time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 500
loss_type: MSE
dyn_sys: lorenz
model_type: MLP
n_hidden: 1024
n_layers: 3
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 99.49%, model saved.
Epoch: 0 Train: 3867.82764 Test: 3902.20312
Epoch 80: New minimal relative error: 42.72%, model saved.
Epoch: 80 Train: 45.18711 Test: 52.00076
Epoch: 160 Train: 22.67044 Test: 31.90022
Epoch 240: New minimal relative error: 24.12%, model saved.
Epoch: 240 Train: 5.53378 Test: 8.38439
Epoch: 320 Train: 23.73665 Test: 34.83721
Epoch: 400 Train: 19.94838 Test: 19.61850
Epoch 480: New minimal relative error: 17.96%, model saved.
Epoch: 480 Train: 1.86335 Test: 4.47084
Epoch: 560 Train: 4.26647 Test: 16.74261
Epoch: 640 Train: 0.92754 Test: 2.44406
Epoch: 720 Train: 1.82634 Test: 3.32634
Epoch 800: New minimal relative error: 17.75%, model saved.
Epoch: 800 Train: 2.29293 Test: 3.49674
Epoch: 880 Train: 2.53408 Test: 3.45357
Epoch: 960 Train: 11.19177 Test: 10.86817
Epoch: 1040 Train: 4.79236 Test: 6.38371
Epoch: 1120 Train: 0.52122 Test: 1.62684
Epoch: 1200 Train: 0.61270 Test: 1.65795
Epoch: 1280 Train: 0.45073 Test: 1.43606
Epoch: 1360 Train: 0.57674 Test: 1.67020
Epoch: 1440 Train: 0.60779 Test: 1.70065
Epoch: 1520 Train: 4.49776 Test: 6.18251
Epoch: 1600 Train: 3.86951 Test: 3.17685
Epoch 1680: New minimal relative error: 13.60%, model saved.
Epoch: 1680 Train: 3.52205 Test: 3.54151
Epoch: 1760 Train: 2.68216 Test: 2.95652
Epoch: 1840 Train: 1.20406 Test: 1.81926
Epoch: 1920 Train: 0.65014 Test: 1.49303
Epoch: 2000 Train: 0.56618 Test: 1.47799
Epoch: 2080 Train: 0.25104 Test: 0.99856
Epoch: 2160 Train: 0.21433 Test: 1.03968
Epoch: 2240 Train: 0.24792 Test: 1.06401
Epoch: 2320 Train: 0.13372 Test: 0.96271
Epoch: 2400 Train: 0.13424 Test: 0.94249
Epoch: 2480 Train: 0.28416 Test: 1.14101
Epoch: 2560 Train: 0.39254 Test: 1.31234
Epoch: 2640 Train: 0.11263 Test: 0.98904
Epoch: 2720 Train: 0.15861 Test: 0.98539
Epoch: 2800 Train: 0.17746 Test: 0.96354
Epoch: 2880 Train: 0.10842 Test: 0.90948
Epoch: 2960 Train: 0.15440 Test: 0.94983
Epoch: 3040 Train: 0.23986 Test: 0.98999
Epoch: 3120 Train: 0.21037 Test: 1.06816
Epoch: 3200 Train: 0.09192 Test: 0.90440
Epoch 3280: New minimal relative error: 10.07%, model saved.
Epoch: 3280 Train: 0.25773 Test: 1.05346
Epoch: 3360 Train: 0.14479 Test: 1.05457
Epoch: 3440 Train: 0.19373 Test: 1.14384
Epoch: 3520 Train: 0.25236 Test: 1.17825
Epoch: 3600 Train: 0.44031 Test: 1.38071
Epoch: 3680 Train: 0.07344 Test: 0.86885
Epoch: 3760 Train: 0.07334 Test: 0.86286
Epoch: 3840 Train: 0.07161 Test: 0.88005
Epoch: 3920 Train: 0.06113 Test: 0.85017
Epoch: 4000 Train: 0.11119 Test: 0.88501
Epoch: 4080 Train: 2.35722 Test: 2.58907
Epoch: 4160 Train: 0.09363 Test: 0.91031
Epoch: 4240 Train: 0.05960 Test: 0.84339
Epoch: 4320 Train: 0.61426 Test: 1.24596
Epoch: 4400 Train: 0.05336 Test: 0.83264
Epoch: 4480 Train: 0.05656 Test: 0.82885
Epoch: 4560 Train: 0.06196 Test: 0.85541
Epoch: 4640 Train: 0.05015 Test: 0.82589
Epoch: 4720 Train: 0.09106 Test: 0.85410
Epoch: 4800 Train: 0.04864 Test: 0.82848
Epoch: 4880 Train: 0.06199 Test: 0.89213
Epoch: 4960 Train: 0.05375 Test: 0.82630
Epoch: 5040 Train: 0.05171 Test: 0.82503
Epoch: 5120 Train: 0.18324 Test: 0.98516
Epoch: 5200 Train: 0.04483 Test: 0.81715
Epoch: 5280 Train: 0.18823 Test: 1.09394
Epoch: 5360 Train: 0.04368 Test: 0.81298
Epoch: 5440 Train: 0.04833 Test: 0.82009
Epoch: 5520 Train: 0.84499 Test: 1.35458
Epoch: 5600 Train: 0.04075 Test: 0.82155
Epoch: 5680 Train: 0.05187 Test: 0.84128
Epoch: 5760 Train: 0.18056 Test: 0.94413
Epoch: 5840 Train: 0.03866 Test: 0.82347
Epoch: 5920 Train: 0.39956 Test: 1.26043
Epoch: 6000 Train: 0.03767 Test: 0.81967
Epoch: 6080 Train: 0.29116 Test: 1.08016
Epoch: 6160 Train: 0.14929 Test: 0.99228
Epoch: 6240 Train: 0.03637 Test: 0.81991
Epoch: 6320 Train: 0.05596 Test: 0.87655
Epoch: 6400 Train: 0.03490 Test: 0.81544
Epoch: 6480 Train: 0.08859 Test: 0.83630
Epoch: 6560 Train: 0.03398 Test: 0.81221
Epoch: 6640 Train: 0.04218 Test: 0.82046
Epoch: 6720 Train: 0.06004 Test: 0.85662
Epoch: 6800 Train: 0.03253 Test: 0.80996
Epoch: 6880 Train: 0.37003 Test: 1.10934
Epoch: 6960 Train: 0.03174 Test: 0.80843
Epoch: 7040 Train: 0.07177 Test: 0.81743
Epoch: 7120 Train: 0.03099 Test: 0.80516
Epoch: 7200 Train: 0.03158 Test: 0.81168
Epoch: 7280 Train: 0.03007 Test: 0.80393
Epoch: 7360 Train: 0.04572 Test: 0.86147
Epoch: 7440 Train: 0.02946 Test: 0.80374
Epoch: 7520 Train: 0.21883 Test: 0.92265
Epoch: 7600 Train: 0.02872 Test: 0.80027
Epoch: 7680 Train: 0.06460 Test: 0.80753
Epoch: 7760 Train: 0.02812 Test: 0.80183
Epoch: 7840 Train: 0.02768 Test: 0.79921
Epoch: 7920 Train: 0.02884 Test: 0.80138
Epoch: 7999 Train: 0.02815 Test: 0.80372
Training Loss: tensor(0.0282)
Test Loss: tensor(0.8037)
Learned LE: [ 0.8508111  -0.02743281 -5.1976414 ]
True LE: [  0.8511634    0.01776594 -14.549056  ]
Relative Error: [3.9991062  4.116169   4.246531   4.418439   4.644332   4.9242096
 5.2563295  5.6384583  6.066344   6.5086493  6.851819   6.929089
 6.7148156  6.323989   5.8417983  5.2452493  4.5156813  3.6808062
 2.808092   2.045603   1.975284   2.7780402  3.5332837  3.9990404
 4.447032   4.8004723  4.885925   4.696871   4.36136    4.0268583
 3.7958004  3.56524    3.2915413  3.1406636  2.988823   2.9223447
 2.9345913  2.8610048  2.6197865  2.1822398  1.8473694  1.8087864
 1.9038453  1.7910033  1.8027788  2.0262578  2.0023983  1.9479331
 1.8714617  1.8308693  1.77728    1.8322802  2.083494   2.3330326
 2.4667485  2.577466   2.6884272  2.763866   2.8319764  2.9547164
 3.0837684  3.1917458  3.317945   3.4328923  3.539408   3.6634467
 3.8062148  3.9531286  4.1259394  4.3753376  4.716341   5.129326
 5.58663    5.9847326  6.150803   6.044771   5.7651987  5.385606
 4.8622675  4.151652   3.2710094  2.3147662  1.571333   1.7557329
 2.6749496  3.4604568  4.0085225  4.4835134  4.832498   4.890931
 4.6397047  4.2024894  3.774672   3.4519956  3.0647125  2.7041352
 2.621715   2.5750453  2.5049987  2.5158656  2.463112   2.4168384
 2.111451   1.7176058  1.6471941  1.7439976  1.6266776  1.6457866
 1.862757   1.8015885  1.7310498  1.6769195  1.6274942  1.5666614
 1.6360979  1.8898362  2.0336556  2.0433805  2.124436   2.2347715
 2.295493   2.3566291  2.4578767  2.5283294  2.6120849  2.7352576
 2.846559   2.9507205  3.0567665  3.1407676  3.1884656  3.2554085
 3.4160542  3.6917377  4.0505404  4.4649677  4.884752   5.168345
 5.219556   5.0865335  4.8423295  4.4438763  3.833362   3.0098188
 2.0186584  1.2360629  1.527031   2.3572474  3.2181807  4.010265
 4.489024   4.7531247  4.8460608  4.614068   4.118845   3.661267
 3.3473763  2.8824072  2.3326027  2.119235   2.0620415  2.0604486
 1.9895464  2.0082786  2.0362408  2.0185049  1.6301396  1.4011569
 1.4748847  1.4757677  1.410504   1.6352829  1.5715871  1.4911306
 1.4346757  1.4188262  1.3875089  1.4739562  1.6543802  1.7257574
 1.619481   1.6419183  1.7681056  1.8319176  1.8914204  1.9843016
 2.0219874  2.0686781  2.1771486  2.279215   2.3607543  2.432271
 2.4631631  2.4498813  2.4509304  2.5092258  2.646585   2.871935
 3.1732726  3.5324383  3.8913357  4.128464   4.188096   4.106768
 3.8703547  3.4167318  2.7624195  1.9191898  1.067979   1.227081
 1.9592794  2.7317603  3.7107513  4.359922   4.375096   4.4809732
 4.4231677  3.9571009  3.40311    3.081496   2.7683659  2.2793689
 1.9212537  1.6225748  1.5418718  1.4937431  1.4214511  1.5443728
 1.5220941  1.4930246  1.143763   1.0134072  1.2248876  1.1537305
 1.2542232  1.3273371  1.2329972  1.1854663  1.2073139  1.1649494
 1.2966926  1.4330168  1.4472616  1.2862409  1.2124914  1.3452107
 1.4167163  1.4442416  1.5201459  1.5685952  1.5740931  1.6551836
 1.7655948  1.8290758  1.856932   1.8483123  1.8188311  1.8141574
 1.8178716  1.8206948  1.8580941  1.9714217  2.1904628  2.483488
 2.7891543  3.0244496  3.12498    3.0715327  2.8166797  2.360075
 1.7570647  1.0261884  0.82588196 1.4720294  2.179509   2.8796363
 3.6182072  3.8794854  3.790056   3.896082   3.7527184  3.259425
 2.896006   2.6693678  2.1990716  1.6933279  1.5113642  1.2518259
 1.0294952  0.9178914  0.9335243  1.016824   0.9687569  0.93783754
 0.6006327  0.49227494 0.8499447  0.83713883 1.0108416  1.0112368
 0.9843479  1.0318818  1.0930047  1.0620044  1.2300793  1.276469
 1.1145849  0.9242014  0.92787987 1.0864253  1.1035734  1.1259594
 1.1769953  1.169704   1.1677854  1.2448187  1.3293675  1.3654227
 1.3736058  1.346905   1.3457134  1.3670605  1.3578131  1.3239139
 1.3037199  1.3179351  1.4369818  1.6396712  1.8364415  1.9858537
 2.0416133  1.9695475  1.7209355  1.3011426  0.8217399  0.49837545
 1.0520233  1.64879    2.0551362  2.417448   2.9483192  3.2642574
 3.2970586  3.1458604  2.9554086  2.4665008  2.04766    1.9194709
 1.7325029  1.5021067  1.3255458  0.92995775 0.61491567 0.6468357
 0.6089918  0.6058181  0.6824148  0.7479305  0.66370815 0.62427664
 0.75489867 0.90839213 0.9998335  0.9787656  0.93042505 1.0951327
 1.1325207  1.153393   1.1367128  1.1819991  0.9638776  0.8967696
 0.8509745  0.96080077 0.9487641  0.93803525 0.9679444  0.9393967
 0.9136566  0.93562984 0.9375819  0.9451618  0.9577437  0.95699096
 1.0088319  1.05813    1.0662762  1.0619309  1.0555831  1.0516287
 1.0935221  1.191518   1.2766811  1.2803077  1.1861509  1.0314556
 0.8681496  0.6893225  0.39551938 0.54224676]
