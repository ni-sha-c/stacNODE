time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 3000
num_train: 1000
num_test: 1000
num_val: 0
num_trans: 0
loss_type: Jacobian
dyn_sys: baker
model_type: MLP_skip
s: 0.2
n_hidden: 256
n_layers: 1
reg_param: 300.0
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 27.313282013 Test: 23.739929199
Epoch 0: New minimal relative error: 23.74%, model saved.
Epoch: 30 Train: 4.732571602 Test: 4.632316589
Epoch 30: New minimal relative error: 4.63%, model saved.
Epoch: 60 Train: 4.032337666 Test: 4.096462250
Epoch 60: New minimal relative error: 4.10%, model saved.
Epoch: 90 Train: 3.943991661 Test: 4.019130707
Epoch 90: New minimal relative error: 4.02%, model saved.
Epoch: 120 Train: 3.926495314 Test: 4.016305923
Epoch 120: New minimal relative error: 4.02%, model saved.
Epoch: 150 Train: 3.928289890 Test: 4.024878025
Epoch: 180 Train: 3.928625584 Test: 4.028988838
Epoch: 210 Train: 3.929063320 Test: 4.031661987
Epoch: 240 Train: 3.922750473 Test: 4.026575089
Epoch: 270 Train: 3.931101799 Test: 4.033384800
Epoch: 300 Train: 3.929241180 Test: 4.024042606
Epoch: 330 Train: 3.915637016 Test: 4.007056236
Epoch 330: New minimal relative error: 4.01%, model saved.
Epoch: 360 Train: 3.909624100 Test: 4.005205631
Epoch 360: New minimal relative error: 4.01%, model saved.
Epoch: 390 Train: 3.907754898 Test: 4.001495361
Epoch 390: New minimal relative error: 4.00%, model saved.
Epoch: 420 Train: 3.910304546 Test: 4.003909588
Epoch: 450 Train: 3.915336609 Test: 4.009523392
Epoch: 480 Train: 3.917231560 Test: 4.011502266
Epoch: 510 Train: 3.920131207 Test: 4.014401913
Epoch: 540 Train: 3.924349308 Test: 4.014916420
Epoch: 570 Train: 3.924138546 Test: 4.017954350
Epoch: 600 Train: 3.923043966 Test: 4.018685818
Epoch: 630 Train: 3.925544739 Test: 4.023449421
Epoch: 660 Train: 3.930685997 Test: 4.025245667
Epoch: 690 Train: 3.934245110 Test: 4.028674126
Epoch: 720 Train: 3.938984871 Test: 4.032574654
Epoch: 750 Train: 3.938184261 Test: 4.034715652
Epoch: 780 Train: 3.935319901 Test: 4.031835556
Epoch: 810 Train: 3.933053493 Test: 4.027212143
Epoch: 840 Train: 3.930850983 Test: 4.022285461
Epoch: 870 Train: 3.931429863 Test: 4.022274971
Epoch: 900 Train: 3.932509899 Test: 4.024592876
Epoch: 930 Train: 3.933045149 Test: 4.026524544
Epoch: 960 Train: 3.930777550 Test: 4.027648926
Epoch: 990 Train: 3.934095860 Test: 4.030051231
Epoch: 1020 Train: 3.937654018 Test: 4.033130646
Epoch: 1050 Train: 3.946169376 Test: 4.038251877
Epoch: 1080 Train: 3.948554516 Test: 4.041004658
Epoch: 1110 Train: 3.953211308 Test: 4.045142174
Epoch: 1140 Train: 3.956511974 Test: 4.048251629
Epoch: 1170 Train: 3.958530188 Test: 4.050415993
Epoch: 1200 Train: 3.951122999 Test: 4.045921803
Epoch: 1230 Train: 3.955256462 Test: 4.048688889
Epoch: 1260 Train: 3.956041098 Test: 4.048704147
Epoch: 1290 Train: 3.956536770 Test: 4.050440311
Epoch: 1320 Train: 3.959418774 Test: 4.050240040
Epoch: 1350 Train: 3.961209774 Test: 4.050945282
Epoch: 1380 Train: 3.962226391 Test: 4.053754807
Epoch: 1410 Train: 3.964773893 Test: 4.055608749
Epoch: 1440 Train: 3.967384338 Test: 4.056483269
Epoch: 1470 Train: 3.968832970 Test: 4.057480335
Epoch: 1500 Train: 3.969202757 Test: 4.055109978
Epoch: 1530 Train: 3.966956139 Test: 4.051054955
Epoch: 1560 Train: 3.964166164 Test: 4.048858643
Epoch: 1590 Train: 3.962139606 Test: 4.045612335
Epoch: 1620 Train: 3.959895134 Test: 4.040747643
Epoch: 1650 Train: 3.959243298 Test: 4.039096832
Epoch: 1680 Train: 3.957583189 Test: 4.039152145
Epoch: 1710 Train: 3.953917027 Test: 4.039957047
Epoch: 1740 Train: 3.956426620 Test: 4.040536880
Epoch: 1770 Train: 3.956541061 Test: 4.042166233
Epoch: 1800 Train: 3.959614277 Test: 4.047816277
Epoch: 1830 Train: 3.964247704 Test: 4.053664207
Epoch: 1860 Train: 3.966676235 Test: 4.057536125
Epoch: 1890 Train: 3.964525700 Test: 4.056835175
Epoch: 1920 Train: 3.959470272 Test: 4.049670696
Epoch: 1950 Train: 3.956612110 Test: 4.046498775
Epoch: 1980 Train: 3.956896544 Test: 4.048362732
Epoch: 2010 Train: 3.958218575 Test: 4.050254822
Epoch: 2040 Train: 3.960806608 Test: 4.051640034
Epoch: 2070 Train: 3.962052345 Test: 4.053758144
Epoch: 2100 Train: 3.963557720 Test: 4.054588318
Epoch: 2130 Train: 3.964467049 Test: 4.054364204
Epoch: 2160 Train: 3.965149879 Test: 4.054718494
Epoch: 2190 Train: 3.963703632 Test: 4.053270817
Epoch: 2220 Train: 3.962860346 Test: 4.051433563
Epoch: 2250 Train: 3.963048935 Test: 4.051279545
Epoch: 2280 Train: 3.962442875 Test: 4.050509930
Epoch: 2310 Train: 3.961691618 Test: 4.049850464
Epoch: 2340 Train: 3.961199760 Test: 4.050696373
Epoch: 2370 Train: 3.961028576 Test: 4.050632477
Epoch: 2400 Train: 3.961649179 Test: 4.051602364
Epoch: 2430 Train: 3.961788654 Test: 4.051117420
Epoch: 2460 Train: 3.960811615 Test: 4.049983025
Epoch: 2490 Train: 3.960254669 Test: 4.049723148
Epoch: 2520 Train: 3.959971428 Test: 4.048801422
Epoch: 2550 Train: 3.960489273 Test: 4.048648834
Epoch: 2580 Train: 3.961138010 Test: 4.048155785
Epoch: 2610 Train: 3.961326122 Test: 4.048238754
Epoch: 2640 Train: 3.962180138 Test: 4.047886848
Epoch: 2670 Train: 3.962320805 Test: 4.048995972
Epoch: 2700 Train: 3.963155508 Test: 4.049473763
Epoch: 2730 Train: 3.963639736 Test: 4.049849033
Epoch: 2760 Train: 3.964711189 Test: 4.049425125
Epoch: 2790 Train: 3.965909719 Test: 4.050951004
Epoch: 2820 Train: 3.965541363 Test: 4.051784039
Epoch: 2850 Train: 3.965808153 Test: 4.051789284
Epoch: 2880 Train: 3.966064930 Test: 4.050802231
Epoch: 2910 Train: 3.965891838 Test: 4.050841331
Epoch: 2940 Train: 3.967162371 Test: 4.051788330
Epoch: 2970 Train: 3.966825247 Test: 4.052435398
Epoch: 2999 Train: 3.967318535 Test: 4.052637100
Training Loss: tensor(3.9673)
Test Loss: tensor(4.0526)
True Mean x: tensor(3.3019, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(3.4041, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(3.3662, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(0.0045, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(0.0067)
Jacobian term Test Loss: tensor(0.0068)
Learned LE: [0.5237999  0.51632416]
True LE: tensor([ 0.6932, -0.7017], dtype=torch.float64)
