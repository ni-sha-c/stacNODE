time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 10000
num_test: 6000
num_trans: 0
loss_type: MSE
dyn_sys: lorenz
model_type: MLP_skip
n_hidden: 1024
n_layers: 5
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 105.73%, model saved.
Epoch: 0 Train: 3663.87964 Test: 3999.34473
Epoch 100: New minimal relative error: 43.66%, model saved.
Epoch: 100 Train: 56.09402 Test: 52.17017
Epoch 200: New minimal relative error: 10.89%, model saved.
Epoch: 200 Train: 21.82479 Test: 12.39462
Epoch: 300 Train: 7.58851 Test: 10.13484
Epoch: 400 Train: 16.79009 Test: 19.07868
Epoch: 500 Train: 9.49619 Test: 10.18836
Epoch 600: New minimal relative error: 10.87%, model saved.
Epoch: 600 Train: 4.01629 Test: 6.17292
Epoch: 700 Train: 1.98693 Test: 0.90250
Epoch: 800 Train: 5.91105 Test: 7.35796
Epoch 900: New minimal relative error: 5.56%, model saved.
Epoch: 900 Train: 0.44399 Test: 0.60293
Epoch: 1000 Train: 0.51460 Test: 0.49186
Epoch: 1100 Train: 13.61051 Test: 8.27439
Epoch: 1200 Train: 13.57316 Test: 18.48032
Epoch 1300: New minimal relative error: 5.00%, model saved.
Epoch: 1300 Train: 1.56625 Test: 0.75623
Epoch: 1400 Train: 1.01194 Test: 0.63979
Epoch: 1500 Train: 2.12534 Test: 2.78157
Epoch: 1600 Train: 4.51470 Test: 5.49989
Epoch: 1700 Train: 7.27943 Test: 10.64804
Epoch: 1800 Train: 6.34462 Test: 6.58210
Epoch: 1900 Train: 3.43917 Test: 4.71424
Epoch: 2000 Train: 0.44966 Test: 0.51655
Epoch: 2100 Train: 4.37814 Test: 6.69704
Epoch: 2200 Train: 1.37447 Test: 1.19830
Epoch: 2300 Train: 1.37496 Test: 1.34781
Epoch: 2400 Train: 1.19072 Test: 1.99405
Epoch: 2500 Train: 7.15881 Test: 5.86488
Epoch: 2600 Train: 0.91791 Test: 1.31633
Epoch: 2700 Train: 1.75643 Test: 2.32409
Epoch: 2800 Train: 0.79785 Test: 1.07215
Epoch: 2900 Train: 1.22893 Test: 1.24587
Epoch: 3000 Train: 0.67490 Test: 0.68010
Epoch: 3100 Train: 5.99898 Test: 4.37294
Epoch: 3200 Train: 4.60227 Test: 7.64349
Epoch: 3300 Train: 0.28028 Test: 0.32512
Epoch: 3400 Train: 0.83032 Test: 1.33831
Epoch: 3500 Train: 0.79896 Test: 0.57415
Epoch: 3600 Train: 1.91822 Test: 1.26236
Epoch: 3700 Train: 1.45706 Test: 2.06936
Epoch: 3800 Train: 2.37247 Test: 2.34637
Epoch: 3900 Train: 1.00706 Test: 1.31257
Epoch: 4000 Train: 2.91660 Test: 2.28831
Epoch: 4100 Train: 1.34401 Test: 1.69630
Epoch: 4200 Train: 2.69181 Test: 1.65721
Epoch: 4300 Train: 0.13488 Test: 0.20919
Epoch: 4400 Train: 1.21080 Test: 1.61209
Epoch: 4500 Train: 0.16643 Test: 0.20027
Epoch: 4600 Train: 2.09737 Test: 1.82081
Epoch: 4700 Train: 0.52337 Test: 1.16718
Epoch: 4800 Train: 2.65436 Test: 1.37009
Epoch 4900: New minimal relative error: 2.15%, model saved.
Epoch: 4900 Train: 0.23577 Test: 0.20543
Epoch: 5000 Train: 0.29368 Test: 0.43312
Epoch: 5100 Train: 3.23320 Test: 3.85987
Epoch: 5200 Train: 0.22513 Test: 0.35646
Epoch: 5300 Train: 0.17444 Test: 0.20086
Epoch: 5400 Train: 0.20787 Test: 0.19142
Epoch: 5500 Train: 1.29858 Test: 1.56832
Epoch: 5600 Train: 0.14474 Test: 0.19817
Epoch: 5700 Train: 0.12858 Test: 0.21679
Epoch: 5800 Train: 0.52072 Test: 0.45485
Epoch: 5900 Train: 0.63099 Test: 0.63622
Epoch: 6000 Train: 0.33876 Test: 0.33210
Epoch: 6100 Train: 0.18543 Test: 0.26447
Epoch: 6200 Train: 0.59608 Test: 0.44729
Epoch: 6300 Train: 0.47680 Test: 0.42085
Epoch: 6400 Train: 0.18057 Test: 0.20644
Epoch: 6500 Train: 0.08896 Test: 0.12997
Epoch: 6600 Train: 0.70731 Test: 0.74948
Epoch: 6700 Train: 1.03579 Test: 1.23136
Epoch 6800: New minimal relative error: 1.42%, model saved.
Epoch: 6800 Train: 0.13956 Test: 0.22063
Epoch: 6900 Train: 0.14394 Test: 0.21175
Epoch: 7000 Train: 0.39407 Test: 0.48342
Epoch: 7100 Train: 0.04398 Test: 0.07204
Epoch: 7200 Train: 0.05202 Test: 0.07507
Epoch: 7300 Train: 0.05964 Test: 0.08291
Epoch: 7400 Train: 0.90681 Test: 1.13755
Epoch: 7500 Train: 0.04123 Test: 0.07198
Epoch: 7600 Train: 0.11332 Test: 0.12749
Epoch: 7700 Train: 1.38593 Test: 1.38803
Epoch: 7800 Train: 0.04126 Test: 0.04977
Epoch: 7900 Train: 0.23930 Test: 0.28266
Epoch: 8000 Train: 0.04600 Test: 0.06296
Epoch: 8100 Train: 0.04395 Test: 0.09012
Epoch: 8200 Train: 0.42756 Test: 0.43042
Epoch: 8300 Train: 0.06054 Test: 0.07022
Epoch: 8400 Train: 0.04978 Test: 0.06002
Epoch: 8500 Train: 0.11977 Test: 0.16633
Epoch: 8600 Train: 0.10267 Test: 0.23896
Epoch: 8700 Train: 0.06087 Test: 0.07672
Epoch: 8800 Train: 0.04753 Test: 0.06151
Epoch: 8900 Train: 0.18847 Test: 0.23983
Epoch: 9000 Train: 0.12119 Test: 0.12915
Epoch: 9100 Train: 0.04022 Test: 0.05719
Epoch: 9200 Train: 0.61964 Test: 0.47463
Epoch: 9300 Train: 0.20109 Test: 0.17636
Epoch: 9400 Train: 0.08388 Test: 0.16034
Epoch: 9500 Train: 0.20460 Test: 0.21292
Epoch 9600: New minimal relative error: 1.02%, model saved.
Epoch: 9600 Train: 0.02032 Test: 0.03628
Epoch: 9700 Train: 0.04330 Test: 0.05815
Epoch: 9800 Train: 0.03782 Test: 0.05007
Epoch: 9900 Train: 0.38479 Test: 0.29929
Epoch: 9999 Train: 0.07325 Test: 0.10764
Training Loss: tensor(0.0733)
Test Loss: tensor(0.1076)
Learned LE: [ 8.9460558e-01  1.8041759e-03 -4.5211987e+00]
True LE: [ 8.7579507e-01  1.3705705e-03 -1.4550784e+01]
Relative Error: [22.710934 23.450304 24.852055 26.49736  28.407495 30.535156 32.551018
 34.65791  36.97364  39.087242 41.009556 42.712826 44.10063  45.105995
 45.738922 45.209324 43.93714  42.544804 40.83346  39.200752 37.628407
 36.836964 36.211678 35.95499  35.670048 35.04655  34.325043 33.84813
 33.512074 33.323704 33.142166 33.254173 33.34441  33.648647 34.03543
 34.66247  35.47743  36.078217 36.225414 36.11409  35.948273 35.210056
 34.1313   32.86841  31.666946 30.706327 29.638773 28.540558 27.20562
 26.194616 24.928524 24.131989 23.405136 22.478436 21.714043 21.014973
 20.53184  20.21875  20.110092 19.893131 19.90897  20.140827 20.535126
 20.919844 22.22137  23.87599  25.860373 27.868227 29.906569 32.003704
 34.218388 36.261467 38.091778 39.72678  40.97323  41.8403   42.250072
 41.427742 40.133865 38.554424 37.129368 35.356575 33.94842  33.17212
 32.691715 32.52135  32.274338 31.733135 31.119442 30.791536 30.540937
 30.451859 30.388763 30.566803 30.7931   31.12909  31.419954 31.93213
 32.749634 33.40706  33.46535  33.199806 32.89677  32.11665  30.986177
 29.79118  28.878286 28.052488 27.08708  26.001343 24.732824 23.87453
 23.052498 22.395096 21.558647 20.71261  19.917627 19.279251 18.767483
 18.348179 18.04257  17.836502 17.872541 18.079556 18.380344 18.745657
 19.752075 21.39474  23.37636  25.314383 27.299854 29.329071 31.552387
 33.50703  35.244835 36.821507 37.899715 38.638382 38.91124  37.86969
 36.501442 34.88818  33.47736  31.674778 30.499475 29.702404 29.267525
 29.181082 28.945082 28.445646 27.958307 27.783752 27.631903 27.737913
 27.800087 28.069422 28.399092 28.693459 28.960382 29.385572 30.092632
 30.743269 30.813507 30.390305 29.874176 29.070986 28.173473 26.785988
 25.981346 25.419409 24.67526  23.649866 22.576319 21.934395 21.448547
 20.708237 19.870537 19.067383 18.247656 17.678215 17.15657  16.557938
 16.121273 15.996079 15.994091 16.10347  16.3542   16.738634 17.48203
 19.03147  20.936832 22.801905 24.726341 26.797375 28.871695 30.715525
 32.364952 33.838245 34.761806 35.550797 35.57597  34.48167  33.11241
 31.64229  29.930798 28.411425 27.502228 26.563221 26.128887 25.836342
 25.589031 25.188934 24.93865  24.817413 24.774042 25.098423 25.304838
 25.64623  26.127512 26.407337 26.62459  26.82466  27.503555 28.142742
 28.254196 27.715557 27.005741 26.223114 25.369173 24.16451  23.274681
 22.97653  22.363081 21.560318 20.66802  20.292038 19.867407 19.09991
 18.318363 17.409521 16.685299 16.16605  15.564161 14.892481 14.328955
 14.242165 14.271318 14.300436 14.573269 14.898118 15.437889 16.844864
 18.533447 20.377281 22.226175 24.151546 26.055225 27.939236 29.536692
 30.959719 31.740643 32.467396 32.329147 31.215706 29.860947 28.782957
 27.353567 26.062265 25.056452 24.286036 23.750267 23.191347 22.59271
 21.835264 21.582499 21.494892 21.733027 22.384565 22.841423 23.40465
 23.865103 24.210737 24.426779 24.490679 25.02931  25.548595 25.706964
 25.010876 24.207035 23.488949 22.612432 21.421175 20.77541  20.677864
 20.288794 19.660257 18.981304 18.735338 18.335924 17.569733 16.854156
 15.881996 15.247367 14.599789 14.060942 13.32575  12.784079 12.576599
 12.700783 12.736834 12.994149 13.329238 13.687581 14.907349 16.340614
 17.999485 19.69218  21.344717 23.28151  25.191238 26.851696 28.180489
 28.92096  29.50714  29.353691 28.091473 27.449509 26.443487 24.99922
 23.753119 22.800474 21.859753 21.254576 20.630117 20.004946 19.12096
 18.173603 18.10049  18.53296  19.40602  20.230497 21.117474 21.671217
 22.083612 22.433004 22.495102 22.540518 22.834976 23.068682 22.550388
 21.719355 20.98773  20.002314 18.848246 18.229809 18.399605 18.396463
 17.842554 17.376759 17.19992  16.793259 16.10497  15.413022 14.548331
 13.819216 13.139717 12.576207 11.815857 11.355807 11.182455 11.261588
 11.311649 11.580554 11.845767 12.235736 13.031233 14.196014 15.618783
 17.132141 18.631231 20.437014 22.446594 24.119572 25.486528 26.2786
 26.764425 26.597876 25.74065  25.299517 24.25745  22.842543 21.598618
 20.491823 19.553059 18.900549 18.074331 17.332    16.577896 15.530796
 14.805295]
