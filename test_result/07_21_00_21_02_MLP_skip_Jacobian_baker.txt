time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 5000
num_test: 5000
num_val: 0
num_trans: 0
loss_type: Jacobian
dyn_sys: baker
model_type: MLP_skip
s: 0.2
n_hidden: 128
n_layers: 4
reg_param: 500
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 11.449556351 Test: 10.512472153
Epoch 0: New minimal relative error: 10.51%, model saved.
Epoch: 100 Train: 3.341612339 Test: 3.390998602
Epoch 100: New minimal relative error: 3.39%, model saved.
Epoch: 200 Train: 3.062427521 Test: 3.142575264
Epoch 200: New minimal relative error: 3.14%, model saved.
Epoch: 300 Train: 2.989192247 Test: 3.055844784
Epoch 300: New minimal relative error: 3.06%, model saved.
Epoch: 400 Train: 3.091484070 Test: 3.154236317
Epoch: 500 Train: 3.113561630 Test: 3.148865700
Epoch: 600 Train: 3.063215733 Test: 3.116409779
Epoch: 700 Train: 3.103486300 Test: 3.160801411
Epoch: 800 Train: 3.120359421 Test: 3.176582336
Epoch: 900 Train: 3.034915924 Test: 3.082796812
Epoch: 1000 Train: 3.032555103 Test: 3.092350483
Epoch: 1100 Train: 3.015826225 Test: 3.098882675
Epoch: 1200 Train: 2.978099823 Test: 3.061066151
Epoch: 1300 Train: 3.051418781 Test: 3.099202156
Epoch: 1400 Train: 3.036377192 Test: 3.100224018
Epoch: 1500 Train: 2.991057873 Test: 3.061415672
Epoch: 1600 Train: 3.059241533 Test: 3.126930714
Epoch: 1700 Train: 3.060788155 Test: 3.143548965
Epoch: 1800 Train: 3.108755112 Test: 3.179880619
Epoch: 1900 Train: 3.112417221 Test: 3.152177095
Epoch: 2000 Train: 3.072853327 Test: 3.131236076
Epoch: 2100 Train: 3.147400856 Test: 3.207065344
Epoch: 2200 Train: 3.109693050 Test: 3.178652763
Epoch: 2300 Train: 3.132004261 Test: 3.197477102
Epoch: 2400 Train: 3.120324612 Test: 3.187431812
Epoch: 2500 Train: 3.139554024 Test: 3.199562550
Epoch: 2600 Train: 3.134713173 Test: 3.201832771
Epoch: 2700 Train: 3.145659924 Test: 3.222212315
Epoch: 2800 Train: 3.145236969 Test: 3.217007875
Epoch: 2900 Train: 3.112218142 Test: 3.158465147
Epoch: 3000 Train: 3.136405945 Test: 3.195654392
Epoch: 3100 Train: 3.125039101 Test: 3.178529263
Epoch: 3200 Train: 3.182645321 Test: 3.246570110
Epoch: 3300 Train: 3.001366138 Test: 2.950548649
Epoch 3300: New minimal relative error: 2.95%, model saved.
Epoch: 3400 Train: 3.079714298 Test: 3.132040501
Epoch: 3500 Train: 3.141176701 Test: 3.205171108
Epoch: 3600 Train: 3.180184841 Test: 3.235176325
Epoch: 3700 Train: 2.955274820 Test: 3.020523071
Epoch: 3800 Train: 3.024051666 Test: 3.103563070
Epoch: 3900 Train: 3.155776024 Test: 3.224490166
Epoch: 4000 Train: 3.176032782 Test: 3.246619940
Epoch: 4100 Train: 3.184185743 Test: 3.257579803
Epoch: 4200 Train: 3.186074734 Test: 3.258013725
Epoch: 4300 Train: 3.178683043 Test: 3.250207901
Epoch: 4400 Train: 3.171748400 Test: 3.238161564
Epoch: 4500 Train: 3.163463593 Test: 3.230059624
Epoch: 4600 Train: 3.159922123 Test: 3.219764948
Epoch: 4700 Train: 3.150061607 Test: 3.214017391
Epoch: 4800 Train: 3.144813538 Test: 3.210210562
Epoch: 4900 Train: 3.141302586 Test: 3.203879356
Epoch: 5000 Train: 3.128961086 Test: 3.194134474
Epoch: 5100 Train: 3.116430998 Test: 3.180880547
Epoch: 5200 Train: 3.098050594 Test: 3.143395424
Epoch: 5300 Train: 3.055408478 Test: 3.110284090
Epoch: 5400 Train: 3.114643097 Test: 3.173642159
Epoch: 5500 Train: 3.153570652 Test: 3.206021309
Epoch: 5600 Train: 3.166259527 Test: 3.226365089
Epoch: 5700 Train: 3.161840916 Test: 3.225799799
Epoch: 5800 Train: 3.187899351 Test: 3.256940842
Epoch: 5900 Train: 3.184199333 Test: 3.249457836
Epoch: 6000 Train: 3.190520287 Test: 3.252873898
Epoch: 6100 Train: 3.174457550 Test: 3.229914427
Epoch: 6200 Train: 3.151588440 Test: 3.214247704
Epoch: 6300 Train: 3.176753521 Test: 3.237025976
Epoch: 6400 Train: 3.143748760 Test: 3.202670097
Epoch: 6500 Train: 3.140832901 Test: 3.201200724
Epoch: 6600 Train: 3.151639462 Test: 3.209639549
Epoch: 6700 Train: 3.154517174 Test: 3.224175453
Epoch: 6800 Train: 3.169475555 Test: 3.236790180
Epoch: 6900 Train: 3.170459032 Test: 3.237440109
Epoch: 7000 Train: 3.190542936 Test: 3.257850170
Epoch: 7100 Train: 3.208481312 Test: 3.266920090
Epoch: 7200 Train: 3.075455666 Test: 3.135739803
Epoch: 7300 Train: 2.999153137 Test: 3.049726486
Epoch: 7400 Train: 2.998699188 Test: 3.037517548
Epoch: 7500 Train: 2.986351013 Test: 3.030389071
Epoch: 7600 Train: 3.007937431 Test: 3.033331871
Epoch: 7700 Train: 2.998178005 Test: 3.032369137
Epoch: 7800 Train: 3.018722534 Test: 3.067905903
Epoch: 7900 Train: 3.048878670 Test: 3.105366945
Epoch: 8000 Train: 3.074996948 Test: 3.140830517
Epoch: 8100 Train: 3.078273058 Test: 3.148394823
Epoch: 8200 Train: 3.098752022 Test: 3.168422699
Epoch: 8300 Train: 3.103430748 Test: 3.173665285
Epoch: 8400 Train: 3.036557198 Test: 3.092696190
Epoch: 8500 Train: 3.020054340 Test: 3.073003292
Epoch: 8600 Train: 3.033291817 Test: 3.081984997
Epoch: 8700 Train: 3.071390390 Test: 3.126387596
Epoch: 8800 Train: 3.084419250 Test: 3.138386965
Epoch: 8900 Train: 3.095111370 Test: 3.152293682
Epoch: 9000 Train: 3.122738838 Test: 3.178412914
Epoch: 9100 Train: 3.120755911 Test: 3.190879345
Epoch: 9200 Train: 3.147736549 Test: 3.215340614
Epoch: 9300 Train: 3.141904593 Test: 3.212364197
Epoch: 9400 Train: 3.133458138 Test: 3.205847263
Epoch: 9500 Train: 3.137468338 Test: 3.210853100
Epoch: 9600 Train: 3.149949551 Test: 3.228026867
Epoch: 9700 Train: 3.379083633 Test: 3.471218109
Epoch: 9800 Train: 3.111601114 Test: 3.185418606
Epoch: 9900 Train: 3.125989437 Test: 3.203269720
Epoch: 9999 Train: 3.137403488 Test: 3.210343361
Training Loss: tensor(3.1374)
Test Loss: tensor(3.2103)
True Mean x: tensor(2.8976, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(3.3700, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(3.4858, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(0.0007, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(0.0032)
Jacobian term Test Loss: tensor(0.0034)
Learned LE: [2.1658282  0.14074495]
True LE: tensor([ 0.6932, -0.7168], dtype=torch.float64)
