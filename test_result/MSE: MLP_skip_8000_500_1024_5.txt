time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 500
loss_type: MSE
dyn_sys: lorenz
model_type: MLP_skip
n_hidden: 1024
n_layers: 5
reg_param: 3000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_MSE/
Epoch 0: New minimal relative error: 101.92%, model saved.
Epoch: 0 Train: 3536.62183 Test: 4173.06885
Epoch: 80 Train: 81.59938 Test: 82.35281
Epoch 160: New minimal relative error: 28.33%, model saved.
Epoch: 160 Train: 22.36321 Test: 11.19598
Epoch 240: New minimal relative error: 17.95%, model saved.
Epoch: 240 Train: 9.11581 Test: 16.73204
Epoch: 320 Train: 27.89620 Test: 42.73402
Epoch 400: New minimal relative error: 11.09%, model saved.
Epoch: 400 Train: 4.61408 Test: 4.10537
Epoch: 480 Train: 11.58227 Test: 11.34683
Epoch: 560 Train: 1.97804 Test: 1.63998
Epoch 640: New minimal relative error: 8.69%, model saved.
Epoch: 640 Train: 1.21686 Test: 1.29678
Epoch: 720 Train: 9.96340 Test: 15.02852
Epoch: 800 Train: 0.93100 Test: 1.13352
Epoch: 880 Train: 12.97896 Test: 11.91659
Epoch: 960 Train: 2.66859 Test: 2.17357
Epoch: 1040 Train: 1.49875 Test: 1.26550
Epoch: 1120 Train: 0.39229 Test: 0.63243
Epoch: 1200 Train: 2.66376 Test: 3.62665
Epoch: 1280 Train: 1.72738 Test: 1.82461
Epoch: 1360 Train: 4.23171 Test: 6.53689
Epoch: 1440 Train: 8.71147 Test: 7.37678
Epoch: 1520 Train: 3.69743 Test: 3.72299
Epoch: 1600 Train: 2.29394 Test: 2.39519
Epoch: 1680 Train: 10.68970 Test: 6.86180
Epoch: 1760 Train: 2.70803 Test: 3.73441
Epoch: 1840 Train: 1.63994 Test: 2.00271
Epoch: 1920 Train: 0.79958 Test: 1.07278
Epoch: 2000 Train: 1.14792 Test: 0.94430
Epoch: 2080 Train: 1.90366 Test: 2.32008
Epoch: 2160 Train: 2.65717 Test: 3.64799
Epoch: 2240 Train: 1.85395 Test: 1.84115
Epoch: 2320 Train: 2.88763 Test: 2.11833
Epoch: 2400 Train: 3.38862 Test: 5.10045
Epoch: 2480 Train: 1.92170 Test: 2.16785
Epoch: 2560 Train: 0.80151 Test: 0.62624
Epoch: 2640 Train: 1.62431 Test: 2.25051
Epoch: 2720 Train: 2.35116 Test: 2.05662
Epoch 2800: New minimal relative error: 4.41%, model saved.
Epoch: 2800 Train: 0.43613 Test: 0.53959
Epoch: 2880 Train: 0.16220 Test: 0.10708
Epoch: 2960 Train: 0.38325 Test: 0.47191
Epoch: 3040 Train: 0.28185 Test: 0.32104
Epoch: 3120 Train: 0.77387 Test: 1.03340
Epoch: 3200 Train: 0.16654 Test: 0.30598
Epoch: 3280 Train: 0.10043 Test: 0.09684
Epoch: 3360 Train: 0.10707 Test: 0.09715
Epoch: 3440 Train: 0.47653 Test: 0.47873
Epoch: 3520 Train: 1.34172 Test: 1.60810
Epoch: 3600 Train: 0.43883 Test: 0.75039
Epoch: 3680 Train: 0.76882 Test: 0.59075
Epoch: 3760 Train: 2.00829 Test: 0.90740
Epoch: 3840 Train: 0.20356 Test: 0.25983
Epoch: 3920 Train: 2.01505 Test: 2.40722
Epoch: 4000 Train: 0.15116 Test: 0.12013
Epoch: 4080 Train: 0.37284 Test: 0.44707
Epoch: 4160 Train: 0.43185 Test: 0.47334
Epoch: 4240 Train: 0.06556 Test: 0.09038
Epoch: 4320 Train: 0.11297 Test: 0.10716
Epoch: 4400 Train: 0.10206 Test: 0.11317
Epoch: 4480 Train: 0.27882 Test: 0.44756
Epoch: 4560 Train: 0.20529 Test: 0.43530
Epoch: 4640 Train: 0.66458 Test: 0.74551
Epoch: 4720 Train: 0.16709 Test: 0.21350
Epoch: 4800 Train: 0.04079 Test: 0.05246
Epoch: 4880 Train: 0.06981 Test: 0.07314
Epoch: 4960 Train: 0.13969 Test: 0.15555
Epoch: 5040 Train: 0.04051 Test: 0.06462
Epoch: 5120 Train: 0.33531 Test: 0.37049
Epoch: 5200 Train: 0.42528 Test: 0.43383
Epoch: 5280 Train: 0.34461 Test: 0.44513
Epoch: 5360 Train: 0.67296 Test: 0.43938
Epoch: 5440 Train: 0.03949 Test: 0.05009
Epoch: 5520 Train: 0.06960 Test: 0.13750
Epoch: 5600 Train: 0.06901 Test: 0.07655
Epoch: 5680 Train: 0.05395 Test: 0.05917
Epoch: 5760 Train: 1.23792 Test: 1.36014
Epoch: 5840 Train: 0.21424 Test: 0.26428
Epoch: 5920 Train: 0.06210 Test: 0.10295
Epoch: 6000 Train: 0.17790 Test: 0.17052
Epoch: 6080 Train: 0.10181 Test: 0.12383
Epoch: 6160 Train: 0.06552 Test: 0.08052
Epoch: 6240 Train: 0.26739 Test: 0.30487
Epoch: 6320 Train: 0.03544 Test: 0.04418
Epoch: 6400 Train: 0.21517 Test: 0.24768
Epoch: 6480 Train: 0.04750 Test: 0.07200
Epoch: 6560 Train: 0.14370 Test: 0.21179
Epoch: 6640 Train: 0.15746 Test: 0.20038
Epoch: 6720 Train: 0.06244 Test: 0.06228
Epoch: 6800 Train: 0.10508 Test: 0.12103
Epoch: 6880 Train: 0.39549 Test: 0.35066
Epoch: 6960 Train: 0.06857 Test: 0.09823
Epoch: 7040 Train: 0.41356 Test: 0.58692
Epoch: 7120 Train: 0.11497 Test: 0.14352
Epoch: 7200 Train: 0.07461 Test: 0.11086
Epoch: 7280 Train: 0.03725 Test: 0.04207
Epoch: 7360 Train: 0.03223 Test: 0.04835
Epoch: 7440 Train: 0.06959 Test: 0.09965
Epoch: 7520 Train: 0.16589 Test: 0.18441
Epoch: 7600 Train: 0.36108 Test: 0.35501
Epoch: 7680 Train: 0.04898 Test: 0.06168
Epoch: 7760 Train: 0.06745 Test: 0.07420
Epoch: 7840 Train: 0.10353 Test: 0.14847
Epoch: 7920 Train: 0.04111 Test: 0.04842
Epoch: 7999 Train: 0.03607 Test: 0.04877
Training Loss: tensor(0.0361)
Test Loss: tensor(0.0488)
Learned LE: [ 0.69792837 -0.02588371 -3.133977  ]
True LE: [ 8.7964606e-01 -2.5608954e-03 -1.4548294e+01]
Relative Error: [1.4710156  1.4099829  1.3627008  1.2906511  1.2205008  1.1197708
 1.2252316  1.4384769  1.499094   1.530182   1.5801039  1.7157292
 1.7648865  1.8476156  1.9761609  2.0684412  1.8058167  1.5372838
 1.8919097  2.2874904  2.3364549  2.101369   2.0355966  1.8494672
 1.7851088  1.672807   1.8274367  1.8824277  1.7296193  1.453745
 1.4156954  1.451086   1.4784579  1.481749   1.5300654  1.6869018
 1.684171   1.5759876  1.585038   1.7365211  1.6224036  1.7563574
 1.9811552  1.6329089  1.47483    1.3415967  1.5912626  1.6114453
 1.6462535  1.722623   1.87779    2.0025692  1.9428054  1.8159412
 1.7094679  1.7795496  1.7262784  1.696683   1.599289   1.4390739
 1.3666327  1.3527107  1.272561   1.2710347  1.2756047  1.1784209
 1.1402014  1.0459439  1.0934372  1.1900522  1.4314952  1.3948069
 1.4286762  1.4710668  1.5754101  1.6359276  1.732755   1.8190799
 1.6949608  1.2757357  1.6621993  2.2776923  2.432713   2.2115154
 2.1137514  1.8531429  1.6540166  1.5291485  1.682462   1.6722311
 1.6448776  1.5224912  1.3772881  1.276659   1.2947004  1.2519286
 1.2945032  1.5138353  1.7580347  1.5500897  1.5657082  1.5883346
 1.7528212  1.5052036  1.5859431  1.7015643  1.3944701  1.2699909
 1.4569218  1.477051   1.589204   1.6588602  1.6905522  1.8751144
 1.8640074  1.6914115  1.5770531  1.7067575  1.6603254  1.5527121
 1.4362907  1.293556   1.1739023  1.0784863  1.0454262  1.070595
 1.1217881  1.1192392  1.086294   1.0190117  1.0330322  1.0869052
 1.2781918  1.3210865  1.253391   1.2263709  1.2905427  1.3941332
 1.4994824  1.5277711  1.4070237  1.1093537  1.4461854  2.0934618
 2.4415708  2.2714899  2.1016626  1.9442903  1.7456019  1.5405067
 1.5872511  1.4881613  1.4260842  1.4672503  1.3593297  1.2036024
 1.1023326  1.0998884  1.0995243  1.1983631  1.3361928  1.3626709
 1.4567343  1.5441359  1.5777392  1.6869297  1.3988856  1.416913
 1.4712467  1.2480897  1.2151966  1.4477035  1.481101   1.5305216
 1.4282324  1.6807792  1.7919649  1.6360724  1.5363234  1.5909406
 1.6117337  1.4302478  1.3179544  1.2350079  1.1745826  1.0310749
 0.91044706 0.9435846  1.0245697  1.0437047  1.1349778  1.1870472
 1.1314437  1.1115521  1.1986185  1.4139936  1.2357264  1.0883144
 1.0393683  1.1022481  1.2837415  1.2231028  1.1832677  1.0161959
 1.1759079  1.6669195  2.2551181  2.2493234  2.0255754  1.9414874
 1.8422894  1.6401727  1.5527223  1.4953388  1.3467407  1.326132
 1.339192   1.1617081  1.0689777  0.95563996 0.9779541  0.95481676
 1.0835736  1.2273059  1.1866763  1.3990971  1.489872   1.5610689
 1.5223684  1.26042    1.272664   1.2836524  1.1651658  1.374334
 1.3038886  1.3356827  1.402255   1.4987041  1.7575148  1.5594302
 1.5162523  1.5295528  1.561938   1.3816502  1.2123619  1.2174412
 1.2259015  1.1547307  0.95559925 0.8682453  0.9031837  1.044636
 1.1278223  1.2182753  1.3021543  1.2942455  1.2880495  1.414539
 1.5350304  1.1664691  0.9468135  0.89176524 0.97838354 1.1211836
 1.1228845  0.9424071  1.0125067  1.2762492  1.8014079  2.1292458
 1.9276222  1.6972516  1.7930249  1.7259276  1.5059085  1.4723732
 1.282071   1.3333156  1.1096361  1.0849884  1.0847373  1.0211853
 0.9892292  1.046201   1.0729882  1.1132216  1.0030811  1.0868174
 1.3293427  1.4044363  1.4216672  1.434735   1.2220118  1.1229925
 1.0547976  1.1779145  1.3871503  1.3300513  1.2575759  1.3851185
 1.6335346  1.5144199  1.459288   1.3948543  1.4106139  1.3531735
 1.2399185  1.289046   1.315509   1.2244835  1.1416054  1.0384499
 0.90372115 0.920431   1.0267111  1.2136035  1.3689091  1.4693348
 1.504526   1.4480637  1.5214809  1.5220957  1.163026   0.92549604
 0.8529047  0.88535464 1.0046561  1.1009198  0.9135324  1.1511205
 1.3765242  1.864828   1.8685479  1.476687   1.4229048  1.6884168
 1.3840896  1.3624368  1.2771585  1.1986955  1.1021549  0.9420693
 0.89727837 1.0794318  1.0324361  1.1224774  1.1823282  1.1630563
 1.2156963  0.9944586  0.9858017  1.1708618  1.3558117  1.3543091
 1.2957647  1.2351227  1.0056013  0.9748311  1.1530831  1.3822666
 1.5153581  1.2955105  1.545588   1.74793    1.4217349  1.2938157
 1.334961   1.2906145  1.2120113  1.3370074  1.3381476  1.353953
 1.1234369  1.018839   0.97268385 0.90568334 0.9442195  1.0742892
 1.2906022  1.3983765  1.4500592  1.4620265  1.4092056  1.4078
 1.5217552  1.2501281  0.95827085 0.78494716 0.6970655  0.8437188
 0.9979965  0.9975077  1.2080481  1.4227642  1.8162823  1.6598387
 1.1527296  1.2100099  1.4015962  1.265153  ]
