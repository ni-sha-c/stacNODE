time_step: 1.0
lr: 0.001
weight_decay: 0.0005
num_epoch: 10000
num_train: 5000
num_test: 5000
num_val: 3000
num_trans: 0
loss_type: Jacobian
dyn_sys: baker
model_type: MLP
s: 0.0
n_hidden: 256
n_layers: 3
reg_param: 100.0
threshold: 0.0
optim_name: AdamW
Epoch: 0 Train: 222.323577881 Test: 10.437595367
Epoch 0: New minimal relative error: 10.44%, model saved.
Epoch: 100 Train: 11.043727875 Test: 9.257298470
Epoch 100: New minimal relative error: 9.26%, model saved.
Epoch: 200 Train: 10.130189896 Test: 7.899302959
Epoch 200: New minimal relative error: 7.90%, model saved.
Epoch: 300 Train: 9.547012329 Test: 6.973177910
Epoch 300: New minimal relative error: 6.97%, model saved.
Epoch: 400 Train: 9.212484360 Test: 6.585352898
Epoch 400: New minimal relative error: 6.59%, model saved.
Epoch: 500 Train: 8.786412239 Test: 6.217668056
Epoch 500: New minimal relative error: 6.22%, model saved.
Epoch: 600 Train: 8.791512489 Test: 5.996070385
Epoch 600: New minimal relative error: 6.00%, model saved.
Epoch: 700 Train: 8.137988091 Test: 5.596106529
Epoch 700: New minimal relative error: 5.60%, model saved.
Epoch: 800 Train: 9.693490028 Test: 6.400987148
Epoch: 900 Train: 9.065459251 Test: 6.306215286
Epoch: 1000 Train: 8.949808121 Test: 6.180642605
Epoch: 1100 Train: 8.827780724 Test: 6.027198792
Epoch: 1200 Train: 8.912884712 Test: 5.738990307
Epoch: 1300 Train: 10.059626579 Test: 6.178040981
Epoch: 1400 Train: 7.292648315 Test: 4.833932877
Epoch 1400: New minimal relative error: 4.83%, model saved.
Epoch: 1500 Train: 8.079492569 Test: 5.172615528
Epoch: 1600 Train: 8.699164391 Test: 6.072046757
Epoch: 1700 Train: 8.266306877 Test: 5.665854454
Epoch: 1800 Train: 7.267573357 Test: 4.811069489
Epoch 1800: New minimal relative error: 4.81%, model saved.
Epoch: 1900 Train: 8.857815742 Test: 6.006519318
Epoch: 2000 Train: 8.071727753 Test: 5.514949322
Epoch: 2100 Train: 7.893710136 Test: 5.313108444
Epoch: 2200 Train: 7.703136444 Test: 5.106133461
Epoch: 2300 Train: 7.272174358 Test: 4.609989166
Epoch 2300: New minimal relative error: 4.61%, model saved.
Epoch: 2400 Train: 5.380537987 Test: 3.350478888
Epoch 2400: New minimal relative error: 3.35%, model saved.
Epoch: 2500 Train: 3.495510101 Test: 2.153400421
Epoch 2500: New minimal relative error: 2.15%, model saved.
Epoch: 2600 Train: 2.759505272 Test: 1.514721632
Epoch 2600: New minimal relative error: 1.51%, model saved.
Epoch: 2700 Train: 1.467797995 Test: 0.963395953
Epoch 2700: New minimal relative error: 0.96%, model saved.
Epoch: 2800 Train: 1.033102155 Test: 0.729194403
Epoch 2800: New minimal relative error: 0.73%, model saved.
Epoch: 2900 Train: 0.805151105 Test: 0.602563441
Epoch 2900: New minimal relative error: 0.60%, model saved.
Epoch: 3000 Train: 0.681307554 Test: 0.557962298
Epoch 3000: New minimal relative error: 0.56%, model saved.
Epoch: 3100 Train: 0.617254198 Test: 0.535439730
Epoch 3100: New minimal relative error: 0.54%, model saved.
Epoch: 3200 Train: 0.580514312 Test: 0.522323012
Epoch 3200: New minimal relative error: 0.52%, model saved.
Epoch: 3300 Train: 0.587285340 Test: 0.517091632
Epoch 3300: New minimal relative error: 0.52%, model saved.
Epoch: 3400 Train: 0.547017932 Test: 0.514256120
Epoch 3400: New minimal relative error: 0.51%, model saved.
Epoch: 3500 Train: 0.538929105 Test: 0.513037682
Epoch 3500: New minimal relative error: 0.51%, model saved.
Epoch: 3600 Train: 0.737992823 Test: 0.559203863
Epoch: 3700 Train: 0.530019879 Test: 0.512204468
Epoch 3700: New minimal relative error: 0.51%, model saved.
Epoch: 3800 Train: 0.527291834 Test: 0.511990428
Epoch 3800: New minimal relative error: 0.51%, model saved.
Epoch: 3900 Train: 0.525236130 Test: 0.512125850
Epoch: 4000 Train: 0.523788750 Test: 0.512281716
Epoch: 4100 Train: 0.522461236 Test: 0.511923909
Epoch 4100: New minimal relative error: 0.51%, model saved.
Epoch: 4200 Train: 0.521409631 Test: 0.511941433
Epoch: 4300 Train: 0.521237195 Test: 0.511028588
Epoch 4300: New minimal relative error: 0.51%, model saved.
Epoch: 4400 Train: 0.519892573 Test: 0.511985242
Epoch: 4500 Train: 0.519259155 Test: 0.511998713
Epoch: 4600 Train: 0.520159900 Test: 0.510470808
Epoch 4600: New minimal relative error: 0.51%, model saved.
Epoch: 4700 Train: 0.518299580 Test: 0.511998415
Epoch: 4800 Train: 0.517865598 Test: 0.512052894
Epoch: 4900 Train: 0.517488599 Test: 0.512068927
Epoch: 5000 Train: 0.519042790 Test: 0.513129592
Epoch: 5100 Train: 0.516897321 Test: 0.512094915
Epoch: 5200 Train: 0.516624272 Test: 0.512102604
Epoch: 5300 Train: 0.516376793 Test: 0.512115896
Epoch: 5400 Train: 0.516990185 Test: 0.513151348
Epoch: 5500 Train: 0.515968382 Test: 0.512130618
Epoch: 5600 Train: 0.515780807 Test: 0.512130380
Epoch: 5700 Train: 0.515688181 Test: 0.512657046
Epoch: 5800 Train: 0.515476227 Test: 0.512147546
Epoch: 5900 Train: 0.515331626 Test: 0.512148976
Epoch: 6000 Train: 0.595578134 Test: 0.524054468
Epoch: 6100 Train: 0.515092611 Test: 0.512190282
Epoch: 6200 Train: 0.514976799 Test: 0.512160063
Epoch: 6300 Train: 0.514871657 Test: 0.512198031
Epoch: 6400 Train: 0.514834642 Test: 0.512063801
Epoch: 6500 Train: 0.514701009 Test: 0.512169719
Epoch: 6600 Train: 0.514616847 Test: 0.512169898
Epoch: 6700 Train: 0.514537930 Test: 0.512173593
Epoch: 6800 Train: 0.514926612 Test: 0.513269782
Epoch: 6900 Train: 0.514406323 Test: 0.512169003
Epoch: 7000 Train: 0.514342010 Test: 0.512176573
Epoch: 7100 Train: 0.514281511 Test: 0.512181640
Epoch: 7200 Train: 0.514322698 Test: 0.511907816
Epoch: 7300 Train: 0.514182150 Test: 0.512179255
Epoch: 7400 Train: 0.514132261 Test: 0.512179971
Epoch: 7500 Train: 0.514085412 Test: 0.512188852
Epoch: 7600 Train: 0.514054596 Test: 0.512182295
Epoch: 7700 Train: 0.514004409 Test: 0.512183130
Epoch: 7800 Train: 0.513965130 Test: 0.512185454
Epoch: 7900 Train: 0.514164865 Test: 0.511903822
Epoch: 8000 Train: 0.513897896 Test: 0.512182295
Epoch: 8100 Train: 0.513864040 Test: 0.512185156
Epoch: 8200 Train: 0.514218748 Test: 0.512076080
Epoch: 8300 Train: 0.514015257 Test: 0.511834681
Epoch: 8400 Train: 0.530012906 Test: 0.516960263
Epoch: 8500 Train: 0.513750911 Test: 0.512188733
Epoch: 8600 Train: 0.516961098 Test: 0.512924552
Epoch: 8700 Train: 0.513703823 Test: 0.512183845
Epoch: 8800 Train: 0.513680041 Test: 0.512186110
Epoch: 8900 Train: 0.513754427 Test: 0.512213290
Epoch: 9000 Train: 0.513638854 Test: 0.512188256
Epoch: 9100 Train: 0.514177740 Test: 0.512746453
Epoch: 9200 Train: 0.513601601 Test: 0.512189150
Epoch: 9300 Train: 0.514743328 Test: 0.512600005
Epoch: 9400 Train: 0.513568580 Test: 0.512180865
Epoch: 9500 Train: 0.513685882 Test: 0.511564314
Epoch: 9600 Train: 0.513534904 Test: 0.512196362
Epoch: 9700 Train: 0.513600588 Test: 0.512255251
Epoch: 9800 Train: 0.515408516 Test: 0.513575792
Epoch: 9900 Train: 0.513492286 Test: 0.512195230
Epoch: 9999 Train: 0.513480663 Test: 0.512144685
Training Loss: tensor(0.5135)
Test Loss: tensor(0.5121)
True Mean x: tensor(3.1718, device='cuda:0', grad_fn=<MeanBackward0>)
Learned Mean x: tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
True Var x: tensor(3.3282, device='cuda:0', grad_fn=<VarBackward0>)
Learned Var x: tensor(nan, device='cuda:0', grad_fn=<VarBackward0>)
Jacobian term Training Loss: tensor(4.5044e-05)
Jacobian term Test Loss: tensor(0.0045)
Learned LE: [nan nan]
True LE: tensor([ 0.6931, -0.6931], dtype=torch.float64)
