time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 500
loss_type: Jacobian
dyn_sys: lorenz
model_type: MLP_skip
n_hidden: 256
n_layers: 3
reg_param: 1000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_Jac/
Epoch 0: New minimal relative error: 102.05%, model saved.
Epoch: 0 Train: 59868.10938 Test: 4257.36621
Epoch 80: New minimal relative error: 97.43%, model saved.
Epoch: 80 Train: 16221.63867 Test: 1722.25391
Epoch 160: New minimal relative error: 79.65%, model saved.
Epoch: 160 Train: 15724.96191 Test: 1625.61243
Epoch: 240 Train: 14748.87695 Test: 1427.35498
Epoch 320: New minimal relative error: 77.17%, model saved.
Epoch: 320 Train: 15071.21387 Test: 1414.19446
Epoch 400: New minimal relative error: 77.09%, model saved.
Epoch: 400 Train: 14241.63477 Test: 1303.49231
Epoch 480: New minimal relative error: 75.76%, model saved.
Epoch: 480 Train: 14606.98633 Test: 1356.54260
Epoch 560: New minimal relative error: 73.71%, model saved.
Epoch: 560 Train: 14726.44141 Test: 1364.26624
Epoch: 640 Train: 13811.64355 Test: 1301.44446
Epoch: 720 Train: 14230.40039 Test: 1349.97339
Epoch 800: New minimal relative error: 71.95%, model saved.
Epoch: 800 Train: 14566.04883 Test: 1488.27747
Epoch: 880 Train: 13410.92188 Test: 1312.64465
Epoch: 960 Train: 11706.86230 Test: 985.06561
Epoch: 1040 Train: 8660.29395 Test: 506.98318
Epoch: 1120 Train: 5632.96777 Test: 229.99271
Epoch: 1200 Train: 2890.73584 Test: 73.70487
Epoch 1280: New minimal relative error: 22.23%, model saved.
Epoch: 1280 Train: 1709.34546 Test: 30.84175
Epoch 1360: New minimal relative error: 22.03%, model saved.
Epoch: 1360 Train: 1058.21838 Test: 13.87306
Epoch 1440: New minimal relative error: 9.62%, model saved.
Epoch: 1440 Train: 789.70190 Test: 10.62674
Epoch: 1520 Train: 652.89349 Test: 5.94599
Epoch: 1600 Train: 570.07971 Test: 4.47107
Epoch: 1680 Train: 474.80087 Test: 3.01983
Epoch 1760: New minimal relative error: 8.82%, model saved.
Epoch: 1760 Train: 434.08218 Test: 2.60504
Epoch: 1840 Train: 410.68671 Test: 2.26413
Epoch: 1920 Train: 378.41385 Test: 1.91714
Epoch 2000: New minimal relative error: 7.16%, model saved.
Epoch: 2000 Train: 348.17737 Test: 1.56841
Epoch: 2080 Train: 339.49796 Test: 1.53738
Epoch: 2160 Train: 342.25284 Test: 1.77658
Epoch: 2240 Train: 360.12158 Test: 2.70270
Epoch: 2320 Train: 348.29422 Test: 1.93974
Epoch: 2400 Train: 334.96799 Test: 1.88248
Epoch 2480: New minimal relative error: 5.37%, model saved.
Epoch: 2480 Train: 299.99939 Test: 1.61048
Epoch: 2560 Train: 306.43265 Test: 1.57151
Epoch: 2640 Train: 290.69821 Test: 1.41348
Epoch: 2720 Train: 280.45795 Test: 1.50493
Epoch: 2800 Train: 277.70599 Test: 2.28873
Epoch: 2880 Train: 267.12576 Test: 1.45392
Epoch: 2960 Train: 269.66461 Test: 1.68084
Epoch: 3040 Train: 268.10614 Test: 1.48427
Epoch: 3120 Train: 259.12665 Test: 1.44735
Epoch: 3200 Train: 258.17920 Test: 1.50376
Epoch: 3280 Train: 258.46909 Test: 1.45643
Epoch: 3360 Train: 288.86139 Test: 1.89220
Epoch: 3440 Train: 306.45569 Test: 1.95669
Epoch: 3520 Train: 286.85086 Test: 1.92600
Epoch: 3600 Train: 274.18494 Test: 2.04380
Epoch 3680: New minimal relative error: 5.09%, model saved.
Epoch: 3680 Train: 250.50124 Test: 1.44406
Epoch: 3760 Train: 233.47733 Test: 1.33330
Epoch: 3840 Train: 241.66441 Test: 1.36676
Epoch: 3920 Train: 228.38432 Test: 1.16417
Epoch 4000: New minimal relative error: 4.67%, model saved.
Epoch: 4000 Train: 218.12085 Test: 1.01425
Epoch: 4080 Train: 215.84485 Test: 0.94391
Epoch: 4160 Train: 222.34601 Test: 1.09676
Epoch: 4240 Train: 212.69101 Test: 1.04256
Epoch 4320: New minimal relative error: 4.23%, model saved.
Epoch: 4320 Train: 207.15515 Test: 0.87971
Epoch: 4400 Train: 209.81892 Test: 0.93159
Epoch: 4480 Train: 215.69252 Test: 0.97282
Epoch: 4560 Train: 203.08553 Test: 0.88800
Epoch 4640: New minimal relative error: 3.53%, model saved.
Epoch: 4640 Train: 201.86217 Test: 0.83297
Epoch: 4720 Train: 207.84431 Test: 1.20702
Epoch: 4800 Train: 208.71571 Test: 0.90141
Epoch: 4880 Train: 211.71779 Test: 0.89925
Epoch: 4960 Train: 210.47092 Test: 0.89718
Epoch: 5040 Train: 206.50134 Test: 0.82028
Epoch: 5120 Train: 201.78622 Test: 0.81044
Epoch: 5200 Train: 203.54022 Test: 0.79979
Epoch: 5280 Train: 200.44478 Test: 0.76396
Epoch: 5360 Train: 204.02249 Test: 0.81751
Epoch: 5440 Train: 214.79532 Test: 1.03107
Epoch: 5520 Train: 205.66455 Test: 0.93766
Epoch: 5600 Train: 219.22847 Test: 1.23608
Epoch 5680: New minimal relative error: 3.31%, model saved.
Epoch: 5680 Train: 198.80756 Test: 0.84784
Epoch: 5760 Train: 190.08249 Test: 0.72267
Epoch: 5840 Train: 182.50134 Test: 0.73940
Epoch: 5920 Train: 177.48642 Test: 0.67706
Epoch: 6000 Train: 168.79256 Test: 0.54668
Epoch: 6080 Train: 159.77953 Test: 0.52937
Epoch: 6160 Train: 150.07129 Test: 0.43739
Epoch: 6240 Train: 150.37787 Test: 0.43912
Epoch: 6320 Train: 138.28458 Test: 0.35550
Epoch: 6400 Train: 137.09119 Test: 0.32091
Epoch 6480: New minimal relative error: 2.92%, model saved.
Epoch: 6480 Train: 134.76553 Test: 0.31659
Epoch: 6560 Train: 134.27827 Test: 0.31744
Epoch: 6640 Train: 139.37498 Test: 0.43439
Epoch: 6720 Train: 164.45468 Test: 0.83824
Epoch: 6800 Train: 215.16437 Test: 1.64841
Epoch: 6880 Train: 161.29701 Test: 0.62462
Epoch: 6960 Train: 182.86778 Test: 0.93081
Epoch: 7040 Train: 172.09641 Test: 0.78099
Epoch: 7120 Train: 170.66188 Test: 0.96764
Epoch: 7200 Train: 173.78665 Test: 0.96125
Epoch: 7280 Train: 144.26208 Test: 0.63336
Epoch: 7360 Train: 128.49548 Test: 0.33997
Epoch: 7440 Train: 126.76356 Test: 0.28717
Epoch 7520: New minimal relative error: 2.12%, model saved.
Epoch: 7520 Train: 128.62561 Test: 0.38488
Epoch: 7600 Train: 136.19888 Test: 0.50097
Epoch: 7680 Train: 133.16801 Test: 0.59024
Epoch: 7760 Train: 120.10983 Test: 0.47381
Epoch: 7840 Train: 125.06506 Test: 0.42483
Epoch: 7920 Train: 111.02787 Test: 0.29418
Epoch: 7999 Train: 123.64931 Test: 0.52148
Training Loss: tensor(123.6493)
Test Loss: tensor(0.5215)
Learned LE: [ -0.8354861  -1.6376469 -12.825075 ]
True LE: [ 8.6603558e-01 -2.2113859e-03 -1.4551199e+01]
Relative Error: [141.27507  145.69218  148.5913   149.90265  149.53981  147.63062
 144.38474  139.92699  134.47057  128.22313  121.29879  113.90864
 106.18835   98.26828   90.16255   81.93396   73.63773   65.35428
  57.191788  49.32848   42.078247  35.994316  31.900436  30.891672
  33.35693   38.6125    45.648327  53.515457  61.52456   69.25159
  76.25453   82.13737   86.64626   89.5729    90.87302   90.642395
  89.07022   86.403915  82.926414  78.98411   74.728874  70.39535
  66.22474   62.38679   59.10723   56.54567   54.85421   54.182785
  54.6288    56.22855   58.957005  62.7441    67.45835   73.013306
  79.283775  86.175064  93.45187  101.0087   108.66438  116.34047
 123.74244  130.56044  136.48283  141.23604  144.55913  146.32072
 146.43259  144.96948  142.16301  138.09248  132.98572  126.994
 120.30186  113.09884  105.56306   97.734634  89.684746  81.458305
  73.09501   64.67853   56.309666  48.14022   40.452328  33.735214
  28.949339  27.276274  29.583445  35.08123   42.45779   50.70758
  59.084057  67.07615   74.41725   80.61574   85.448944  88.672104
  90.21898   90.17161   88.71023   86.08131   82.59013   78.53812
  74.109886  69.57756   65.12432   60.977375  57.31709   54.317326
  52.16611   51.02861   51.02631   52.21899   54.59172   58.076412
  62.559944  67.91634   73.99305   80.694565  87.86416   95.35076
 102.98752  110.59761  118.09928  125.118546 131.37015  136.53273
 140.38017  142.70149  143.42192  142.51581  140.26611  136.69577
 132.02068  126.38316  119.99538  113.05809  105.72673   98.04952
  90.08513   81.85661   73.46465   64.96567   56.4296    47.972576
  39.81489   32.40373   26.652401  23.999214  25.628153  31.122906
  38.753216  47.345856  56.104183  64.486496  72.16748   78.79707
  84.05569   87.71029   89.64948   89.92328   88.69511   86.20602
  82.769196  78.66845   74.12874   69.397285  64.67395   60.195946
  56.117336  52.67175   50.06609   48.471058  47.955788  48.610367
  50.4472    53.41106   57.48567   62.487022  68.34083   74.83909
  81.8544    89.1872    96.792435 104.42287  111.91747  119.15094
 125.74472  131.40498  135.86475  138.86795  140.3434   140.13376
 138.57466  135.64632  131.51248  126.35551  120.36927  113.77988
 106.720665  99.24333   91.38405   83.24156   74.87835   66.349205
  57.709682  49.036892  40.47528   32.352448  25.39345   21.175095
  21.61683   26.60214   34.353577  43.20301   52.35526   61.187565
  69.2734    76.45026   82.262825  86.51522   89.02897   89.80134
  88.96988   86.76134   83.48186   79.42086   74.8345    69.94387
  64.98203   60.1641    55.752243  51.902496  48.79759   46.563564
  45.41191   45.418377  46.632404  49.022205  52.49295   56.94514
  62.349667  68.49659   75.29977   82.48778   89.94824   97.583145
 105.14923  112.48313  119.42865  125.6162   130.74924  134.57732
 136.91147  137.64526  136.89926  134.79019  131.36435  126.837456
 121.37991  115.232155 108.524574 101.30278   93.63857   85.64893
  77.393394  68.92612   60.279102  51.491432  42.66445   33.986137
  25.8977    19.583956  17.655828  21.544395  29.022095  38.071995
  47.5409    56.86977   65.55149   73.27929   79.82131   84.83282
  88.134514  89.63376   89.417625  87.68364   84.71603   80.82714
  76.28279   71.29398   66.13919   61.083084  56.31377   52.03547
  48.358936  45.46278   43.52667   42.7167    43.134357  44.79111
  47.614567  51.48853   56.263287  61.799248  68.17927   75.106285
  82.40911   89.92981   97.54257  105.02535  112.19777  118.889496
 124.75128  129.48514  132.83469  134.69655  134.94862  133.87317
 131.38255  127.666565 122.910324 117.33749  111.10986  104.27326
  96.918945  89.176186  81.102715  72.76082   64.18644   55.416306
  46.492935  37.492302  28.646603  20.572536  15.128038  15.966914
  22.663055  31.651146  41.397156  51.161385  60.501648  68.96389
  76.33066   82.2892    86.610435  89.121826  89.808044  88.81774
  86.39238   82.867584  78.512886  73.55209   68.285774  63.053097
  57.96563   53.21958   48.95732   45.32518   42.532352  40.758263
  40.1756    40.870388  42.82653   45.94098   50.065052  55.041294
  60.746105  67.07777   74.07279   81.38517   88.917564  96.48985
 103.91185  110.95468  117.48191  123.152664 127.66531  130.76639
 132.36508  132.46423  131.20714  128.55418  124.74134  119.947395
 114.398    108.136406 101.24023   93.8702    86.096275  77.99678
  69.606705  60.96025   52.06946   42.98065   33.78667   24.701546
  16.462563  11.864508  15.246789  23.71037 ]
time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 8000
num_train: 10000
num_test: 6000
num_trans: 500
loss_type: Jacobian
dyn_sys: lorenz
model_type: MLP_skip
n_hidden: 256
n_layers: 3
reg_param: 1000
optim_name: AdamW
train_dir: ../plot/Vector_field/train_MLPskip_Jac/
Epoch 0: New minimal relative error: 102.05%, model saved.
Epoch: 0 Train: 59868.10938 Test: 4257.36621
Epoch 80: New minimal relative error: 97.43%, model saved.
Epoch: 80 Train: 16221.63867 Test: 1722.25391
Epoch 160: New minimal relative error: 79.65%, model saved.
Epoch: 160 Train: 15724.96191 Test: 1625.61243
Epoch: 240 Train: 14748.87695 Test: 1427.35498
Epoch 320: New minimal relative error: 77.17%, model saved.
Epoch: 320 Train: 15071.21387 Test: 1414.19446
Epoch 400: New minimal relative error: 77.09%, model saved.
Epoch: 400 Train: 14241.63477 Test: 1303.49231
Epoch 480: New minimal relative error: 75.76%, model saved.
Epoch: 480 Train: 14606.98633 Test: 1356.54260
Epoch 560: New minimal relative error: 73.71%, model saved.
Epoch: 560 Train: 14726.44141 Test: 1364.26624
Epoch: 640 Train: 13811.64355 Test: 1301.44446
Epoch: 720 Train: 14230.40039 Test: 1349.97339
Epoch 800: New minimal relative error: 71.95%, model saved.
Epoch: 800 Train: 14566.04883 Test: 1488.27747
Epoch: 880 Train: 13410.92188 Test: 1312.64465
Epoch: 960 Train: 11706.86230 Test: 985.06561
Epoch: 1040 Train: 8660.29395 Test: 506.98318
Epoch: 1120 Train: 5632.96777 Test: 229.99271
Epoch: 1200 Train: 2890.73584 Test: 73.70487
Epoch 1280: New minimal relative error: 22.23%, model saved.
Epoch: 1280 Train: 1709.34546 Test: 30.84175
Epoch 1360: New minimal relative error: 22.03%, model saved.
Epoch: 1360 Train: 1058.21838 Test: 13.87306
Epoch 1440: New minimal relative error: 9.62%, model saved.
Epoch: 1440 Train: 789.70190 Test: 10.62674
Epoch: 1520 Train: 652.89349 Test: 5.94599
Epoch: 1600 Train: 570.07971 Test: 4.47107
Epoch: 1680 Train: 474.80087 Test: 3.01983
Epoch 1760: New minimal relative error: 8.82%, model saved.
Epoch: 1760 Train: 434.08218 Test: 2.60504
Epoch: 1840 Train: 410.68671 Test: 2.26413
Epoch: 1920 Train: 378.41385 Test: 1.91714
Epoch 2000: New minimal relative error: 7.16%, model saved.
Epoch: 2000 Train: 348.17737 Test: 1.56841
Epoch: 2080 Train: 339.49796 Test: 1.53738
Epoch: 2160 Train: 342.25284 Test: 1.77658
Epoch: 2240 Train: 360.12158 Test: 2.70270
Epoch: 2320 Train: 348.29422 Test: 1.93974
Epoch: 2400 Train: 334.96799 Test: 1.88248
Epoch 2480: New minimal relative error: 5.37%, model saved.
Epoch: 2480 Train: 299.99939 Test: 1.61048
Epoch: 2560 Train: 306.43265 Test: 1.57151
Epoch: 2640 Train: 290.69821 Test: 1.41348
Epoch: 2720 Train: 280.45795 Test: 1.50493
Epoch: 2800 Train: 277.70599 Test: 2.28873
Epoch: 2880 Train: 267.12576 Test: 1.45392
Epoch: 2960 Train: 269.66461 Test: 1.68084
Epoch: 3040 Train: 268.10614 Test: 1.48427
Epoch: 3120 Train: 259.12665 Test: 1.44735
Epoch: 3200 Train: 258.17920 Test: 1.50376
Epoch: 3280 Train: 258.46909 Test: 1.45643
Epoch: 3360 Train: 288.86139 Test: 1.89220
Epoch: 3440 Train: 306.45569 Test: 1.95669
Epoch: 3520 Train: 286.85086 Test: 1.92600
Epoch: 3600 Train: 274.18494 Test: 2.04380
Epoch 3680: New minimal relative error: 5.09%, model saved.
Epoch: 3680 Train: 250.50124 Test: 1.44406
Epoch: 3760 Train: 233.47733 Test: 1.33330
Epoch: 3840 Train: 241.66441 Test: 1.36676
Epoch: 3920 Train: 228.38432 Test: 1.16417
Epoch 4000: New minimal relative error: 4.67%, model saved.
Epoch: 4000 Train: 218.12085 Test: 1.01425
Epoch: 4080 Train: 215.84485 Test: 0.94391
Epoch: 4160 Train: 222.34601 Test: 1.09676
Epoch: 4240 Train: 212.69101 Test: 1.04256
Epoch 4320: New minimal relative error: 4.23%, model saved.
Epoch: 4320 Train: 207.15515 Test: 0.87971
Epoch: 4400 Train: 209.81892 Test: 0.93159
Epoch: 4480 Train: 215.69252 Test: 0.97282
Epoch: 4560 Train: 203.08553 Test: 0.88800
Epoch 4640: New minimal relative error: 3.53%, model saved.
Epoch: 4640 Train: 201.86217 Test: 0.83297
Epoch: 4720 Train: 207.84431 Test: 1.20702
Epoch: 4800 Train: 208.71571 Test: 0.90141
Epoch: 4880 Train: 211.71779 Test: 0.89925
Epoch: 4960 Train: 210.47092 Test: 0.89718
Epoch: 5040 Train: 206.50134 Test: 0.82028
Epoch: 5120 Train: 201.78622 Test: 0.81044
Epoch: 5200 Train: 203.54022 Test: 0.79979
Epoch: 5280 Train: 200.44478 Test: 0.76396
Epoch: 5360 Train: 204.02249 Test: 0.81751
Epoch: 5440 Train: 214.79532 Test: 1.03107
Epoch: 5520 Train: 205.66455 Test: 0.93766
Epoch: 5600 Train: 219.22847 Test: 1.23608
Epoch 5680: New minimal relative error: 3.31%, model saved.
Epoch: 5680 Train: 198.80756 Test: 0.84784
Epoch: 5760 Train: 190.08249 Test: 0.72267
Epoch: 5840 Train: 182.50134 Test: 0.73940
Epoch: 5920 Train: 177.48642 Test: 0.67706
Epoch: 6000 Train: 168.79256 Test: 0.54668
Epoch: 6080 Train: 159.77953 Test: 0.52937
Epoch: 6160 Train: 150.07129 Test: 0.43739
Epoch: 6240 Train: 150.37787 Test: 0.43912
Epoch: 6320 Train: 138.28458 Test: 0.35550
Epoch: 6400 Train: 137.09119 Test: 0.32091
Epoch 6480: New minimal relative error: 2.92%, model saved.
Epoch: 6480 Train: 134.76553 Test: 0.31659
Epoch: 6560 Train: 134.27827 Test: 0.31744
Epoch: 6640 Train: 139.37498 Test: 0.43439
Epoch: 6720 Train: 164.45468 Test: 0.83824
Epoch: 6800 Train: 215.16437 Test: 1.64841
Epoch: 6880 Train: 161.29701 Test: 0.62462
Epoch: 6960 Train: 182.86778 Test: 0.93081
Epoch: 7040 Train: 172.09641 Test: 0.78099
Epoch: 7120 Train: 170.66188 Test: 0.96764
Epoch: 7200 Train: 173.78665 Test: 0.96125
Epoch: 7280 Train: 144.26208 Test: 0.63336
Epoch: 7360 Train: 128.49548 Test: 0.33997
Epoch: 7440 Train: 126.76356 Test: 0.28717
Epoch 7520: New minimal relative error: 2.12%, model saved.
Epoch: 7520 Train: 128.62561 Test: 0.38488
Epoch: 7600 Train: 136.19888 Test: 0.50097
Epoch: 7680 Train: 133.16801 Test: 0.59024
Epoch: 7760 Train: 120.10983 Test: 0.47381
Epoch: 7840 Train: 125.06506 Test: 0.42483
Epoch: 7920 Train: 111.02787 Test: 0.29418
Epoch: 7999 Train: 123.64931 Test: 0.52148
Training Loss: tensor(123.6493)
Test Loss: tensor(0.5215)
Learned LE: [ 8.62494588e-01  7.80213298e-03 -1.45549135e+01]
True LE: [ 8.6603558e-01 -2.2113859e-03 -1.4551199e+01]
Relative Error: [2.4306397  2.744054   3.2696524  3.8456147  4.2656393  4.931864
 5.7279325  6.694641   7.7444315  7.696233   6.5612288  4.8634443
 3.1727452  1.6866535  1.0525389  1.5864862  2.2210937  2.6516955
 2.9147882  3.0322914  2.99093    2.889115   2.7116592  2.4630432
 2.1979954  2.0572283  1.8566598  1.5986608  1.3909729  1.1721251
 0.8727156  0.6398454  0.41070086 0.6391363  1.2208661  1.7359552
 2.2602146  2.4968815  2.4915044  2.626426   2.925859   3.2775347
 2.7955704  2.2047071  1.6933653  1.4817423  1.4328861  1.5357666
 1.8694799  2.461336   3.2800355  3.6832783  2.8997371  2.3435714
 1.9671731  1.7271959  1.5280802  1.4086138  1.3460225  1.3381875
 1.5661961  1.7598828  1.7645583  1.9162446  2.2845485  2.8547657
 3.3181596  3.8910315  4.5890546  5.391841   6.3424883  7.3891187
 6.7872567  5.3618455  3.5735593  2.0842004  1.4210992  1.8172662
 2.421186   2.9224603  3.2298994  3.3424928  3.292256   3.1386342
 2.9164648  2.6190493  2.2507005  1.9789242  1.8810067  1.7953992
 1.7452866  1.6876005  1.5442246  1.296869   0.99371654 0.57320535
 0.58305    1.2339253  1.7535299  1.9422593  2.0993633  2.3137121
 2.634019   2.9300992  2.5098872  1.8650167  1.2649994  1.030982
 0.9855559  1.1430459  1.5669088  2.2494564  3.1755924  3.054712
 2.3026998  1.8195331  1.5543951  1.4159744  1.3032767  1.35622
 1.377882   1.2678245  1.3484197  1.4991546  1.4192613  1.316386
 1.4761037  1.9075509  2.556511   2.9870398  3.5758312  4.253306
 5.0704985  5.9891214  7.020643   6.027447   4.2494     2.6555908
 1.8274063  1.9555231  2.5592816  3.0996878  3.4056578  3.5536826
 3.5496898  3.3707306  3.1085753  2.7907279  2.4247513  2.043389
 1.8478947  1.9559348  2.0888746  2.2005954  2.2285156  2.0552967
 1.7312553  1.1329064  0.47154623 0.68123174 1.3636436  1.6895416
 1.8131472  2.03075    2.5531693  2.935393   2.531207   1.7400997
 1.0054672  0.713554   0.6809086  0.8252538  1.2810156  2.0106554
 2.9869916  2.4994252  1.7768439  1.4068725  1.3288449  1.2614117
 1.3007033  1.4706836  1.4605473  1.4233212  1.3402048  1.3260357
 1.3246752  1.0128678  0.8970989  1.0655257  1.5943514  2.158093
 2.6892836  3.2909696  3.9654822  4.7155113  5.611074   6.338396
 5.035292   3.4519486  2.4021094  2.217109   2.6434867  3.1385682
 3.4955852  3.6811433  3.7252333  3.5801754  3.2960334  2.951355
 2.6000354  2.2596748  2.0003686  2.0124464  2.351062   2.6705236
 2.8688958  2.84775    2.4613664  1.9484725  1.1798519  0.3894418
 0.9266648  1.3528196  1.5493344  1.947301   2.4263353  2.8017135
 2.6187756  1.9053478  1.0658123  0.43100783 0.40651843 0.5260459
 0.9516262  1.7316816  2.7425363  2.11863    1.3740824  1.0724851
 1.1022435  1.2242297  1.4353179  1.5514982  1.5992364  1.4913651
 1.4484767  1.2912694  1.2525004  1.1521214  0.7582704  0.49719083
 0.66330236 1.1549752  1.6573892  2.2288916  2.888485   3.6148977
 4.2903905  5.206258   5.8893147  4.3529453  3.252275   2.672368
 2.833341   3.1862173  3.4896605  3.6895466  3.771252   3.6859136
 3.4818895  3.113988   2.734469   2.44645    2.2721205  2.239182
 2.4728608  3.0162365  3.4349792  3.5389316  3.3016179  2.8739681
 2.2059822  1.2692173  0.5548859  0.9541957  1.2021565  1.7301911
 2.2845578  2.6517575  2.6447532  2.0938995  1.4119008  0.6030479
 0.24262087 0.25955135 0.5649903  1.298731   2.349343   1.9079314
 1.1400659  0.8973825  1.0168303  1.1502509  1.4586225  1.7101668
 1.703853   1.5999149  1.4096067  1.4117851  1.3513205  1.3131344
 1.094597   0.66924846 0.35658985 0.4416085  0.83057785 1.336928
 1.8738618  2.3588836  2.9638758  3.7795405  4.849577   5.523858
 4.0286527  3.3316345  2.9240568  3.0324821  3.285306   3.478099
 3.6515129  3.717731   3.5361216  3.2556686  2.8831053  2.533316
 2.4264898  2.5378318  2.760913   3.1127567  3.69125    4.068302
 4.1590347  3.8632925  3.368395   2.4862728  1.4143729  0.84564865
 0.72405285 1.2794614  1.941596   2.4400723  2.640236   2.2538574
 1.7508739  1.1461016  0.3329117  0.310251   0.23128493 0.7950443
 1.7715963  1.8459212  1.0701503  0.87971205 1.0672613  1.2051122
 1.4635246  1.6951693  1.8309476  1.7486039  1.5232724  1.4420507
 1.482505   1.3555388  1.2228434  0.97593665 0.6042006  0.46042368
 0.55749893 0.79601014 1.1926248  1.5097554  1.8091592  2.2768288
 3.1946402  4.434261   5.3977094  3.879693   3.2742388  3.0154283
 3.0506992  3.2080927  3.2826803  3.3177547  3.4016042  3.269665
 2.972677   2.6640096  2.4116619  2.5627675 ]
